Exp  1 started at  2018-12-20 19:55:30 +0100
Exp 1's result is {"10.158.0.1"=>{:stderr=>"18/12/20 18:55:32 INFO terasort.TeraSort: starting18/12/20 18:55:33 INFO input.FileInputFormat: Total input files to process : 2418/12/20 18:55:35 INFO client.RMProxy: Connecting to ResourceManager at node1/10.158.0.1:803218/12/20 18:55:35 INFO mapreduce.JobSubmitter: number of splits:91218/12/20 18:55:35 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces18/12/20 18:55:36 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1545331827303_000118/12/20 18:55:36 INFO impl.YarnClientImpl: Submitted application application_1545331827303_000118/12/20 18:55:37 INFO mapreduce.Job: The url to track the job: http://node1:8088/proxy/application_1545331827303_0001/18/12/20 18:55:37 INFO mapreduce.Job: Running job: job_1545331827303_000118/12/20 18:55:43 INFO mapreduce.Job: Job job_1545331827303_0001 running in uber mode : false18/12/20 18:55:43 INFO mapreduce.Job:  map 0% reduce 0%18/12/20 18:55:54 INFO mapreduce.Job:  map 1% reduce 0%18/12/20 18:55:55 INFO mapreduce.Job:  map 5% reduce 0%18/12/20 18:55:56 INFO mapreduce.Job:  map 20% reduce 0%18/12/20 18:55:57 INFO mapreduce.Job:  map 31% reduce 0%18/12/20 18:56:04 INFO mapreduce.Job:  map 32% reduce 0%18/12/20 18:56:05 INFO mapreduce.Job:  map 37% reduce 0%18/12/20 18:56:06 INFO mapreduce.Job:  map 45% reduce 0%18/12/20 18:56:07 INFO mapreduce.Job:  map 56% reduce 0%18/12/20 18:56:08 INFO mapreduce.Job:  map 61% reduce 0%18/12/20 18:56:13 INFO mapreduce.Job:  map 62% reduce 4%18/12/20 18:56:14 INFO mapreduce.Job:  map 63% reduce 4%18/12/20 18:56:15 INFO mapreduce.Job:  map 68% reduce 4%18/12/20 18:56:16 INFO mapreduce.Job:  map 75% reduce 4%18/12/20 18:56:17 INFO mapreduce.Job:  map 86% reduce 4%18/12/20 18:56:18 INFO mapreduce.Job:  map 91% reduce 4%18/12/20 18:56:19 INFO mapreduce.Job:  map 92% reduce 6%18/12/20 18:56:20 INFO mapreduce.Job:  map 93% reduce 6%18/12/20 18:56:22 INFO mapreduce.Job:  map 94% reduce 6%18/12/20 18:56:23 INFO mapreduce.Job:  map 96% reduce 6%18/12/20 18:56:24 INFO mapreduce.Job:  map 97% reduce 6%18/12/20 18:56:25 INFO mapreduce.Job:  map 98% reduce 8%18/12/20 18:56:26 INFO mapreduce.Job:  map 99% reduce 8%18/12/20 18:56:28 INFO mapreduce.Job:  map 100% reduce 8%18/12/20 18:56:31 INFO mapreduce.Job:  map 100% reduce 10%18/12/20 18:56:32 INFO mapreduce.Job:  map 100% reduce 11%18/12/20 18:56:37 INFO mapreduce.Job:  map 100% reduce 13%18/12/20 18:56:43 INFO mapreduce.Job:  map 100% reduce 16%18/12/20 18:56:49 INFO mapreduce.Job:  map 100% reduce 18%18/12/20 18:56:55 INFO mapreduce.Job:  map 100% reduce 20%18/12/20 18:56:56 INFO mapreduce.Job:  map 100% reduce 21%18/12/20 18:57:01 INFO mapreduce.Job:  map 100% reduce 23%18/12/20 18:57:07 INFO mapreduce.Job:  map 100% reduce 25%18/12/20 18:57:13 INFO mapreduce.Job:  map 100% reduce 28%18/12/20 18:57:19 INFO mapreduce.Job:  map 100% reduce 30%18/12/20 18:57:25 INFO mapreduce.Job:  map 100% reduce 31%18/12/20 18:57:37 INFO mapreduce.Job:  map 100% reduce 32%18/12/20 18:57:43 INFO mapreduce.Job:  map 100% reduce 33%18/12/20 18:57:49 INFO mapreduce.Job:  map 100% reduce 34%18/12/20 18:57:55 INFO mapreduce.Job:  map 100% reduce 37%18/12/20 18:58:02 INFO mapreduce.Job:  map 100% reduce 43%18/12/20 18:58:08 INFO mapreduce.Job:  map 100% reduce 49%18/12/20 18:58:14 INFO mapreduce.Job:  map 100% reduce 53%18/12/20 18:58:20 INFO mapreduce.Job:  map 100% reduce 56%18/12/20 18:58:26 INFO mapreduce.Job:  map 100% reduce 58%18/12/20 18:58:32 INFO mapreduce.Job:  map 100% reduce 61%18/12/20 18:58:38 INFO mapreduce.Job:  map 100% reduce 65%18/12/20 18:58:44 INFO mapreduce.Job:  map 100% reduce 70%18/12/20 18:58:50 INFO mapreduce.Job:  map 100% reduce 74%18/12/20 18:58:56 INFO mapreduce.Job:  map 100% reduce 77%18/12/20 18:59:02 INFO mapreduce.Job:  map 100% reduce 79%18/12/20 18:59:08 INFO mapreduce.Job:  map 100% reduce 81%18/12/20 18:59:14 INFO mapreduce.Job:  map 100% reduce 83%18/12/20 18:59:20 INFO mapreduce.Job:  map 100% reduce 85%18/12/20 18:59:26 INFO mapreduce.Job:  map 100% reduce 87%18/12/20 18:59:32 INFO mapreduce.Job:  map 100% reduce 89%18/12/20 18:59:38 INFO mapreduce.Job:  map 100% reduce 91%18/12/20 18:59:44 INFO mapreduce.Job:  map 100% reduce 92%18/12/20 18:59:50 INFO mapreduce.Job:  map 100% reduce 93%18/12/20 18:59:56 INFO mapreduce.Job:  map 100% reduce 95%18/12/20 19:00:02 INFO mapreduce.Job:  map 100% reduce 96%18/12/20 19:00:08 INFO mapreduce.Job:  map 100% reduce 97%18/12/20 19:00:20 INFO mapreduce.Job:  map 100% reduce 98%18/12/20 19:00:26 INFO mapreduce.Job:  map 100% reduce 99%18/12/20 19:00:37 INFO mapreduce.Job:  map 100% reduce 100%18/12/20 19:00:47 INFO mapreduce.Job: Job job_1545331827303_0001 completed successfully18/12/20 19:00:47 INFO mapreduce.Job: Counters: 51\n\tFile System Counters\n\t\tFILE: Number of bytes read=388046907088\n\t\tFILE: Number of bytes written=512954021312\n\t\tFILE: Number of read operations=0\n\t\tFILE: Number of large read operations=0\n\t\tFILE: Number of write operations=0\n\t\tHDFS: Number of bytes read=120000092112\n\t\tHDFS: Number of bytes written=120000000000\n\t\tHDFS: Number of read operations=2772\n\t\tHDFS: Number of large read operations=0\n\t\tHDFS: Number of write operations=24\n\tJob Counters \n\t\tKilled map tasks=1\n\t\tLaunched map tasks=913\n\t\tLaunched reduce tasks=12\n\t\tData-local map tasks=901\n\t\tRack-local map tasks=12\n\t\tTotal time spent by all maps in occupied slots (ms)=8135958\n\t\tTotal time spent by all reduces in occupied slots (ms)=2994653\n\t\tTotal time spent by all map tasks (ms)=8135958\n\t\tTotal time spent by all reduce tasks (ms)=2994653\n\t\tTotal vcore-milliseconds taken by all map tasks=8135958\n\t\tTotal vcore-milliseconds taken by all reduce tasks=2994653\n\t\tTotal megabyte-milliseconds taken by all map tasks=8331220992\n\t\tTotal megabyte-milliseconds taken by all reduce tasks=3066524672\n\tMap-Reduce Framework\n\t\tMap input records=1200000000\n\t\tMap output records=1200000000\n\t\tMap output bytes=122400000000\n\t\tMap output materialized bytes=124800065664\n\t\tInput split bytes=92112\n\t\tCombine input records=0\n\t\tCombine output records=0\n\t\tReduce input groups=1200000000\n\t\tReduce shuffle bytes=124800065664\n\t\tReduce input records=1200000000\n\t\tReduce output records=1200000000\n\t\tSpilled Records=4930835110\n\t\tShuffled Maps =10944\n\t\tFailed Shuffles=0\n\t\tMerged Map outputs=10944\n\t\tGC time elapsed (ms)=391546\n\t\tCPU time spent (ms)=14201340\n\t\tPhysical memory (bytes) snapshot=275969175552\n\t\tVirtual memory (bytes) snapshot=1861604581376\n\t\tTotal committed heap usage (bytes)=182343172096\n\tShuffle Errors\n\t\tBAD_ID=0\n\t\tCONNECTION=0\n\t\tIO_ERROR=0\n\t\tWRONG_LENGTH=0\n\t\tWRONG_MAP=0\n\t\tWRONG_REDUCE=0\n\tFile Input Format Counters \n\t\tBytes Read=120000000000\n\tFile Output Format Counters \n\t\tBytes Written=12000000000018/12/20 19:00:47 INFO terasort.TeraSort: donereal\t5m15.725s\nuser\t0m11.375s\nsys\t0m1.112s", :stdout=>"Spent 194ms computing base-splits.Spent 6ms computing TeraScheduler splits.Computing input splits took 200msSampling 10 splits of 912Making 12 from 100000 sampled recordsComputing parititions took 1198msSpent 1401ms computing partitions.", :status=>0}}
Exp  1, overall time taken is 5 m 15.725 s
Exp  1 termintated at 2018-12-20 20:00:48 +0100

Exp  2 started at  2018-12-20 20:18:11 +0100
Exp 2's result is {"10.158.0.1"=>{:stderr=>"18/12/20 19:18:14 INFO terasort.TeraSort: starting18/12/20 19:18:14 INFO input.FileInputFormat: Total input files to process : 2418/12/20 19:18:16 INFO client.RMProxy: Connecting to ResourceManager at node1/10.158.0.1:803218/12/20 19:18:17 INFO mapreduce.JobSubmitter: number of splits:91218/12/20 19:18:17 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces18/12/20 19:18:17 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1545333187075_000118/12/20 19:18:18 INFO impl.YarnClientImpl: Submitted application application_1545333187075_000118/12/20 19:18:18 INFO mapreduce.Job: The url to track the job: http://node1:8088/proxy/application_1545333187075_0001/18/12/20 19:18:18 INFO mapreduce.Job: Running job: job_1545333187075_000118/12/20 19:18:24 INFO mapreduce.Job: Job job_1545333187075_0001 running in uber mode : false18/12/20 19:18:24 INFO mapreduce.Job:  map 0% reduce 0%18/12/20 19:18:36 INFO mapreduce.Job:  map 5% reduce 0%18/12/20 19:18:37 INFO mapreduce.Job:  map 17% reduce 0%18/12/20 19:18:38 INFO mapreduce.Job:  map 30% reduce 0%18/12/20 19:18:45 INFO mapreduce.Job:  map 31% reduce 0%18/12/20 19:18:46 INFO mapreduce.Job:  map 36% reduce 0%18/12/20 19:18:47 INFO mapreduce.Job:  map 45% reduce 0%18/12/20 19:18:48 INFO mapreduce.Job:  map 53% reduce 0%18/12/20 19:18:49 INFO mapreduce.Job:  map 59% reduce 0%18/12/20 19:18:54 INFO mapreduce.Job:  map 59% reduce 4%18/12/20 19:18:55 INFO mapreduce.Job:  map 60% reduce 4%18/12/20 19:18:56 INFO mapreduce.Job:  map 65% reduce 4%18/12/20 19:18:57 INFO mapreduce.Job:  map 73% reduce 4%18/12/20 19:18:58 INFO mapreduce.Job:  map 83% reduce 4%18/12/20 19:18:59 INFO mapreduce.Job:  map 87% reduce 4%18/12/20 19:19:00 INFO mapreduce.Job:  map 88% reduce 6%18/12/20 19:19:01 INFO mapreduce.Job:  map 89% reduce 6%18/12/20 19:19:03 INFO mapreduce.Job:  map 91% reduce 6%18/12/20 19:19:04 INFO mapreduce.Job:  map 92% reduce 6%18/12/20 19:19:06 INFO mapreduce.Job:  map 93% reduce 8%18/12/20 19:19:07 INFO mapreduce.Job:  map 94% reduce 8%18/12/20 19:19:08 INFO mapreduce.Job:  map 95% reduce 8%18/12/20 19:19:10 INFO mapreduce.Job:  map 96% reduce 8%18/12/20 19:19:12 INFO mapreduce.Job:  map 96% reduce 11%18/12/20 19:19:18 INFO mapreduce.Job:  map 96% reduce 13%18/12/20 19:19:24 INFO mapreduce.Job:  map 96% reduce 16%18/12/20 19:19:30 INFO mapreduce.Job:  map 96% reduce 18%18/12/20 19:19:36 INFO mapreduce.Job:  map 96% reduce 21%18/12/20 19:19:42 INFO mapreduce.Job:  map 96% reduce 23%18/12/20 19:19:48 INFO mapreduce.Job:  map 96% reduce 26%18/12/20 19:19:54 INFO mapreduce.Job:  map 96% reduce 29%18/12/20 19:20:00 INFO mapreduce.Job:  map 96% reduce 30%18/12/20 19:20:06 INFO mapreduce.Job:  map 96% reduce 31%18/12/20 19:20:12 INFO mapreduce.Job:  map 96% reduce 32%18/12/20 19:22:28 INFO mapreduce.Job:  map 97% reduce 32%18/12/20 19:28:20 INFO mapreduce.Job:  map 98% reduce 32%18/12/20 19:34:07 INFO mapreduce.Job:  map 99% reduce 32%18/12/20 19:35:21 INFO mapreduce.Job:  map 100% reduce 32%18/12/20 19:35:25 INFO mapreduce.Job:  map 100% reduce 33%18/12/20 19:35:37 INFO mapreduce.Job:  map 100% reduce 42%18/12/20 19:35:43 INFO mapreduce.Job:  map 100% reduce 65%18/12/20 19:35:49 INFO mapreduce.Job:  map 100% reduce 69%18/12/20 19:35:55 INFO mapreduce.Job:  map 100% reduce 71%18/12/20 19:36:01 INFO mapreduce.Job:  map 100% reduce 73%18/12/20 19:36:07 INFO mapreduce.Job:  map 100% reduce 74%18/12/20 19:36:13 INFO mapreduce.Job:  map 100% reduce 76%18/12/20 19:36:19 INFO mapreduce.Job:  map 100% reduce 79%18/12/20 19:36:25 INFO mapreduce.Job:  map 100% reduce 81%18/12/20 19:36:31 INFO mapreduce.Job:  map 100% reduce 83%18/12/20 19:36:37 INFO mapreduce.Job:  map 100% reduce 85%18/12/20 19:36:43 INFO mapreduce.Job:  map 100% reduce 87%18/12/20 19:36:49 INFO mapreduce.Job:  map 100% reduce 89%18/12/20 19:36:55 INFO mapreduce.Job:  map 100% reduce 91%18/12/20 19:37:01 INFO mapreduce.Job:  map 100% reduce 93%18/12/20 19:37:08 INFO mapreduce.Job:  map 100% reduce 95%18/12/20 19:37:14 INFO mapreduce.Job:  map 100% reduce 97%18/12/20 19:37:20 INFO mapreduce.Job:  map 100% reduce 98%18/12/20 19:37:26 INFO mapreduce.Job:  map 100% reduce 99%18/12/20 19:37:32 INFO mapreduce.Job:  map 100% reduce 100%18/12/20 19:37:41 INFO mapreduce.Job: Job job_1545333187075_0001 completed successfully18/12/20 19:37:41 INFO mapreduce.Job: Counters: 51\n\tFile System Counters\n\t\tFILE: Number of bytes read=395589951272\n\t\tFILE: Number of bytes written=520497065496\n\t\tFILE: Number of read operations=0\n\t\tFILE: Number of large read operations=0\n\t\tFILE: Number of write operations=0\n\t\tHDFS: Number of bytes read=120000092112\n\t\tHDFS: Number of bytes written=120000000000\n\t\tHDFS: Number of read operations=2772\n\t\tHDFS: Number of large read operations=0\n\t\tHDFS: Number of write operations=24\n\tJob Counters \n\t\tKilled map tasks=11\n\t\tLaunched map tasks=923\n\t\tLaunched reduce tasks=12\n\t\tData-local map tasks=882\n\t\tRack-local map tasks=41\n\t\tTotal time spent by all maps in occupied slots (ms)=52816510\n\t\tTotal time spent by all reduces in occupied slots (ms)=13497024\n\t\tTotal time spent by all map tasks (ms)=52816510\n\t\tTotal time spent by all reduce tasks (ms)=13497024\n\t\tTotal vcore-milliseconds taken by all map tasks=52816510\n\t\tTotal vcore-milliseconds taken by all reduce tasks=13497024\n\t\tTotal megabyte-milliseconds taken by all map tasks=54084106240\n\t\tTotal megabyte-milliseconds taken by all reduce tasks=13820952576\n\tMap-Reduce Framework\n\t\tMap input records=1200000000\n\t\tMap output records=1200000000\n\t\tMap output bytes=122400000000\n\t\tMap output materialized bytes=124800065664\n\t\tInput split bytes=92112\n\t\tCombine input records=0\n\t\tCombine output records=0\n\t\tReduce input groups=1200000000\n\t\tReduce shuffle bytes=124800065664\n\t\tReduce input records=1200000000\n\t\tReduce output records=1200000000\n\t\tSpilled Records=5003364381\n\t\tShuffled Maps =10944\n\t\tFailed Shuffles=0\n\t\tMerged Map outputs=10944\n\t\tGC time elapsed (ms)=389512\n\t\tCPU time spent (ms)=14214600\n\t\tPhysical memory (bytes) snapshot=275808006144\n\t\tVirtual memory (bytes) snapshot=1861712822272\n\t\tTotal committed heap usage (bytes)=182233071616\n\tShuffle Errors\n\t\tBAD_ID=0\n\t\tCONNECTION=0\n\t\tIO_ERROR=0\n\t\tWRONG_LENGTH=0\n\t\tWRONG_MAP=0\n\t\tWRONG_REDUCE=0\n\tFile Input Format Counters \n\t\tBytes Read=120000000000\n\tFile Output Format Counters \n\t\tBytes Written=12000000000018/12/20 19:37:41 INFO terasort.TeraSort: donereal\t19m28.035s\nuser\t0m13.091s\nsys\t0m1.881s", :stdout=>"Spent 193ms computing base-splits.Spent 5ms computing TeraScheduler splits.\nComputing input splits took 199msSampling 10 splits of 912Making 12 from 100000 sampled recordsComputing parititions took 1280msSpent 1481ms computing partitions.", :status=>0}}
Exp  2, overall time taken is 19 m 28.035 s
Exp  2 termintated at 2018-12-20 20:37:41 +0100

Exp  3 started at  2018-12-20 20:55:59 +0100
Exp 3's result is {"10.158.0.1"=>{:stderr=>"18/12/20 19:56:02 INFO terasort.TeraSort: starting18/12/20 19:56:03 INFO input.FileInputFormat: Total input files to process : 2418/12/20 19:56:04 INFO client.RMProxy: Connecting to ResourceManager at node1/10.158.0.1:803218/12/20 19:56:05 INFO mapreduce.JobSubmitter: number of splits:91218/12/20 19:56:05 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces18/12/20 19:56:05 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1545335450938_000118/12/20 19:56:05 INFO impl.YarnClientImpl: Submitted application application_1545335450938_000118/12/20 19:56:05 INFO mapreduce.Job: The url to track the job: http://node1:8088/proxy/application_1545335450938_0001/18/12/20 19:56:05 INFO mapreduce.Job: Running job: job_1545335450938_000118/12/20 19:56:11 INFO mapreduce.Job: Job job_1545335450938_0001 running in uber mode : false18/12/20 19:56:11 INFO mapreduce.Job:  map 0% reduce 0%18/12/20 19:56:30 INFO mapreduce.Job:  map 2% reduce 0%18/12/20 19:56:31 INFO mapreduce.Job:  map 7% reduce 0%18/12/20 19:56:32 INFO mapreduce.Job:  map 9% reduce 0%18/12/20 19:56:36 INFO mapreduce.Job:  map 10% reduce 0%18/12/20 19:56:37 INFO mapreduce.Job:  map 12% reduce 0%18/12/20 19:56:38 INFO mapreduce.Job:  map 13% reduce 0%18/12/20 19:56:42 INFO mapreduce.Job:  map 15% reduce 0%18/12/20 19:56:43 INFO mapreduce.Job:  map 17% reduce 0%18/12/20 19:56:44 INFO mapreduce.Job:  map 18% reduce 0%18/12/20 19:56:47 INFO mapreduce.Job:  map 19% reduce 0%18/12/20 19:56:48 INFO mapreduce.Job:  map 24% reduce 0%18/12/20 19:56:49 INFO mapreduce.Job:  map 29% reduce 0%18/12/20 19:56:50 INFO mapreduce.Job:  map 30% reduce 0%18/12/20 19:56:59 INFO mapreduce.Job:  map 31% reduce 0%18/12/20 19:57:02 INFO mapreduce.Job:  map 32% reduce 0%18/12/20 19:57:03 INFO mapreduce.Job:  map 34% reduce 0%18/12/20 19:57:04 INFO mapreduce.Job:  map 37% reduce 0%18/12/20 19:57:05 INFO mapreduce.Job:  map 39% reduce 3%18/12/20 19:57:06 INFO mapreduce.Job:  map 41% reduce 5%18/12/20 19:57:09 INFO mapreduce.Job:  map 42% reduce 5%18/12/20 19:57:10 INFO mapreduce.Job:  map 44% reduce 5%18/12/20 19:57:11 INFO mapreduce.Job:  map 45% reduce 6%18/12/20 19:57:12 INFO mapreduce.Job:  map 46% reduce 7%18/12/20 19:57:15 INFO mapreduce.Job:  map 47% reduce 7%18/12/20 19:57:16 INFO mapreduce.Job:  map 49% reduce 7%18/12/20 19:57:17 INFO mapreduce.Job:  map 50% reduce 9%18/12/20 19:57:18 INFO mapreduce.Job:  map 52% reduce 9%18/12/20 19:57:19 INFO mapreduce.Job:  map 54% reduce 9%18/12/20 19:57:20 INFO mapreduce.Job:  map 56% reduce 9%18/12/20 19:57:21 INFO mapreduce.Job:  map 59% reduce 9%18/12/20 19:57:23 INFO mapreduce.Job:  map 60% reduce 11%18/12/20 19:57:24 INFO mapreduce.Job:  map 61% reduce 11%18/12/20 19:57:28 INFO mapreduce.Job:  map 62% reduce 12%18/12/20 19:57:29 INFO mapreduce.Job:  map 62% reduce 13%18/12/20 19:57:30 INFO mapreduce.Job:  map 63% reduce 14%18/12/20 19:57:34 INFO mapreduce.Job:  map 64% reduce 14%18/12/20 19:57:35 INFO mapreduce.Job:  map 64% reduce 16%18/12/20 19:57:37 INFO mapreduce.Job:  map 65% reduce 16%18/12/20 19:57:40 INFO mapreduce.Job:  map 66% reduce 17%18/12/20 19:57:41 INFO mapreduce.Job:  map 66% reduce 18%18/12/20 19:57:43 INFO mapreduce.Job:  map 67% reduce 18%18/12/20 19:57:44 INFO mapreduce.Job:  map 68% reduce 18%18/12/20 19:57:45 INFO mapreduce.Job:  map 69% reduce 18%18/12/20 19:57:46 INFO mapreduce.Job:  map 70% reduce 18%18/12/20 19:57:47 INFO mapreduce.Job:  map 71% reduce 19%18/12/20 19:57:48 INFO mapreduce.Job:  map 72% reduce 20%18/12/20 19:57:49 INFO mapreduce.Job:  map 73% reduce 20%18/12/20 19:57:50 INFO mapreduce.Job:  map 74% reduce 20%18/12/20 19:57:51 INFO mapreduce.Job:  map 75% reduce 20%18/12/20 19:57:52 INFO mapreduce.Job:  map 76% reduce 20%18/12/20 19:57:53 INFO mapreduce.Job:  map 76% reduce 21%18/12/20 19:57:54 INFO mapreduce.Job:  map 77% reduce 21%18/12/20 19:57:56 INFO mapreduce.Job:  map 78% reduce 21%18/12/20 19:57:57 INFO mapreduce.Job:  map 79% reduce 21%18/12/20 19:57:58 INFO mapreduce.Job:  map 80% reduce 21%18/12/20 19:57:59 INFO mapreduce.Job:  map 81% reduce 21%18/12/20 19:58:00 INFO mapreduce.Job:  map 83% reduce 21%18/12/20 19:58:01 INFO mapreduce.Job:  map 84% reduce 21%18/12/20 19:58:02 INFO mapreduce.Job:  map 85% reduce 21%18/12/20 19:58:03 INFO mapreduce.Job:  map 86% reduce 21%18/12/20 19:58:04 INFO mapreduce.Job:  map 87% reduce 22%18/12/20 19:58:05 INFO mapreduce.Job:  map 87% reduce 23%18/12/20 19:58:06 INFO mapreduce.Job:  map 88% reduce 23%18/12/20 19:58:07 INFO mapreduce.Job:  map 89% reduce 23%18/12/20 19:58:08 INFO mapreduce.Job:  map 90% reduce 23%18/12/20 19:58:10 INFO mapreduce.Job:  map 90% reduce 24%18/12/20 19:58:11 INFO mapreduce.Job:  map 90% reduce 25%18/12/20 19:58:14 INFO mapreduce.Job:  map 91% reduce 25%18/12/20 19:58:17 INFO mapreduce.Job:  map 91% reduce 26%18/12/20 19:58:19 INFO mapreduce.Job:  map 92% reduce 26%18/12/20 19:58:26 INFO mapreduce.Job:  map 93% reduce 26%18/12/20 19:58:32 INFO mapreduce.Job:  map 94% reduce 26%18/12/20 19:58:38 INFO mapreduce.Job:  map 95% reduce 26%18/12/20 19:58:40 INFO mapreduce.Job:  map 95% reduce 27%18/12/20 19:58:49 INFO mapreduce.Job:  map 96% reduce 27%18/12/20 19:58:53 INFO mapreduce.Job:  map 96% reduce 28%18/12/20 19:58:55 INFO mapreduce.Job:  map 97% reduce 28%18/12/20 19:59:05 INFO mapreduce.Job:  map 98% reduce 28%18/12/20 19:59:22 INFO mapreduce.Job:  map 99% reduce 28%18/12/20 19:59:36 INFO mapreduce.Job:  map 99% reduce 29%18/12/20 19:59:44 INFO mapreduce.Job:  map 100% reduce 29%18/12/20 20:00:12 INFO mapreduce.Job:  map 100% reduce 30%18/12/20 20:01:00 INFO mapreduce.Job:  map 100% reduce 31%18/12/20 20:01:24 INFO mapreduce.Job:  map 100% reduce 32%18/12/20 20:01:36 INFO mapreduce.Job:  map 100% reduce 33%18/12/20 20:01:48 INFO mapreduce.Job:  map 100% reduce 35%18/12/20 20:02:00 INFO mapreduce.Job:  map 100% reduce 37%18/12/20 20:02:06 INFO mapreduce.Job:  map 100% reduce 39%18/12/20 20:02:12 INFO mapreduce.Job:  map 100% reduce 42%18/12/20 20:02:18 INFO mapreduce.Job:  map 100% reduce 44%18/12/20 20:02:23 INFO mapreduce.Job:  map 100% reduce 46%18/12/20 20:02:24 INFO mapreduce.Job:  map 100% reduce 47%18/12/20 20:02:29 INFO mapreduce.Job:  map 100% reduce 48%18/12/20 20:02:59 INFO mapreduce.Job:  map 100% reduce 49%18/12/20 20:03:11 INFO mapreduce.Job:  map 100% reduce 50%18/12/20 20:03:23 INFO mapreduce.Job:  map 100% reduce 51%18/12/20 20:03:35 INFO mapreduce.Job:  map 100% reduce 52%18/12/20 20:03:41 INFO mapreduce.Job:  map 100% reduce 53%18/12/20 20:03:47 INFO mapreduce.Job:  map 100% reduce 54%18/12/20 20:03:53 INFO mapreduce.Job:  map 100% reduce 55%18/12/20 20:03:58 INFO mapreduce.Job:  map 100% reduce 56%18/12/20 20:04:29 INFO mapreduce.Job:  map 100% reduce 58%18/12/20 20:04:35 INFO mapreduce.Job:  map 100% reduce 61%18/12/20 20:04:41 INFO mapreduce.Job:  map 100% reduce 62%18/12/20 20:04:53 INFO mapreduce.Job:  map 100% reduce 63%18/12/20 20:05:04 INFO mapreduce.Job:  map 100% reduce 64%18/12/20 20:05:05 INFO mapreduce.Job:  map 100% reduce 67%18/12/20 20:05:10 INFO mapreduce.Job:  map 100% reduce 68%18/12/20 20:05:11 INFO mapreduce.Job:  map 100% reduce 70%18/12/20 20:05:17 INFO mapreduce.Job:  map 100% reduce 71%18/12/20 20:05:27 INFO mapreduce.Job:  map 100% reduce 72%18/12/20 20:09:29 INFO mapreduce.Job:  map 100% reduce 73%18/12/20 20:09:47 INFO mapreduce.Job:  map 100% reduce 74%18/12/20 20:10:12 INFO mapreduce.Job:  map 100% reduce 75%18/12/20 20:10:30 INFO mapreduce.Job:  map 100% reduce 76%18/12/20 20:10:48 INFO mapreduce.Job:  map 100% reduce 77%18/12/20 20:11:58 INFO mapreduce.Job:  map 100% reduce 78%18/12/20 20:12:36 INFO mapreduce.Job:  map 100% reduce 79%18/12/20 20:12:53 INFO mapreduce.Job:  map 100% reduce 80%18/12/20 20:13:05 INFO mapreduce.Job:  map 100% reduce 81%18/12/20 20:13:23 INFO mapreduce.Job:  map 100% reduce 82%18/12/20 20:13:35 INFO mapreduce.Job:  map 100% reduce 83%18/12/20 20:13:47 INFO mapreduce.Job:  map 100% reduce 84%18/12/20 20:13:59 INFO mapreduce.Job:  map 100% reduce 85%18/12/20 20:14:17 INFO mapreduce.Job:  map 100% reduce 86%18/12/20 20:14:29 INFO mapreduce.Job:  map 100% reduce 87%18/12/20 20:14:47 INFO mapreduce.Job:  map 100% reduce 88%18/12/20 20:14:59 INFO mapreduce.Job:  map 100% reduce 89%18/12/20 20:19:17 INFO mapreduce.Job:  map 100% reduce 90%18/12/20 20:19:35 INFO mapreduce.Job:  map 100% reduce 91%18/12/20 20:19:53 INFO mapreduce.Job:  map 100% reduce 92%18/12/20 20:20:05 INFO mapreduce.Job:  map 100% reduce 93%18/12/20 20:20:17 INFO mapreduce.Job:  map 100% reduce 94%18/12/20 20:20:47 INFO mapreduce.Job:  map 100% reduce 95%18/12/20 20:21:47 INFO mapreduce.Job:  map 100% reduce 96%18/12/20 20:22:48 INFO mapreduce.Job:  map 100% reduce 97%18/12/20 20:23:48 INFO mapreduce.Job:  map 100% reduce 98%18/12/20 20:24:48 INFO mapreduce.Job:  map 100% reduce 99%18/12/20 20:25:48 INFO mapreduce.Job:  map 100% reduce 100%18/12/20 20:27:31 INFO mapreduce.Job: Job job_1545335450938_0001 completed successfully18/12/20 20:27:32 INFO mapreduce.Job: Counters: 52\n\tFile System Counters\n\t\tFILE: Number of bytes read=387956522280\n\t\tFILE: Number of bytes written=512863551192\n\t\tFILE: Number of read operations=0\n\t\tFILE: Number of large read operations=0\n\t\tFILE: Number of write operations=0\n\t\tHDFS: Number of bytes read=120000092112\n\t\tHDFS: Number of bytes written=120000000000\n\t\tHDFS: Number of read operations=2772\n\t\tHDFS: Number of large read operations=0\n\t\tHDFS: Number of write operations=24\n\tJob Counters \n\t\tKilled map tasks=4\n\t\tKilled reduce tasks=4\n\t\tLaunched map tasks=916\n\t\tLaunched reduce tasks=16\n\t\tData-local map tasks=863\n\t\tRack-local map tasks=53\n\t\tTotal time spent by all maps in occupied slots (ms)=26118663\n\t\tTotal time spent by all reduces in occupied slots (ms)=17437883\n\t\tTotal time spent by all map tasks (ms)=26118663\n\t\tTotal time spent by all reduce tasks (ms)=17437883\n\t\tTotal vcore-milliseconds taken by all map tasks=26118663\n\t\tTotal vcore-milliseconds taken by all reduce tasks=17437883\n\t\tTotal megabyte-milliseconds taken by all map tasks=26745510912\n\t\tTotal megabyte-milliseconds taken by all reduce tasks=17856392192\n\tMap-Reduce Framework\n\t\tMap input records=1200000000\n\t\tMap output records=1200000000\n\t\tMap output bytes=122400000000\n\t\tMap output materialized bytes=124800065664\n\t\tInput split bytes=92112\n\t\tCombine input records=0\n\t\tCombine output records=0\n\t\tReduce input groups=1200000000\n\t\tReduce shuffle bytes=124800065664\n\t\tReduce input records=1200000000\n\t\tReduce output records=1200000000\n\t\tSpilled Records=4929965205\n\t\tShuffled Maps =10944\n\t\tFailed Shuffles=0\n\t\tMerged Map outputs=10944\n\t\tGC time elapsed (ms)=342694\n\t\tCPU time spent (ms)=14385260\n\t\tPhysical memory (bytes) snapshot=275772854272\n\t\tVirtual memory (bytes) snapshot=1861470924800\n\t\tTotal committed heap usage (bytes)=182110912512\n\tShuffle Errors\n\t\tBAD_ID=0\n\t\tCONNECTION=0\n\t\tIO_ERROR=0\n\t\tWRONG_LENGTH=0\n\t\tWRONG_MAP=0\n\t\tWRONG_REDUCE=0\n\tFile Input Format Counters \n\t\tBytes Read=120000000000\n\tFile Output Format Counters \n\t\tBytes Written=12000000000018/12/20 20:27:32 INFO terasort.TeraSort: donereal\t31m30.720s\nuser\t0m15.712s\nsys\t0m2.137s", :stdout=>"Spent 183ms computing base-splits.Spent 4ms computing TeraScheduler splits.Computing input splits took 188msSampling 10 splits of 912Making 12 from 100000 sampled recordsComputing parititions took 1228msSpent 1418ms computing partitions.", :status=>0}}
Exp  3, overall time taken is 31 m 30.720 s
Exp  3 termintated at 2018-12-20 21:27:32 +0100

Exp  4 started at  2018-12-20 21:45:18 +0100
Exp 4's result is {"10.158.0.1"=>{:stderr=>"18/12/20 20:45:21 INFO terasort.TeraSort: starting18/12/20 20:45:21 INFO input.FileInputFormat: Total input files to process : 2418/12/20 20:45:23 INFO client.RMProxy: Connecting to ResourceManager at node1/10.158.0.1:803218/12/20 20:45:24 INFO mapreduce.JobSubmitter: number of splits:91218/12/20 20:45:24 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces18/12/20 20:45:25 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1545338410941_000118/12/20 20:45:25 INFO impl.YarnClientImpl: Submitted application application_1545338410941_000118/12/20 20:45:25 INFO mapreduce.Job: The url to track the job: http://node1:8088/proxy/application_1545338410941_0001/18/12/20 20:45:25 INFO mapreduce.Job: Running job: job_1545338410941_000118/12/20 20:45:31 INFO mapreduce.Job: Job job_1545338410941_0001 running in uber mode : false18/12/20 20:45:31 INFO mapreduce.Job:  map 0% reduce 0%18/12/20 20:45:50 INFO mapreduce.Job:  map 2% reduce 0%18/12/20 20:45:51 INFO mapreduce.Job:  map 4% reduce 0%18/12/20 20:45:52 INFO mapreduce.Job:  map 5% reduce 0%18/12/20 20:45:56 INFO mapreduce.Job:  map 6% reduce 0%18/12/20 20:45:57 INFO mapreduce.Job:  map 7% reduce 0%18/12/20 20:46:02 INFO mapreduce.Job:  map 8% reduce 0%18/12/20 20:46:03 INFO mapreduce.Job:  map 9% reduce 0%18/12/20 20:46:08 INFO mapreduce.Job:  map 11% reduce 0%18/12/20 20:46:09 INFO mapreduce.Job:  map 12% reduce 0%18/12/20 20:46:14 INFO mapreduce.Job:  map 13% reduce 0%18/12/20 20:46:15 INFO mapreduce.Job:  map 14% reduce 0%18/12/20 20:46:20 INFO mapreduce.Job:  map 15% reduce 0%18/12/20 20:46:21 INFO mapreduce.Job:  map 16% reduce 0%18/12/20 20:46:25 INFO mapreduce.Job:  map 17% reduce 0%18/12/20 20:46:26 INFO mapreduce.Job:  map 18% reduce 0%18/12/20 20:46:27 INFO mapreduce.Job:  map 19% reduce 0%18/12/20 20:46:33 INFO mapreduce.Job:  map 20% reduce 0%18/12/20 20:46:34 INFO mapreduce.Job:  map 22% reduce 0%18/12/20 20:46:35 INFO mapreduce.Job:  map 23% reduce 0%18/12/20 20:46:36 INFO mapreduce.Job:  map 26% reduce 0%18/12/20 20:46:37 INFO mapreduce.Job:  map 27% reduce 0%18/12/20 20:46:39 INFO mapreduce.Job:  map 28% reduce 0%18/12/20 20:46:40 INFO mapreduce.Job:  map 29% reduce 0%18/12/20 20:46:44 INFO mapreduce.Job:  map 30% reduce 0%18/12/20 20:46:49 INFO mapreduce.Job:  map 31% reduce 0%18/12/20 20:46:51 INFO mapreduce.Job:  map 32% reduce 0%18/12/20 20:46:52 INFO mapreduce.Job:  map 33% reduce 4%18/12/20 20:46:54 INFO mapreduce.Job:  map 34% reduce 4%18/12/20 20:46:57 INFO mapreduce.Job:  map 36% reduce 4%18/12/20 20:46:58 INFO mapreduce.Job:  map 37% reduce 7%18/12/20 20:47:00 INFO mapreduce.Job:  map 38% reduce 7%18/12/20 20:47:04 INFO mapreduce.Job:  map 39% reduce 9%18/12/20 20:47:07 INFO mapreduce.Job:  map 40% reduce 9%18/12/20 20:47:10 INFO mapreduce.Job:  map 41% reduce 10%18/12/20 20:47:12 INFO mapreduce.Job:  map 42% reduce 10%18/12/20 20:47:14 INFO mapreduce.Job:  map 43% reduce 10%18/12/20 20:47:15 INFO mapreduce.Job:  map 44% reduce 10%18/12/20 20:47:16 INFO mapreduce.Job:  map 44% reduce 11%18/12/20 20:47:17 INFO mapreduce.Job:  map 45% reduce 11%18/12/20 20:47:21 INFO mapreduce.Job:  map 46% reduce 11%18/12/20 20:47:22 INFO mapreduce.Job:  map 47% reduce 11%18/12/20 20:47:25 INFO mapreduce.Job:  map 48% reduce 11%18/12/20 20:47:27 INFO mapreduce.Job:  map 49% reduce 11%18/12/20 20:47:28 INFO mapreduce.Job:  map 49% reduce 12%18/12/20 20:47:29 INFO mapreduce.Job:  map 50% reduce 12%18/12/20 20:47:30 INFO mapreduce.Job:  map 51% reduce 12%18/12/20 20:47:32 INFO mapreduce.Job:  map 52% reduce 12%18/12/20 20:47:33 INFO mapreduce.Job:  map 53% reduce 12%18/12/20 20:47:34 INFO mapreduce.Job:  map 53% reduce 13%18/12/20 20:47:35 INFO mapreduce.Job:  map 54% reduce 13%18/12/20 20:47:40 INFO mapreduce.Job:  map 54% reduce 15%18/12/20 20:47:41 INFO mapreduce.Job:  map 55% reduce 15%18/12/20 20:47:42 INFO mapreduce.Job:  map 56% reduce 15%18/12/20 20:47:45 INFO mapreduce.Job:  map 57% reduce 15%18/12/20 20:47:46 INFO mapreduce.Job:  map 57% reduce 16%18/12/20 20:47:51 INFO mapreduce.Job:  map 58% reduce 16%18/12/20 20:47:55 INFO mapreduce.Job:  map 59% reduce 16%18/12/20 20:47:56 INFO mapreduce.Job:  map 60% reduce 16%18/12/20 20:47:58 INFO mapreduce.Job:  map 61% reduce 17%18/12/20 20:48:00 INFO mapreduce.Job:  map 62% reduce 17%18/12/20 20:48:02 INFO mapreduce.Job:  map 63% reduce 17%18/12/20 20:48:04 INFO mapreduce.Job:  map 63% reduce 18%18/12/20 20:48:08 INFO mapreduce.Job:  map 64% reduce 18%18/12/20 20:48:11 INFO mapreduce.Job:  map 65% reduce 18%18/12/20 20:48:14 INFO mapreduce.Job:  map 66% reduce 18%18/12/20 20:48:17 INFO mapreduce.Job:  map 67% reduce 18%18/12/20 20:48:20 INFO mapreduce.Job:  map 68% reduce 18%18/12/20 20:48:22 INFO mapreduce.Job:  map 69% reduce 18%18/12/20 20:48:26 INFO mapreduce.Job:  map 70% reduce 18%18/12/20 20:48:27 INFO mapreduce.Job:  map 71% reduce 18%18/12/20 20:48:28 INFO mapreduce.Job:  map 71% reduce 19%18/12/20 20:48:30 INFO mapreduce.Job:  map 72% reduce 19%18/12/20 20:48:32 INFO mapreduce.Job:  map 73% reduce 19%18/12/20 20:48:35 INFO mapreduce.Job:  map 74% reduce 19%18/12/20 20:48:37 INFO mapreduce.Job:  map 75% reduce 19%18/12/20 20:48:39 INFO mapreduce.Job:  map 76% reduce 19%18/12/20 20:48:40 INFO mapreduce.Job:  map 76% reduce 20%18/12/20 20:48:41 INFO mapreduce.Job:  map 77% reduce 20%18/12/20 20:48:43 INFO mapreduce.Job:  map 78% reduce 20%18/12/20 20:48:45 INFO mapreduce.Job:  map 79% reduce 20%18/12/20 20:48:46 INFO mapreduce.Job:  map 79% reduce 21%18/12/20 20:48:48 INFO mapreduce.Job:  map 80% reduce 21%18/12/20 20:48:51 INFO mapreduce.Job:  map 81% reduce 21%18/12/20 20:48:54 INFO mapreduce.Job:  map 82% reduce 21%18/12/20 20:48:56 INFO mapreduce.Job:  map 83% reduce 21%18/12/20 20:48:58 INFO mapreduce.Job:  map 84% reduce 22%18/12/20 20:48:59 INFO mapreduce.Job:  map 85% reduce 22%18/12/20 20:49:02 INFO mapreduce.Job:  map 86% reduce 22%18/12/20 20:49:04 INFO mapreduce.Job:  map 86% reduce 23%18/12/20 20:49:05 INFO mapreduce.Job:  map 87% reduce 23%18/12/20 20:49:10 INFO mapreduce.Job:  map 87% reduce 24%18/12/20 20:49:12 INFO mapreduce.Job:  map 88% reduce 24%18/12/20 20:49:21 INFO mapreduce.Job:  map 89% reduce 24%18/12/20 20:49:26 INFO mapreduce.Job:  map 90% reduce 24%18/12/20 20:49:28 INFO mapreduce.Job:  map 90% reduce 25%18/12/20 20:49:37 INFO mapreduce.Job:  map 91% reduce 25%18/12/20 20:49:47 INFO mapreduce.Job:  map 92% reduce 25%18/12/20 20:49:57 INFO mapreduce.Job:  map 93% reduce 25%18/12/20 20:49:58 INFO mapreduce.Job:  map 93% reduce 26%18/12/20 20:50:15 INFO mapreduce.Job:  map 94% reduce 26%18/12/20 20:50:26 INFO mapreduce.Job:  map 95% reduce 26%18/12/20 20:50:35 INFO mapreduce.Job:  map 95% reduce 27%18/12/20 20:50:36 INFO mapreduce.Job:  map 96% reduce 27%18/12/20 20:50:43 INFO mapreduce.Job:  map 97% reduce 27%18/12/20 20:50:49 INFO mapreduce.Job:  map 98% reduce 27%18/12/20 20:51:02 INFO mapreduce.Job:  map 99% reduce 27%18/12/20 20:51:05 INFO mapreduce.Job:  map 99% reduce 28%18/12/20 20:51:19 INFO mapreduce.Job:  map 100% reduce 28%18/12/20 20:51:58 INFO mapreduce.Job:  map 100% reduce 29%18/12/20 20:54:17 INFO mapreduce.Job:  map 100% reduce 30%18/12/20 20:57:30 INFO mapreduce.Job: Task Id : attempt_1545338410941_0001_m_000406_0, Status : FAILEDAttemptID:attempt_1545338410941_0001_m_000406_0 Timed out after 600 secs18/12/20 20:57:30 INFO mapreduce.Job: Task Id : attempt_1545338410941_0001_m_000404_0, Status : FAILEDAttemptID:attempt_1545338410941_0001_m_000404_0 Timed out after 600 secs18/12/20 20:57:30 INFO mapreduce.Job: Task Id : attempt_1545338410941_0001_m_000403_0, Status : FAILEDAttemptID:attempt_1545338410941_0001_m_000403_0 Timed out after 600 secs18/12/20 20:57:30 INFO mapreduce.Job: Task Id : attempt_1545338410941_0001_m_000408_0, Status : FAILEDAttemptID:attempt_1545338410941_0001_m_000408_0 Timed out after 600 secs18/12/20 20:57:30 INFO mapreduce.Job: Task Id : attempt_1545338410941_0001_m_000405_0, Status : FAILEDAttemptID:attempt_1545338410941_0001_m_000405_0 Timed out after 600 secs18/12/20 20:57:30 INFO mapreduce.Job: Task Id : attempt_1545338410941_0001_m_000402_0, Status : FAILEDAttemptID:attempt_1545338410941_0001_m_000402_0 Timed out after 600 secs18/12/20 20:57:30 INFO mapreduce.Job: Task Id : attempt_1545338410941_0001_m_000407_0, Status : FAILEDAttemptID:attempt_1545338410941_0001_m_000407_0 Timed out after 600 secs18/12/20 20:57:31 INFO mapreduce.Job:  map 99% reduce 30%18/12/20 20:57:39 INFO mapreduce.Job:  map 100% reduce 30%18/12/20 20:57:45 INFO mapreduce.Job:  map 100% reduce 31%18/12/20 20:57:46 INFO mapreduce.Job:  map 100% reduce 33%18/12/20 20:57:47 INFO mapreduce.Job:  map 100% reduce 34%18/12/20 20:57:51 INFO mapreduce.Job:  map 100% reduce 35%18/12/20 20:57:52 INFO mapreduce.Job:  map 100% reduce 37%18/12/20 20:57:53 INFO mapreduce.Job:  map 100% reduce 38%18/12/20 20:57:57 INFO mapreduce.Job:  map 100% reduce 39%18/12/20 20:57:58 INFO mapreduce.Job:  map 100% reduce 41%18/12/20 20:57:59 INFO mapreduce.Job:  map 100% reduce 42%18/12/20 20:58:52 INFO mapreduce.Job:  map 100% reduce 43%18/12/20 20:59:16 INFO mapreduce.Job:  map 100% reduce 44%18/12/20 20:59:28 INFO mapreduce.Job:  map 100% reduce 45%18/12/20 20:59:40 INFO mapreduce.Job:  map 100% reduce 46%18/12/20 20:59:58 INFO mapreduce.Job:  map 100% reduce 47%18/12/20 21:00:22 INFO mapreduce.Job:  map 100% reduce 48%18/12/20 21:00:34 INFO mapreduce.Job:  map 100% reduce 49%18/12/20 21:01:04 INFO mapreduce.Job:  map 100% reduce 50%18/12/20 21:01:17 INFO mapreduce.Job:  map 100% reduce 51%18/12/20 21:01:22 INFO mapreduce.Job:  map 100% reduce 52%18/12/20 21:01:23 INFO mapreduce.Job:  map 100% reduce 53%18/12/20 21:01:39 INFO mapreduce.Job:  map 100% reduce 54%18/12/20 21:01:57 INFO mapreduce.Job:  map 100% reduce 55%18/12/20 21:02:09 INFO mapreduce.Job:  map 100% reduce 56%18/12/20 21:02:17 INFO mapreduce.Job:  map 100% reduce 57%18/12/20 21:02:29 INFO mapreduce.Job:  map 100% reduce 58%18/12/20 21:02:59 INFO mapreduce.Job:  map 100% reduce 59%18/12/20 21:06:04 INFO mapreduce.Job:  map 100% reduce 60%18/12/20 21:06:10 INFO mapreduce.Job:  map 100% reduce 61%18/12/20 21:06:16 INFO mapreduce.Job:  map 100% reduce 62%18/12/20 21:07:41 INFO mapreduce.Job:  map 100% reduce 65%18/12/20 21:07:47 INFO mapreduce.Job:  map 100% reduce 67%18/12/20 21:10:59 INFO mapreduce.Job:  map 100% reduce 68%18/12/20 21:11:11 INFO mapreduce.Job:  map 100% reduce 69%18/12/20 21:11:23 INFO mapreduce.Job:  map 100% reduce 70%18/12/20 21:11:35 INFO mapreduce.Job:  map 100% reduce 71%18/12/20 21:11:46 INFO mapreduce.Job:  map 100% reduce 72%18/12/20 21:11:58 INFO mapreduce.Job:  map 100% reduce 73%18/12/20 21:12:10 INFO mapreduce.Job:  map 100% reduce 74%18/12/20 21:12:17 INFO mapreduce.Job:  map 100% reduce 75%18/12/20 21:13:08 INFO mapreduce.Job:  map 100% reduce 77%18/12/20 21:13:14 INFO mapreduce.Job:  map 100% reduce 78%18/12/20 21:13:41 INFO mapreduce.Job:  map 100% reduce 79%18/12/20 21:14:17 INFO mapreduce.Job:  map 100% reduce 80%18/12/20 21:14:47 INFO mapreduce.Job:  map 100% reduce 81%18/12/20 21:17:04 INFO mapreduce.Job:  map 100% reduce 82%18/12/20 21:18:28 INFO mapreduce.Job:  map 100% reduce 83%18/12/20 21:19:02 INFO mapreduce.Job:  map 100% reduce 84%18/12/20 21:19:26 INFO mapreduce.Job:  map 100% reduce 85%18/12/20 21:19:50 INFO mapreduce.Job:  map 100% reduce 86%18/12/20 21:20:13 INFO mapreduce.Job:  map 100% reduce 87%18/12/20 21:21:17 INFO mapreduce.Job:  map 100% reduce 88%18/12/20 21:21:48 INFO mapreduce.Job:  map 100% reduce 89%18/12/20 21:21:54 INFO mapreduce.Job:  map 100% reduce 90%18/12/20 21:22:12 INFO mapreduce.Job:  map 100% reduce 91%18/12/20 21:22:47 INFO mapreduce.Job:  map 100% reduce 92%18/12/20 21:29:17 INFO mapreduce.Job:  map 100% reduce 93%18/12/20 21:29:47 INFO mapreduce.Job:  map 100% reduce 94%18/12/20 21:33:01 INFO mapreduce.Job: Task Id : attempt_1545338410941_0001_r_000011_0, Status : FAILEDAttemptID:attempt_1545338410941_0001_r_000011_0 Timed out after 600 secsContainer killed by the ApplicationMaster.\nSent signal OUTPUT_THREAD_DUMP (SIGQUIT) to pid 15894 as user hadoop for container container_1545338410941_0001_01_000382, result=success\nContainer killed on request. Exit code is 143\nContainer exited with a non-zero exit code 14318/12/20 21:33:01 INFO mapreduce.Job: Task Id : attempt_1545338410941_0001_r_000001_1, Status : FAILEDAttemptID:attempt_1545338410941_0001_r_000001_1 Timed out after 600 secs\nSent signal OUTPUT_THREAD_DUMP (SIGQUIT) to pid 18486 as user hadoop for container container_1545338410941_0001_01_000947, result=success\nContainer killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\nContainer exited with a non-zero exit code 14318/12/20 21:33:13 INFO mapreduce.Job:  map 100% reduce 95%18/12/20 21:33:43 INFO mapreduce.Job:  map 100% reduce 96%18/12/20 21:34:01 INFO mapreduce.Job: Task Id : attempt_1545338410941_0001_r_000008_0, Status : FAILEDAttemptID:attempt_1545338410941_0001_r_000008_0 Timed out after 600 secsContainer killed by the ApplicationMaster.\nSent signal OUTPUT_THREAD_DUMP (SIGQUIT) to pid 15895 as user hadoop for container container_1545338410941_0001_01_000379, result=success\nContainer killed on request. Exit code is 143\nContainer exited with a non-zero exit code 14318/12/20 21:34:01 INFO mapreduce.Job: Task Id : attempt_1545338410941_0001_r_000011_1, Status : FAILEDAttemptID:attempt_1545338410941_0001_r_000011_1 Timed out after 600 secs\nContainer killed by the ApplicationMaster.\nSent signal OUTPUT_THREAD_DUMP (SIGQUIT) to pid 18564 as user hadoop for container container_1545338410941_0001_01_000948, result=success\nContainer killed on request. Exit code is 143\nContainer exited with a non-zero exit code 14318/12/20 21:34:02 INFO mapreduce.Job:  map 100% reduce 91%18/12/20 21:34:24 INFO mapreduce.Job:  map 100% reduce 92%18/12/20 21:34:53 INFO mapreduce.Job:  map 100% reduce 93%18/12/20 21:35:23 INFO mapreduce.Job:  map 100% reduce 94%18/12/20 21:41:11 INFO mapreduce.Job:  map 100% reduce 96%18/12/20 21:41:17 INFO mapreduce.Job:  map 100% reduce 97%18/12/20 21:44:51 INFO mapreduce.Job:  map 100% reduce 98%18/12/20 21:45:21 INFO mapreduce.Job:  map 100% reduce 99%18/12/20 21:45:51 INFO mapreduce.Job:  map 100% reduce 100%18/12/20 21:49:47 INFO mapreduce.Job: Job job_1545338410941_0001 completed successfully18/12/20 21:49:47 INFO mapreduce.Job: Counters: 55\n\tFile System Counters\n\t\tFILE: Number of bytes read=390327007352\n\t\tFILE: Number of bytes written=515234121576\n\t\tFILE: Number of read operations=0\n\t\tFILE: Number of large read operations=0\n\t\tFILE: Number of write operations=0\n\t\tHDFS: Number of bytes read=120000092112\n\t\tHDFS: Number of bytes written=120000000000\n\t\tHDFS: Number of read operations=2772\n\t\tHDFS: Number of large read operations=0\n\t\tHDFS: Number of write operations=24\n\tJob Counters \n\t\tFailed map tasks=7\n\t\tFailed reduce tasks=4\n\t\tKilled map tasks=4\n\t\tKilled reduce tasks=6\n\t\tLaunched map tasks=923\n\t\tLaunched reduce tasks=22\n\t\tOther local map tasks=8\n\t\tData-local map tasks=836\n\t\tRack-local map tasks=79\n\t\tTotal time spent by all maps in occupied slots (ms)=55648672\n\t\tTotal time spent by all reduces in occupied slots (ms)=34283984\n\t\tTotal time spent by all map tasks (ms)=55648672\n\t\tTotal time spent by all reduce tasks (ms)=34283984\n\t\tTotal vcore-milliseconds taken by all map tasks=55648672\n\t\tTotal vcore-milliseconds taken by all reduce tasks=34283984\n\t\tTotal megabyte-milliseconds taken by all map tasks=56984240128\n\t\tTotal megabyte-milliseconds taken by all reduce tasks=35106799616\n\tMap-Reduce Framework\n\t\tMap input records=1200000000\n\t\tMap output records=1200000000\n\t\tMap output bytes=122400000000\n\t\tMap output materialized bytes=124800065664\n\t\tInput split bytes=92112\n\t\tCombine input records=0\n\t\tCombine output records=0\n\t\tReduce input groups=1200000000\n\t\tReduce shuffle bytes=124800065664\n\t\tReduce input records=1200000000\n\t\tReduce output records=1200000000\n\t\tSpilled Records=4952759151\n\t\tShuffled Maps =10944\n\t\tFailed Shuffles=0\n\t\tMerged Map outputs=10944\n\t\tGC time elapsed (ms)=351608\n\t\tCPU time spent (ms)=14083950\n\t\tPhysical memory (bytes) snapshot=275567976448\n\t\tVirtual memory (bytes) snapshot=1861403537408\n\t\tTotal committed heap usage (bytes)=182124544000\n\tShuffle Errors\n\t\tBAD_ID=0\n\t\tCONNECTION=0\n\t\tIO_ERROR=0\n\t\tWRONG_LENGTH=0\n\t\tWRONG_MAP=0\n\t\tWRONG_REDUCE=0\n\tFile Input Format Counters \n\t\tBytes Read=120000000000\n\tFile Output Format Counters \n\t\tBytes Written=12000000000018/12/20 21:49:47 INFO terasort.TeraSort: donereal\t64m27.404s\nuser\t0m19.556s\nsys\t0m3.644s", :stdout=>"Spent 184ms computing base-splits.Spent 5ms computing TeraScheduler splits.\nComputing input splits took 189msSampling 10 splits of 912Making 12 from 100000 sampled recordsComputing parititions took 1210msSpent 1401ms computing partitions.", :status=>0}}
Exp  4, overall time taken is 64 m 27.404 s
Exp  4 termintated at 2018-12-20 22:49:47 +0100

Exp  5 started at  2018-12-20 23:07:57 +0100
Exp 5's result is {"10.158.0.1"=>{:stderr=>"18/12/20 22:07:59 INFO terasort.TeraSort: starting18/12/20 22:08:00 INFO input.FileInputFormat: Total input files to process : 2418/12/20 22:08:01 INFO client.RMProxy: Connecting to ResourceManager at node1/10.158.0.1:803218/12/20 22:08:03 INFO mapreduce.JobSubmitter: number of splits:91218/12/20 22:08:03 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces18/12/20 22:08:03 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1545343367699_000118/12/20 22:08:03 INFO impl.YarnClientImpl: Submitted application application_1545343367699_000118/12/20 22:08:03 INFO mapreduce.Job: The url to track the job: http://node1:8088/proxy/application_1545343367699_0001/18/12/20 22:08:03 INFO mapreduce.Job: Running job: job_1545343367699_000118/12/20 22:08:09 INFO mapreduce.Job: Job job_1545343367699_0001 running in uber mode : false18/12/20 22:08:09 INFO mapreduce.Job:  map 0% reduce 0%18/12/20 22:08:28 INFO mapreduce.Job:  map 1% reduce 0%18/12/20 22:08:29 INFO mapreduce.Job:  map 4% reduce 0%18/12/20 22:08:30 INFO mapreduce.Job:  map 7% reduce 0%18/12/20 22:08:35 INFO mapreduce.Job:  map 9% reduce 0%18/12/20 22:08:36 INFO mapreduce.Job:  map 10% reduce 0%18/12/20 22:08:40 INFO mapreduce.Job:  map 11% reduce 0%18/12/20 22:08:41 INFO mapreduce.Job:  map 13% reduce 0%18/12/20 22:08:42 INFO mapreduce.Job:  map 14% reduce 0%18/12/20 22:08:46 INFO mapreduce.Job:  map 17% reduce 0%18/12/20 22:08:47 INFO mapreduce.Job:  map 19% reduce 0%18/12/20 22:08:48 INFO mapreduce.Job:  map 22% reduce 0%18/12/20 22:08:54 INFO mapreduce.Job:  map 23% reduce 0%18/12/20 22:08:59 INFO mapreduce.Job:  map 24% reduce 0%18/12/20 22:09:01 INFO mapreduce.Job:  map 25% reduce 0%18/12/20 22:09:02 INFO mapreduce.Job:  map 26% reduce 0%18/12/20 22:09:03 INFO mapreduce.Job:  map 27% reduce 1%18/12/20 22:09:04 INFO mapreduce.Job:  map 28% reduce 4%18/12/20 22:09:05 INFO mapreduce.Job:  map 30% reduce 4%18/12/20 22:09:07 INFO mapreduce.Job:  map 31% reduce 4%18/12/20 22:09:08 INFO mapreduce.Job:  map 32% reduce 4%18/12/20 22:09:09 INFO mapreduce.Job:  map 32% reduce 5%18/12/20 22:09:10 INFO mapreduce.Job:  map 33% reduce 6%18/12/20 22:09:11 INFO mapreduce.Job:  map 34% reduce 6%18/12/20 22:09:12 INFO mapreduce.Job:  map 35% reduce 6%18/12/20 22:09:13 INFO mapreduce.Job:  map 36% reduce 6%18/12/20 22:09:14 INFO mapreduce.Job:  map 38% reduce 6%18/12/20 22:09:15 INFO mapreduce.Job:  map 39% reduce 6%18/12/20 22:09:16 INFO mapreduce.Job:  map 40% reduce 7%18/12/20 22:09:17 INFO mapreduce.Job:  map 42% reduce 7%18/12/20 22:09:19 INFO mapreduce.Job:  map 43% reduce 7%18/12/20 22:09:20 INFO mapreduce.Job:  map 44% reduce 7%18/12/20 22:09:21 INFO mapreduce.Job:  map 44% reduce 8%18/12/20 22:09:22 INFO mapreduce.Job:  map 46% reduce 8%18/12/20 22:09:23 INFO mapreduce.Job:  map 46% reduce 9%18/12/20 22:09:26 INFO mapreduce.Job:  map 47% reduce 9%18/12/20 22:09:29 INFO mapreduce.Job:  map 48% reduce 9%18/12/20 22:09:33 INFO mapreduce.Job:  map 49% reduce 10%18/12/20 22:09:35 INFO mapreduce.Job:  map 50% reduce 10%18/12/20 22:09:38 INFO mapreduce.Job:  map 52% reduce 10%18/12/20 22:09:40 INFO mapreduce.Job:  map 53% reduce 10%18/12/20 22:09:41 INFO mapreduce.Job:  map 54% reduce 10%18/12/20 22:09:44 INFO mapreduce.Job:  map 55% reduce 10%18/12/20 22:09:45 INFO mapreduce.Job:  map 56% reduce 10%18/12/20 22:09:46 INFO mapreduce.Job:  map 57% reduce 10%18/12/20 22:09:48 INFO mapreduce.Job:  map 58% reduce 10%18/12/20 22:09:50 INFO mapreduce.Job:  map 59% reduce 10%18/12/20 22:09:51 INFO mapreduce.Job:  map 60% reduce 11%18/12/20 22:09:52 INFO mapreduce.Job:  map 61% reduce 11%18/12/20 22:09:53 INFO mapreduce.Job:  map 62% reduce 11%18/12/20 22:09:55 INFO mapreduce.Job:  map 63% reduce 11%18/12/20 22:09:56 INFO mapreduce.Job:  map 65% reduce 11%18/12/20 22:09:58 INFO mapreduce.Job:  map 66% reduce 11%18/12/20 22:10:00 INFO mapreduce.Job:  map 67% reduce 11%18/12/20 22:10:02 INFO mapreduce.Job:  map 68% reduce 11%18/12/20 22:10:03 INFO mapreduce.Job:  map 69% reduce 12%18/12/20 22:10:05 INFO mapreduce.Job:  map 70% reduce 12%18/12/20 22:10:06 INFO mapreduce.Job:  map 71% reduce 12%18/12/20 22:10:08 INFO mapreduce.Job:  map 72% reduce 12%18/12/20 22:10:11 INFO mapreduce.Job:  map 74% reduce 12%18/12/20 22:10:12 INFO mapreduce.Job:  map 75% reduce 12%18/12/20 22:10:15 INFO mapreduce.Job:  map 76% reduce 13%18/12/20 22:10:19 INFO mapreduce.Job:  map 77% reduce 13%18/12/20 22:10:23 INFO mapreduce.Job:  map 78% reduce 13%18/12/20 22:10:28 INFO mapreduce.Job:  map 79% reduce 13%18/12/20 22:10:32 INFO mapreduce.Job:  map 80% reduce 13%18/12/20 22:10:33 INFO mapreduce.Job:  map 80% reduce 14%18/12/20 22:10:35 INFO mapreduce.Job:  map 81% reduce 14%18/12/20 22:10:39 INFO mapreduce.Job:  map 82% reduce 14%18/12/20 22:10:45 INFO mapreduce.Job:  map 83% reduce 14%18/12/20 22:10:51 INFO mapreduce.Job:  map 84% reduce 14%18/12/20 22:10:56 INFO mapreduce.Job:  map 85% reduce 14%18/12/20 22:11:00 INFO mapreduce.Job:  map 86% reduce 14%18/12/20 22:11:05 INFO mapreduce.Job:  map 87% reduce 14%18/12/20 22:11:09 INFO mapreduce.Job:  map 88% reduce 14%18/12/20 22:11:11 INFO mapreduce.Job:  map 89% reduce 14%18/12/20 22:11:16 INFO mapreduce.Job:  map 90% reduce 14%18/12/20 22:11:17 INFO mapreduce.Job:  map 91% reduce 14%18/12/20 22:11:18 INFO mapreduce.Job:  map 91% reduce 15%18/12/20 22:11:19 INFO mapreduce.Job:  map 92% reduce 15%18/12/20 22:11:22 INFO mapreduce.Job:  map 93% reduce 15%18/12/20 22:11:26 INFO mapreduce.Job:  map 94% reduce 15%18/12/20 22:11:28 INFO mapreduce.Job:  map 94% reduce 16%18/12/20 22:11:29 INFO mapreduce.Job:  map 95% reduce 16%18/12/20 22:11:34 INFO mapreduce.Job:  map 96% reduce 16%18/12/20 22:11:37 INFO mapreduce.Job:  map 97% reduce 16%18/12/20 22:11:40 INFO mapreduce.Job:  map 97% reduce 17%18/12/20 22:11:46 INFO mapreduce.Job:  map 98% reduce 17%18/12/20 22:11:49 INFO mapreduce.Job:  map 99% reduce 17%18/12/20 22:12:06 INFO mapreduce.Job:  map 100% reduce 17%18/12/20 22:12:10 INFO mapreduce.Job:  map 100% reduce 18%18/12/20 22:12:58 INFO mapreduce.Job:  map 100% reduce 19%18/12/20 22:13:43 INFO mapreduce.Job:  map 100% reduce 20%18/12/20 22:13:55 INFO mapreduce.Job:  map 100% reduce 21%18/12/20 22:14:01 INFO mapreduce.Job:  map 100% reduce 22%18/12/20 22:14:07 INFO mapreduce.Job:  map 100% reduce 23%18/12/20 22:14:22 INFO mapreduce.Job:  map 100% reduce 24%18/12/20 22:14:25 INFO mapreduce.Job:  map 100% reduce 26%18/12/20 22:14:31 INFO mapreduce.Job:  map 100% reduce 27%18/12/20 22:14:46 INFO mapreduce.Job:  map 100% reduce 28%18/12/20 22:14:59 INFO mapreduce.Job:  map 100% reduce 29%18/12/20 22:15:12 INFO mapreduce.Job:  map 100% reduce 30%18/12/20 22:15:24 INFO mapreduce.Job:  map 100% reduce 31%18/12/20 22:15:40 INFO mapreduce.Job:  map 100% reduce 32%18/12/20 22:16:04 INFO mapreduce.Job:  map 100% reduce 33%18/12/20 22:17:11 INFO mapreduce.Job:  map 100% reduce 34%18/12/20 22:17:28 INFO mapreduce.Job:  map 100% reduce 35%18/12/20 22:17:34 INFO mapreduce.Job:  map 100% reduce 36%18/12/20 22:17:40 INFO mapreduce.Job:  map 100% reduce 37%18/12/20 22:17:41 INFO mapreduce.Job:  map 100% reduce 38%18/12/20 22:17:52 INFO mapreduce.Job:  map 100% reduce 39%18/12/20 22:17:58 INFO mapreduce.Job:  map 100% reduce 40%18/12/20 22:18:04 INFO mapreduce.Job:  map 100% reduce 41%18/12/20 22:18:37 INFO mapreduce.Job:  map 100% reduce 42%18/12/20 22:19:04 INFO mapreduce.Job:  map 100% reduce 43%18/12/20 22:19:22 INFO mapreduce.Job:  map 100% reduce 44%18/12/20 22:19:34 INFO mapreduce.Job:  map 100% reduce 45%18/12/20 22:19:52 INFO mapreduce.Job:  map 100% reduce 46%18/12/20 22:20:10 INFO mapreduce.Job:  map 100% reduce 47%18/12/20 22:20:22 INFO mapreduce.Job:  map 100% reduce 48%18/12/20 22:20:55 INFO mapreduce.Job:  map 100% reduce 49%18/12/20 22:22:50 INFO mapreduce.Job:  map 100% reduce 50%18/12/20 22:24:59 INFO mapreduce.Job:  map 100% reduce 51%18/12/20 22:27:20 INFO mapreduce.Job:  map 100% reduce 52%18/12/20 22:29:30 INFO mapreduce.Job:  map 100% reduce 53%18/12/20 22:32:14 INFO mapreduce.Job:  map 100% reduce 54%18/12/20 22:35:07 INFO mapreduce.Job:  map 100% reduce 55%18/12/20 22:38:06 INFO mapreduce.Job:  map 100% reduce 56%18/12/20 22:47:08 INFO mapreduce.Job:  map 100% reduce 57%18/12/20 22:47:31 INFO mapreduce.Job:  map 100% reduce 58%18/12/20 22:47:46 INFO mapreduce.Job:  map 100% reduce 59%18/12/20 22:48:01 INFO mapreduce.Job:  map 100% reduce 60%18/12/20 22:48:14 INFO mapreduce.Job:  map 100% reduce 61%18/12/20 22:48:28 INFO mapreduce.Job:  map 100% reduce 62%18/12/20 22:48:43 INFO mapreduce.Job:  map 100% reduce 63%18/12/20 22:48:56 INFO mapreduce.Job:  map 100% reduce 64%18/12/20 22:49:13 INFO mapreduce.Job:  map 100% reduce 65%18/12/20 22:49:26 INFO mapreduce.Job:  map 100% reduce 66%18/12/20 22:49:40 INFO mapreduce.Job:  map 100% reduce 67%18/12/20 22:49:55 INFO mapreduce.Job:  map 100% reduce 68%18/12/20 22:50:08 INFO mapreduce.Job:  map 100% reduce 69%18/12/20 22:50:25 INFO mapreduce.Job:  map 100% reduce 70%18/12/20 22:50:38 INFO mapreduce.Job:  map 100% reduce 71%18/12/20 22:50:51 INFO mapreduce.Job:  map 100% reduce 72%18/12/20 22:51:07 INFO mapreduce.Job:  map 100% reduce 73%18/12/20 22:51:21 INFO mapreduce.Job:  map 100% reduce 74%18/12/20 22:51:36 INFO mapreduce.Job:  map 100% reduce 75%18/12/20 22:51:49 INFO mapreduce.Job:  map 100% reduce 76%18/12/20 22:52:06 INFO mapreduce.Job:  map 100% reduce 77%18/12/20 22:52:20 INFO mapreduce.Job:  map 100% reduce 78%18/12/20 22:54:13 INFO mapreduce.Job:  map 100% reduce 79%18/12/20 22:54:20 INFO mapreduce.Job:  map 100% reduce 80%18/12/20 22:55:07 INFO mapreduce.Job:  map 100% reduce 81%18/12/20 22:55:11 INFO mapreduce.Job: Task Id : attempt_1545343367699_0001_r_000003_0, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.9:50010,DS-acb54183-48fd-4a6c-a730-044181fe2813,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)18/12/20 22:55:12 INFO mapreduce.Job:  map 100% reduce 77%18/12/20 22:55:12 INFO mapreduce.Job: Task Id : attempt_1545343367699_0001_r_000004_0, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.9:50010,DS-acb54183-48fd-4a6c-a730-044181fe2813,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)18/12/20 22:55:13 INFO mapreduce.Job:  map 100% reduce 74%18/12/20 22:55:13 INFO mapreduce.Job: Task Id : attempt_1545343367699_0001_r_000002_0, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.9:50010,DS-acb54183-48fd-4a6c-a730-044181fe2813,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)18/12/20 22:55:14 INFO mapreduce.Job:  map 100% reduce 72%18/12/20 22:55:16 INFO mapreduce.Job: Task Id : attempt_1545343367699_0001_r_000007_0, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.9:50010,DS-acb54183-48fd-4a6c-a730-044181fe2813,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)18/12/20 22:55:17 INFO mapreduce.Job:  map 100% reduce 71%18/12/20 22:55:18 INFO mapreduce.Job: Task Id : attempt_1545343367699_0001_r_000010_0, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.9:50010,DS-acb54183-48fd-4a6c-a730-044181fe2813,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)18/12/20 22:55:19 INFO mapreduce.Job:  map 100% reduce 68%18/12/20 22:55:19 INFO mapreduce.Job: Task Id : attempt_1545343367699_0001_r_000011_0, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.9:50010,DS-acb54183-48fd-4a6c-a730-044181fe2813,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)18/12/20 22:55:19 INFO mapreduce.Job: Task Id : attempt_1545343367699_0001_r_000008_0, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.9:50010,DS-acb54183-48fd-4a6c-a730-044181fe2813,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)18/12/20 22:55:19 INFO mapreduce.Job: Task Id : attempt_1545343367699_0001_r_000009_0, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.9:50010,DS-acb54183-48fd-4a6c-a730-044181fe2813,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)18/12/20 22:55:20 INFO mapreduce.Job:  map 100% reduce 64%18/12/20 22:55:47 INFO mapreduce.Job:  map 100% reduce 65%18/12/20 22:56:28 INFO mapreduce.Job: Task Id : attempt_1545343367699_0001_r_000007_0, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.9:50010,DS-acb54183-48fd-4a6c-a730-044181fe2813,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)\n\nTask attempt attempt_1545343367699_0001_r_000007_0 is done from TaskUmbilicalProtocol's point of view. However, it stays in finishing state for too long18/12/20 22:56:28 INFO mapreduce.Job: Task Id : attempt_1545343367699_0001_r_000009_0, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.9:50010,DS-acb54183-48fd-4a6c-a730-044181fe2813,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)\n\nTask attempt attempt_1545343367699_0001_r_000009_0 is done from TaskUmbilicalProtocol's point of view. However, it stays in finishing state for too long18/12/20 22:56:28 INFO mapreduce.Job: Task Id : attempt_1545343367699_0001_r_000004_0, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.9:50010,DS-acb54183-48fd-4a6c-a730-044181fe2813,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)\n\nTask attempt attempt_1545343367699_0001_r_000004_0 is done from TaskUmbilicalProtocol's point of view. However, it stays in finishing state for too long18/12/20 22:56:28 INFO mapreduce.Job: Task Id : attempt_1545343367699_0001_r_000008_0, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.9:50010,DS-acb54183-48fd-4a6c-a730-044181fe2813,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)\n\nTask attempt attempt_1545343367699_0001_r_000008_0 is done from TaskUmbilicalProtocol's point of view. However, it stays in finishing state for too long18/12/20 22:56:28 INFO mapreduce.Job: Task Id : attempt_1545343367699_0001_r_000003_0, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.9:50010,DS-acb54183-48fd-4a6c-a730-044181fe2813,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)\n\nTask attempt attempt_1545343367699_0001_r_000003_0 is done from TaskUmbilicalProtocol's point of view. However, it stays in finishing state for too long18/12/20 22:56:28 INFO mapreduce.Job: Task Id : attempt_1545343367699_0001_r_000011_0, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.9:50010,DS-acb54183-48fd-4a6c-a730-044181fe2813,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)\n\nTask attempt attempt_1545343367699_0001_r_000011_0 is done from TaskUmbilicalProtocol's point of view. However, it stays in finishing state for too long18/12/20 22:56:28 INFO mapreduce.Job: Task Id : attempt_1545343367699_0001_r_000002_0, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.9:50010,DS-acb54183-48fd-4a6c-a730-044181fe2813,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)Task attempt attempt_1545343367699_0001_r_000002_0 is done from TaskUmbilicalProtocol's point of view. However, it stays in finishing state for too long18/12/20 22:56:28 INFO mapreduce.Job: Task Id : attempt_1545343367699_0001_r_000010_0, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.9:50010,DS-acb54183-48fd-4a6c-a730-044181fe2813,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)\n\nTask attempt attempt_1545343367699_0001_r_000010_0 is done from TaskUmbilicalProtocol's point of view. However, it stays in finishing state for too long18/12/20 22:56:32 INFO mapreduce.Job:  map 100% reduce 66%18/12/20 22:57:13 INFO mapreduce.Job:  map 100% reduce 67%18/12/20 22:57:46 INFO mapreduce.Job:  map 100% reduce 68%18/12/20 22:58:46 INFO mapreduce.Job:  map 100% reduce 69%18/12/20 22:59:37 INFO mapreduce.Job:  map 100% reduce 70%18/12/20 23:00:10 INFO mapreduce.Job:  map 100% reduce 71%18/12/20 23:00:29 INFO mapreduce.Job:  map 100% reduce 72%18/12/20 23:00:50 INFO mapreduce.Job:  map 100% reduce 73%18/12/20 23:01:08 INFO mapreduce.Job:  map 100% reduce 74%18/12/20 23:01:29 INFO mapreduce.Job:  map 100% reduce 75%18/12/20 23:01:53 INFO mapreduce.Job:  map 100% reduce 76%18/12/20 23:02:17 INFO mapreduce.Job:  map 100% reduce 77%18/12/20 23:02:41 INFO mapreduce.Job:  map 100% reduce 78%18/12/20 23:02:56 INFO mapreduce.Job:  map 100% reduce 79%18/12/20 23:03:02 INFO mapreduce.Job:  map 100% reduce 80%18/12/20 23:03:17 INFO mapreduce.Job:  map 100% reduce 81%18/12/20 23:03:29 INFO mapreduce.Job:  map 100% reduce 82%18/12/20 23:03:41 INFO mapreduce.Job:  map 100% reduce 83%18/12/20 23:03:50 INFO mapreduce.Job:  map 100% reduce 84%18/12/20 23:04:02 INFO mapreduce.Job:  map 100% reduce 85%18/12/20 23:04:13 INFO mapreduce.Job:  map 100% reduce 86%18/12/20 23:04:23 INFO mapreduce.Job:  map 100% reduce 87%18/12/20 23:04:37 INFO mapreduce.Job:  map 100% reduce 88%18/12/20 23:04:39 INFO mapreduce.Job: Task Id : attempt_1545343367699_0001_r_000002_1, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.2:50010,DS-b6a9e2e4-d657-430f-836d-51c626e4512c,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)18/12/20 23:04:40 INFO mapreduce.Job:  map 100% reduce 83%18/12/20 23:04:40 INFO mapreduce.Job: Task Id : attempt_1545343367699_0001_r_000008_1, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.2:50010,DS-b6a9e2e4-d657-430f-836d-51c626e4512c,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)18/12/20 23:04:41 INFO mapreduce.Job:  map 100% reduce 77%18/12/20 23:04:46 INFO mapreduce.Job: Task Id : attempt_1545343367699_0001_r_000004_1, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.2:50010,DS-b6a9e2e4-d657-430f-836d-51c626e4512c,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)18/12/20 23:04:47 INFO mapreduce.Job:  map 100% reduce 73%18/12/20 23:04:47 INFO mapreduce.Job: Task Id : attempt_1545343367699_0001_r_000009_1, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.2:50010,DS-b6a9e2e4-d657-430f-836d-51c626e4512c,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)18/12/20 23:04:48 INFO mapreduce.Job: Task Id : attempt_1545343367699_0001_r_000010_1, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.2:50010,DS-b6a9e2e4-d657-430f-836d-51c626e4512c,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)18/12/20 23:04:49 INFO mapreduce.Job:  map 100% reduce 70%18/12/20 23:04:49 INFO mapreduce.Job: Task Id : attempt_1545343367699_0001_r_000007_1, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.2:50010,DS-b6a9e2e4-d657-430f-836d-51c626e4512c,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)18/12/20 23:04:50 INFO mapreduce.Job:  map 100% reduce 65%18/12/20 23:04:50 INFO mapreduce.Job: Task Id : attempt_1545343367699_0001_r_000003_1, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.2:50010,DS-b6a9e2e4-d657-430f-836d-51c626e4512c,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)18/12/20 23:04:50 INFO mapreduce.Job: Task Id : attempt_1545343367699_0001_r_000011_1, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.2:50010,DS-b6a9e2e4-d657-430f-836d-51c626e4512c,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)18/12/20 23:04:51 INFO mapreduce.Job:  map 100% reduce 59%18/12/20 23:05:48 INFO mapreduce.Job: Task Id : attempt_1545343367699_0001_r_000009_1, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.2:50010,DS-b6a9e2e4-d657-430f-836d-51c626e4512c,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)\n\nTask attempt attempt_1545343367699_0001_r_000009_1 is done from TaskUmbilicalProtocol's point of view. However, it stays in finishing state for too long18/12/20 23:05:48 INFO mapreduce.Job: Task Id : attempt_1545343367699_0001_r_000002_1, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.2:50010,DS-b6a9e2e4-d657-430f-836d-51c626e4512c,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)\n\nTask attempt attempt_1545343367699_0001_r_000002_1 is done from TaskUmbilicalProtocol's point of view. However, it stays in finishing state for too long18/12/20 23:05:48 INFO mapreduce.Job: Task Id : attempt_1545343367699_0001_r_000004_1, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.2:50010,DS-b6a9e2e4-d657-430f-836d-51c626e4512c,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)\n\nTask attempt attempt_1545343367699_0001_r_000004_1 is done from TaskUmbilicalProtocol's point of view. However, it stays in finishing state for too long18/12/20 23:06:08 INFO mapreduce.Job: Task Id : attempt_1545343367699_0001_r_000007_1, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.2:50010,DS-b6a9e2e4-d657-430f-836d-51c626e4512c,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)\n\nTask attempt attempt_1545343367699_0001_r_000007_1 is done from TaskUmbilicalProtocol's point of view. However, it stays in finishing state for too long18/12/20 23:06:08 INFO mapreduce.Job: Task Id : attempt_1545343367699_0001_r_000010_1, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.2:50010,DS-b6a9e2e4-d657-430f-836d-51c626e4512c,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)\n\nTask attempt attempt_1545343367699_0001_r_000010_1 is done from TaskUmbilicalProtocol's point of view. However, it stays in finishing state for too long18/12/20 23:06:08 INFO mapreduce.Job: Task Id : attempt_1545343367699_0001_r_000003_1, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.2:50010,DS-b6a9e2e4-d657-430f-836d-51c626e4512c,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)\n\nTask attempt attempt_1545343367699_0001_r_000003_1 is done from TaskUmbilicalProtocol's point of view. However, it stays in finishing state for too long18/12/20 23:06:33 INFO mapreduce.Job:  map 100% reduce 60%18/12/20 23:08:46 INFO mapreduce.Job:  map 100% reduce 61%18/12/20 23:10:57 INFO mapreduce.Job:  map 100% reduce 62%18/12/20 23:17:11 INFO mapreduce.Job:  map 100% reduce 63%18/12/20 23:24:58 INFO mapreduce.Job:  map 100% reduce 64%18/12/20 23:35:54 INFO mapreduce.Job:  map 100% reduce 65%18/12/20 23:46:31 INFO mapreduce.Job:  map 100% reduce 66%18/12/21 00:06:01 INFO mapreduce.Job:  map 100% reduce 67%18/12/21 00:13:19 INFO mapreduce.Job:  map 100% reduce 68%18/12/21 00:17:49 INFO mapreduce.Job:  map 100% reduce 69%18/12/21 00:20:38 INFO mapreduce.Job:  map 100% reduce 70%18/12/21 00:23:26 INFO mapreduce.Job:  map 100% reduce 71%18/12/21 00:25:49 INFO mapreduce.Job:  map 100% reduce 72%18/12/21 00:27:56 INFO mapreduce.Job:  map 100% reduce 73%18/12/21 00:30:09 INFO mapreduce.Job:  map 100% reduce 74%18/12/21 00:32:45 INFO mapreduce.Job:  map 100% reduce 75%18/12/21 00:35:21 INFO mapreduce.Job:  map 100% reduce 76%18/12/21 00:37:56 INFO mapreduce.Job:  map 100% reduce 77%18/12/21 00:39:54 INFO mapreduce.Job: Task Id : attempt_1545343367699_0001_r_000004_2, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.18:50010,DS-f92aaacb-2a61-42e1-bc16-9e0ae4457e28,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)18/12/21 00:39:55 INFO mapreduce.Job:  map 100% reduce 73%18/12/21 00:40:01 INFO mapreduce.Job:  map 100% reduce 74%18/12/21 00:41:31 INFO mapreduce.Job:  map 100% reduce 75%18/12/21 00:44:01 INFO mapreduce.Job:  map 100% reduce 77%18/12/21 00:44:07 INFO mapreduce.Job:  map 100% reduce 78%18/12/21 00:44:19 INFO mapreduce.Job:  map 100% reduce 79%18/12/21 00:44:43 INFO mapreduce.Job:  map 100% reduce 80%18/12/21 00:45:07 INFO mapreduce.Job:  map 100% reduce 81%18/12/21 00:45:32 INFO mapreduce.Job:  map 100% reduce 82%18/12/21 00:47:26 INFO mapreduce.Job:  map 100% reduce 83%18/12/21 00:50:08 INFO mapreduce.Job:  map 100% reduce 84%18/12/21 00:52:38 INFO mapreduce.Job:  map 100% reduce 85%18/12/21 00:54:20 INFO mapreduce.Job:  map 100% reduce 86%18/12/21 00:56:09 INFO mapreduce.Job:  map 100% reduce 87%18/12/21 00:57:51 INFO mapreduce.Job:  map 100% reduce 88%18/12/21 01:01:15 INFO mapreduce.Job:  map 100% reduce 89%18/12/21 01:05:09 INFO mapreduce.Job:  map 100% reduce 90%18/12/21 01:07:15 INFO mapreduce.Job:  map 100% reduce 91%18/12/21 01:09:21 INFO mapreduce.Job:  map 100% reduce 92%18/12/21 01:09:32 INFO mapreduce.Job: Task Id : attempt_1545343367699_0001_r_000011_2, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.18:50010,DS-f92aaacb-2a61-42e1-bc16-9e0ae4457e28,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)18/12/21 01:09:33 INFO mapreduce.Job:  map 100% reduce 89%18/12/21 01:09:33 INFO mapreduce.Job: Task Id : attempt_1545343367699_0001_r_000002_2, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.18:50010,DS-f92aaacb-2a61-42e1-bc16-9e0ae4457e28,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)18/12/21 01:09:34 INFO mapreduce.Job:  map 100% reduce 84%18/12/21 01:09:36 INFO mapreduce.Job: Task Id : attempt_1545343367699_0001_r_000010_2, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.18:50010,DS-f92aaacb-2a61-42e1-bc16-9e0ae4457e28,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)18/12/21 01:09:37 INFO mapreduce.Job:  map 100% reduce 80%18/12/21 01:09:38 INFO mapreduce.Job: Task Id : attempt_1545343367699_0001_r_000007_2, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.18:50010,DS-f92aaacb-2a61-42e1-bc16-9e0ae4457e28,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)18/12/21 01:09:39 INFO mapreduce.Job:  map 100% reduce 76%18/12/21 01:09:43 INFO mapreduce.Job: Task Id : attempt_1545343367699_0001_r_000008_2, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.18:50010,DS-f92aaacb-2a61-42e1-bc16-9e0ae4457e28,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)18/12/21 01:09:44 INFO mapreduce.Job:  map 100% reduce 73%18/12/21 01:10:49 INFO mapreduce.Job: Task Id : attempt_1545343367699_0001_r_000007_2, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.18:50010,DS-f92aaacb-2a61-42e1-bc16-9e0ae4457e28,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)\n\nTask attempt attempt_1545343367699_0001_r_000007_2 is done from TaskUmbilicalProtocol's point of view. However, it stays in finishing state for too long18/12/21 01:10:49 INFO mapreduce.Job: Task Id : attempt_1545343367699_0001_r_000002_2, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.18:50010,DS-f92aaacb-2a61-42e1-bc16-9e0ae4457e28,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)\n\nTask attempt attempt_1545343367699_0001_r_000002_2 is done from TaskUmbilicalProtocol's point of view. However, it stays in finishing state for too long18/12/21 01:10:49 INFO mapreduce.Job: Task Id : attempt_1545343367699_0001_r_000008_2, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.18:50010,DS-f92aaacb-2a61-42e1-bc16-9e0ae4457e28,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)\n\nTask attempt attempt_1545343367699_0001_r_000008_2 is done from TaskUmbilicalProtocol's point of view. However, it stays in finishing state for too long18/12/21 01:10:49 INFO mapreduce.Job: Task Id : attempt_1545343367699_0001_r_000011_2, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.18:50010,DS-f92aaacb-2a61-42e1-bc16-9e0ae4457e28,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)Task attempt attempt_1545343367699_0001_r_000011_2 is done from TaskUmbilicalProtocol's point of view. However, it stays in finishing state for too long18/12/21 01:10:49 INFO mapreduce.Job: Task Id : attempt_1545343367699_0001_r_000010_2, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.18:50010,DS-f92aaacb-2a61-42e1-bc16-9e0ae4457e28,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)Task attempt attempt_1545343367699_0001_r_000010_2 is done from TaskUmbilicalProtocol's point of view. However, it stays in finishing state for too long18/12/21 01:13:48 INFO mapreduce.Job:  map 100% reduce 75%18/12/21 01:14:24 INFO mapreduce.Job:  map 100% reduce 76%18/12/21 01:14:39 INFO mapreduce.Job:  map 100% reduce 100%18/12/21 01:14:41 INFO mapreduce.Job: Job job_1545343367699_0001 failed with state FAILED due to: Task failed task_1545343367699_0001_r_000008\nJob failed as tasks failed. failedMaps:0 failedReduces:118/12/21 01:14:41 INFO mapreduce.Job: Counters: 53\n\tFile System Counters\n\t\tFILE: Number of bytes read=277467292646\n\t\tFILE: Number of bytes written=402373613173\n\t\tFILE: Number of read operations=0\n\t\tFILE: Number of large read operations=0\n\t\tFILE: Number of write operations=0\n\t\tHDFS: Number of bytes read=120000092112\n\t\tHDFS: Number of bytes written=69744217800\n\t\tHDFS: Number of read operations=2757\n\t\tHDFS: Number of large read operations=0\n\t\tHDFS: Number of write operations=14\n\tJob Counters \n\t\tFailed reduce tasks=43\n\t\tKilled map tasks=3\n\t\tKilled reduce tasks=9\n\t\tLaunched map tasks=913\n\t\tLaunched reduce tasks=40\n\t\tData-local map tasks=871\n\t\tRack-local map tasks=42\n\t\tTotal time spent by all maps in occupied slots (ms)=40086547\n\t\tTotal time spent by all reduces in occupied slots (ms)=222994304\n\t\tTotal time spent by all map tasks (ms)=40086547\n\t\tTotal time spent by all reduce tasks (ms)=222994304\n\t\tTotal vcore-milliseconds taken by all map tasks=40086547\n\t\tTotal vcore-milliseconds taken by all reduce tasks=222994304\n\t\tTotal megabyte-milliseconds taken by all map tasks=41048624128\n\t\tTotal megabyte-milliseconds taken by all reduce tasks=228346167296\n\tMap-Reduce Framework\n\t\tMap input records=1200000000\n\t\tMap output records=1200000000\n\t\tMap output bytes=122400000000\n\t\tMap output materialized bytes=124800065664\n\t\tInput split bytes=92112\n\t\tCombine input records=0\n\t\tCombine output records=0\n\t\tReduce input groups=697442178\n\t\tReduce shuffle bytes=72534024816\n\t\tReduce input records=697442178\n\t\tReduce output records=697442178\n\t\tSpilled Records=3867569622\n\t\tShuffled Maps =6384\n\t\tFailed Shuffles=0\n\t\tMerged Map outputs=6384\n\t\tGC time elapsed (ms)=261062\n\t\tCPU time spent (ms)=11635690\n\t\tPhysical memory (bytes) snapshot=273702633472\n\t\tVirtual memory (bytes) snapshot=1851316756480\n\t\tTotal committed heap usage (bytes)=181040840704\n\tShuffle Errors\n\t\tBAD_ID=0\n\t\tCONNECTION=0\n\t\tIO_ERROR=0\n\t\tWRONG_LENGTH=0\n\t\tWRONG_MAP=0\n\t\tWRONG_REDUCE=0\n\tFile Input Format Counters \n\t\tBytes Read=120000000000\n\tFile Output Format Counters \n\t\tBytes Written=6974421780018/12/21 01:14:41 INFO terasort.TeraSort: donereal\t186m42.861s\nuser\t0m25.939s\nsys\t0m8.847s", :stdout=>"Spent 185ms computing base-splits.Spent 5ms computing TeraScheduler splits.Computing input splits took 191msSampling 10 splits of 912Making 12 from 100000 sampled recordsComputing parititions took 1257msSpent 1450ms computing partitions.", :status=>1}}
Exp  5, overall time taken is 186 m 42.861 s
Exp  5 termintated at 2018-12-21 02:14:42 +0100

