Exp  1 started at  2018-12-13 01:43:59 +0100
Exp 1's result is {"10.158.0.1"=>{:stderr=>"18/12/13 00:44:53 INFO terasort.TeraSort: starting18/12/13 00:44:54 INFO input.FileInputFormat: Total input files to process : 2318/12/13 00:44:56 INFO client.RMProxy: Connecting to ResourceManager at node1/10.158.0.1:803218/12/13 00:44:57 INFO mapreduce.JobSubmitter: number of splits:87418/12/13 00:44:57 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces18/12/13 00:44:58 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1544661638415_000118/12/13 00:44:59 INFO impl.YarnClientImpl: Submitted application application_1544661638415_000118/12/13 00:44:59 INFO mapreduce.Job: The url to track the job: http://node1:8088/proxy/application_1544661638415_0001/18/12/13 00:44:59 INFO mapreduce.Job: Running job: job_1544661638415_000118/12/13 00:45:05 INFO mapreduce.Job: Job job_1544661638415_0001 running in uber mode : false18/12/13 00:45:05 INFO mapreduce.Job:  map 0% reduce 0%18/12/13 00:45:24 INFO mapreduce.Job:  map 9% reduce 0%18/12/13 00:45:25 INFO mapreduce.Job:  map 17% reduce 0%18/12/13 00:45:26 INFO mapreduce.Job:  map 24% reduce 0%18/12/13 00:45:27 INFO mapreduce.Job:  map 28% reduce 0%18/12/13 00:45:28 INFO mapreduce.Job:  map 31% reduce 0%18/12/13 00:45:34 INFO mapreduce.Job:  map 32% reduce 0%18/12/13 00:45:37 INFO mapreduce.Job:  map 33% reduce 0%18/12/13 00:45:38 INFO mapreduce.Job:  map 35% reduce 0%18/12/13 00:45:39 INFO mapreduce.Job:  map 37% reduce 0%18/12/13 00:45:40 INFO mapreduce.Job:  map 39% reduce 0%18/12/13 00:45:41 INFO mapreduce.Job:  map 41% reduce 0%18/12/13 00:45:42 INFO mapreduce.Job:  map 46% reduce 0%18/12/13 00:45:43 INFO mapreduce.Job:  map 54% reduce 4%18/12/13 00:45:44 INFO mapreduce.Job:  map 59% reduce 4%18/12/13 00:45:45 INFO mapreduce.Job:  map 60% reduce 4%18/12/13 00:45:46 INFO mapreduce.Job:  map 61% reduce 4%18/12/13 00:45:47 INFO mapreduce.Job:  map 62% reduce 4%18/12/13 00:45:49 INFO mapreduce.Job:  map 63% reduce 6%18/12/13 00:45:51 INFO mapreduce.Job:  map 64% reduce 6%18/12/13 00:45:52 INFO mapreduce.Job:  map 66% reduce 6%18/12/13 00:45:53 INFO mapreduce.Job:  map 69% reduce 6%18/12/13 00:45:54 INFO mapreduce.Job:  map 72% reduce 6%18/12/13 00:45:55 INFO mapreduce.Job:  map 74% reduce 8%18/12/13 00:45:57 INFO mapreduce.Job:  map 80% reduce 8%18/12/13 00:45:58 INFO mapreduce.Job:  map 84% reduce 8%18/12/13 00:45:59 INFO mapreduce.Job:  map 85% reduce 8%18/12/13 00:46:00 INFO mapreduce.Job:  map 90% reduce 8%18/12/13 00:46:01 INFO mapreduce.Job:  map 93% reduce 10%18/12/13 00:46:02 INFO mapreduce.Job:  map 96% reduce 10%18/12/13 00:46:03 INFO mapreduce.Job:  map 97% reduce 10%18/12/13 00:46:04 INFO mapreduce.Job:  map 98% reduce 10%18/12/13 00:46:05 INFO mapreduce.Job:  map 99% reduce 10%18/12/13 00:46:06 INFO mapreduce.Job:  map 100% reduce 10%18/12/13 00:46:07 INFO mapreduce.Job:  map 100% reduce 13%18/12/13 00:46:13 INFO mapreduce.Job:  map 100% reduce 15%18/12/13 00:46:19 INFO mapreduce.Job:  map 100% reduce 18%18/12/13 00:46:25 INFO mapreduce.Job:  map 100% reduce 20%18/12/13 00:46:31 INFO mapreduce.Job:  map 100% reduce 23%18/12/13 00:46:37 INFO mapreduce.Job:  map 100% reduce 26%18/12/13 00:46:43 INFO mapreduce.Job:  map 100% reduce 28%18/12/13 00:46:49 INFO mapreduce.Job:  map 100% reduce 30%18/12/13 00:46:56 INFO mapreduce.Job:  map 100% reduce 31%18/12/13 00:47:20 INFO mapreduce.Job:  map 100% reduce 32%18/12/13 00:47:26 INFO mapreduce.Job:  map 100% reduce 33%18/12/13 00:47:31 INFO mapreduce.Job:  map 100% reduce 34%18/12/13 00:47:32 INFO mapreduce.Job:  map 100% reduce 38%18/12/13 00:47:38 INFO mapreduce.Job:  map 100% reduce 43%18/12/13 00:47:43 INFO mapreduce.Job:  map 100% reduce 44%18/12/13 00:47:44 INFO mapreduce.Job:  map 100% reduce 50%18/12/13 00:47:50 INFO mapreduce.Job:  map 100% reduce 55%18/12/13 00:47:56 INFO mapreduce.Job:  map 100% reduce 57%18/12/13 00:48:01 INFO mapreduce.Job:  map 100% reduce 58%18/12/13 00:48:02 INFO mapreduce.Job:  map 100% reduce 59%18/12/13 00:48:07 INFO mapreduce.Job:  map 100% reduce 60%18/12/13 00:48:08 INFO mapreduce.Job:  map 100% reduce 61%18/12/13 00:48:14 INFO mapreduce.Job:  map 100% reduce 62%18/12/13 00:48:19 INFO mapreduce.Job:  map 100% reduce 63%18/12/13 00:48:20 INFO mapreduce.Job:  map 100% reduce 64%18/12/13 00:48:25 INFO mapreduce.Job:  map 100% reduce 65%18/12/13 00:48:26 INFO mapreduce.Job:  map 100% reduce 66%18/12/13 00:48:32 INFO mapreduce.Job:  map 100% reduce 67%18/12/13 00:48:37 INFO mapreduce.Job:  map 100% reduce 68%18/12/13 00:48:38 INFO mapreduce.Job:  map 100% reduce 69%18/12/13 00:48:43 INFO mapreduce.Job:  map 100% reduce 70%18/12/13 00:48:49 INFO mapreduce.Job:  map 100% reduce 71%18/12/13 00:48:50 INFO mapreduce.Job:  map 100% reduce 72%18/12/13 00:48:56 INFO mapreduce.Job:  map 100% reduce 73%18/12/13 00:49:01 INFO mapreduce.Job:  map 100% reduce 74%18/12/13 00:49:02 INFO mapreduce.Job:  map 100% reduce 75%18/12/13 00:49:07 INFO mapreduce.Job:  map 100% reduce 76%18/12/13 00:49:13 INFO mapreduce.Job:  map 100% reduce 77%18/12/13 00:49:14 INFO mapreduce.Job:  map 100% reduce 78%18/12/13 00:49:19 INFO mapreduce.Job:  map 100% reduce 79%18/12/13 00:49:25 INFO mapreduce.Job:  map 100% reduce 80%18/12/13 00:49:31 INFO mapreduce.Job:  map 100% reduce 81%18/12/13 00:49:37 INFO mapreduce.Job:  map 100% reduce 82%18/12/13 00:49:43 INFO mapreduce.Job:  map 100% reduce 83%18/12/13 00:49:49 INFO mapreduce.Job:  map 100% reduce 84%18/12/13 00:49:55 INFO mapreduce.Job:  map 100% reduce 86%18/12/13 00:50:01 INFO mapreduce.Job:  map 100% reduce 87%18/12/13 00:50:07 INFO mapreduce.Job:  map 100% reduce 88%18/12/13 00:50:13 INFO mapreduce.Job:  map 100% reduce 89%18/12/13 00:50:19 INFO mapreduce.Job:  map 100% reduce 90%18/12/13 00:50:25 INFO mapreduce.Job:  map 100% reduce 91%18/12/13 00:50:37 INFO mapreduce.Job:  map 100% reduce 92%18/12/13 00:50:55 INFO mapreduce.Job:  map 100% reduce 93%18/12/13 00:51:13 INFO mapreduce.Job:  map 100% reduce 94%18/12/13 00:51:37 INFO mapreduce.Job:  map 100% reduce 95%18/12/13 00:51:55 INFO mapreduce.Job:  map 100% reduce 96%18/12/13 00:52:14 INFO mapreduce.Job:  map 100% reduce 97%18/12/13 00:52:38 INFO mapreduce.Job:  map 100% reduce 98%18/12/13 00:52:56 INFO mapreduce.Job:  map 100% reduce 99%18/12/13 00:53:14 INFO mapreduce.Job:  map 100% reduce 100%18/12/13 00:53:25 INFO mapreduce.Job: Job job_1544661638415_0001 completed successfully18/12/13 00:53:25 INFO mapreduce.Job: Counters: 52\n\tFile System Counters\n\t\tFILE: Number of bytes read=382425805068\n\t\tFILE: Number of bytes written=502131999880\n\t\tFILE: Number of read operations=0\n\t\tFILE: Number of large read operations=0\n\t\tFILE: Number of write operations=0\n\t\tHDFS: Number of bytes read=115000088274\n\t\tHDFS: Number of bytes written=115000000000\n\t\tHDFS: Number of read operations=2655\n\t\tHDFS: Number of large read operations=0\n\t\tHDFS: Number of write operations=22\n\tJob Counters \n\t\tKilled map tasks=1\n\t\tKilled reduce tasks=3\n\t\tLaunched map tasks=875\n\t\tLaunched reduce tasks=14\n\t\tData-local map tasks=867\n\t\tRack-local map tasks=8\n\t\tTotal time spent by all maps in occupied slots (ms)=12468278\n\t\tTotal time spent by all reduces in occupied slots (ms)=4029864\n\t\tTotal time spent by all map tasks (ms)=12468278\n\t\tTotal time spent by all reduce tasks (ms)=4029864\n\t\tTotal vcore-milliseconds taken by all map tasks=12468278\n\t\tTotal vcore-milliseconds taken by all reduce tasks=4029864\n\t\tTotal megabyte-milliseconds taken by all map tasks=12767516672\n\t\tTotal megabyte-milliseconds taken by all reduce tasks=4126580736\n\tMap-Reduce Framework\n\t\tMap input records=1150000000\n\t\tMap output records=1150000000\n\t\tMap output bytes=117300000000\n\t\tMap output materialized bytes=119600057684\n\t\tInput split bytes=88274\n\t\tCombine input records=0\n\t\tCombine output records=0\n\t\tReduce input groups=1150000000\n\t\tReduce shuffle bytes=119600057684\n\t\tReduce input records=1150000000\n\t\tReduce output records=1150000000\n\t\tSpilled Records=4826837284\n\t\tShuffled Maps =9614\n\t\tFailed Shuffles=0\n\t\tMerged Map outputs=9614\n\t\tGC time elapsed (ms)=354241\n\t\tCPU time spent (ms)=13369700\n\t\tPhysical memory (bytes) snapshot=264614977536\n\t\tVirtual memory (bytes) snapshot=1782914179072\n\t\tTotal committed heap usage (bytes)=174657110016\n\tShuffle Errors\n\t\tBAD_ID=0\n\t\tCONNECTION=0\n\t\tIO_ERROR=0\n\t\tWRONG_LENGTH=0\n\t\tWRONG_MAP=0\n\t\tWRONG_REDUCE=0\n\tFile Input Format Counters \n\t\tBytes Read=115000000000\n\tFile Output Format Counters \n\t\tBytes Written=11500000000018/12/13 00:53:25 INFO terasort.TeraSort: donereal\t8m32.494s\nuser\t0m11.958s\nsys\t0m1.172s", :stdout=>"Spent 191ms computing base-splits.Spent 4ms computing TeraScheduler splits.\nComputing input splits took 196msSampling 10 splits of 874Making 11 from 100000 sampled recordsComputing parititions took 1724msSpent 1923ms computing partitions.", :status=>0}}
Exp  1, overall time taken is 8 m 32.494 s
Exp  1 termintated at 2018-12-13 01:53:25 +0100

Exp  2 started at  2018-12-13 02:03:22 +0100
Exp 2's result is {"10.158.0.1"=>{:stderr=>"18/12/13 01:04:16 INFO terasort.TeraSort: starting18/12/13 01:04:17 INFO input.FileInputFormat: Total input files to process : 2318/12/13 01:04:19 INFO client.RMProxy: Connecting to ResourceManager at node1/10.158.0.1:803218/12/13 01:04:21 INFO mapreduce.JobSubmitter: number of splits:87418/12/13 01:04:21 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces18/12/13 01:04:22 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1544662799784_000118/12/13 01:04:22 INFO impl.YarnClientImpl: Submitted application application_1544662799784_000118/12/13 01:04:22 INFO mapreduce.Job: The url to track the job: http://node1:8088/proxy/application_1544662799784_0001/18/12/13 01:04:22 INFO mapreduce.Job: Running job: job_1544662799784_000118/12/13 01:04:28 INFO mapreduce.Job: Job job_1544662799784_0001 running in uber mode : false18/12/13 01:04:28 INFO mapreduce.Job:  map 0% reduce 0%18/12/13 01:04:46 INFO mapreduce.Job:  map 1% reduce 0%18/12/13 01:04:47 INFO mapreduce.Job:  map 9% reduce 0%18/12/13 01:04:48 INFO mapreduce.Job:  map 18% reduce 0%18/12/13 01:04:49 INFO mapreduce.Job:  map 21% reduce 0%18/12/13 01:04:50 INFO mapreduce.Job:  map 25% reduce 0%18/12/13 01:04:52 INFO mapreduce.Job:  map 26% reduce 0%18/12/13 01:04:53 INFO mapreduce.Job:  map 27% reduce 0%18/12/13 01:04:54 INFO mapreduce.Job:  map 29% reduce 0%18/12/13 01:04:55 INFO mapreduce.Job:  map 30% reduce 0%18/12/13 01:05:00 INFO mapreduce.Job:  map 31% reduce 0%18/12/13 01:05:02 INFO mapreduce.Job:  map 32% reduce 0%18/12/13 01:05:03 INFO mapreduce.Job:  map 34% reduce 0%18/12/13 01:05:04 INFO mapreduce.Job:  map 36% reduce 0%18/12/13 01:05:05 INFO mapreduce.Job:  map 39% reduce 0%18/12/13 01:05:06 INFO mapreduce.Job:  map 44% reduce 0%18/12/13 01:05:07 INFO mapreduce.Job:  map 49% reduce 2%18/12/13 01:05:08 INFO mapreduce.Job:  map 52% reduce 4%18/12/13 01:05:09 INFO mapreduce.Job:  map 53% reduce 4%18/12/13 01:05:10 INFO mapreduce.Job:  map 56% reduce 4%18/12/13 01:05:11 INFO mapreduce.Job:  map 57% reduce 4%18/12/13 01:05:12 INFO mapreduce.Job:  map 58% reduce 4%18/12/13 01:05:15 INFO mapreduce.Job:  map 60% reduce 6%18/12/13 01:05:16 INFO mapreduce.Job:  map 61% reduce 6%18/12/13 01:05:17 INFO mapreduce.Job:  map 63% reduce 6%18/12/13 01:05:18 INFO mapreduce.Job:  map 66% reduce 6%18/12/13 01:05:19 INFO mapreduce.Job:  map 69% reduce 6%18/12/13 01:05:20 INFO mapreduce.Job:  map 72% reduce 6%18/12/13 01:05:21 INFO mapreduce.Job:  map 77% reduce 8%18/12/13 01:05:22 INFO mapreduce.Job:  map 78% reduce 8%18/12/13 01:05:23 INFO mapreduce.Job:  map 80% reduce 8%18/12/13 01:05:24 INFO mapreduce.Job:  map 82% reduce 8%18/12/13 01:05:25 INFO mapreduce.Job:  map 84% reduce 8%18/12/13 01:05:26 INFO mapreduce.Job:  map 87% reduce 8%18/12/13 01:05:27 INFO mapreduce.Job:  map 88% reduce 10%18/12/13 01:05:28 INFO mapreduce.Job:  map 89% reduce 10%18/12/13 01:05:29 INFO mapreduce.Job:  map 90% reduce 10%18/12/13 01:05:30 INFO mapreduce.Job:  map 91% reduce 10%18/12/13 01:05:31 INFO mapreduce.Job:  map 92% reduce 10%18/12/13 01:05:32 INFO mapreduce.Job:  map 93% reduce 10%18/12/13 01:05:33 INFO mapreduce.Job:  map 94% reduce 12%18/12/13 01:05:35 INFO mapreduce.Job:  map 95% reduce 12%18/12/13 01:05:37 INFO mapreduce.Job:  map 96% reduce 12%18/12/13 01:05:39 INFO mapreduce.Job:  map 96% reduce 15%18/12/13 01:05:45 INFO mapreduce.Job:  map 96% reduce 17%18/12/13 01:05:51 INFO mapreduce.Job:  map 96% reduce 19%18/12/13 01:05:57 INFO mapreduce.Job:  map 96% reduce 20%18/12/13 01:06:03 INFO mapreduce.Job:  map 96% reduce 22%18/12/13 01:06:09 INFO mapreduce.Job:  map 96% reduce 23%18/12/13 01:06:15 INFO mapreduce.Job:  map 96% reduce 24%18/12/13 01:06:27 INFO mapreduce.Job:  map 96% reduce 25%18/12/13 01:06:45 INFO mapreduce.Job:  map 96% reduce 26%18/12/13 01:07:09 INFO mapreduce.Job:  map 96% reduce 27%18/12/13 01:07:38 INFO mapreduce.Job:  map 96% reduce 28%18/12/13 01:08:08 INFO mapreduce.Job:  map 96% reduce 29%18/12/13 01:08:57 INFO mapreduce.Job:  map 96% reduce 30%18/12/13 01:09:24 INFO mapreduce.Job:  map 97% reduce 30%18/12/13 01:09:57 INFO mapreduce.Job:  map 97% reduce 31%18/12/13 01:10:51 INFO mapreduce.Job:  map 97% reduce 32%18/12/13 01:15:01 INFO mapreduce.Job:  map 98% reduce 32%18/12/13 01:19:22 INFO mapreduce.Job:  map 99% reduce 32%18/12/13 01:21:22 INFO mapreduce.Job:  map 99% reduce 33%18/12/13 01:21:24 INFO mapreduce.Job:  map 100% reduce 33%18/12/13 01:21:28 INFO mapreduce.Job:  map 100% reduce 38%18/12/13 01:21:34 INFO mapreduce.Job:  map 100% reduce 62%18/12/13 01:21:40 INFO mapreduce.Job:  map 100% reduce 68%18/12/13 01:21:46 INFO mapreduce.Job:  map 100% reduce 70%18/12/13 01:21:52 INFO mapreduce.Job:  map 100% reduce 72%18/12/13 01:21:58 INFO mapreduce.Job:  map 100% reduce 74%18/12/13 01:22:04 INFO mapreduce.Job:  map 100% reduce 76%18/12/13 01:22:10 INFO mapreduce.Job:  map 100% reduce 78%18/12/13 01:22:16 INFO mapreduce.Job:  map 100% reduce 79%18/12/13 01:22:22 INFO mapreduce.Job:  map 100% reduce 81%18/12/13 01:22:28 INFO mapreduce.Job:  map 100% reduce 83%18/12/13 01:22:34 INFO mapreduce.Job:  map 100% reduce 85%18/12/13 01:22:40 INFO mapreduce.Job:  map 100% reduce 87%18/12/13 01:22:46 INFO mapreduce.Job:  map 100% reduce 89%18/12/13 01:22:52 INFO mapreduce.Job:  map 100% reduce 90%18/12/13 01:22:58 INFO mapreduce.Job:  map 100% reduce 92%18/12/13 01:23:04 INFO mapreduce.Job:  map 100% reduce 93%18/12/13 01:23:10 INFO mapreduce.Job:  map 100% reduce 94%18/12/13 01:23:16 INFO mapreduce.Job:  map 100% reduce 95%18/12/13 01:23:22 INFO mapreduce.Job:  map 100% reduce 96%18/12/13 01:23:34 INFO mapreduce.Job:  map 100% reduce 97%18/12/13 01:23:52 INFO mapreduce.Job:  map 100% reduce 98%18/12/13 01:24:16 INFO mapreduce.Job:  map 100% reduce 99%18/12/13 01:24:45 INFO mapreduce.Job:  map 100% reduce 100%18/12/13 01:24:57 INFO mapreduce.Job: Job job_1544662799784_0001 completed successfully18/12/13 01:24:58 INFO mapreduce.Job: Counters: 51\n\tFile System Counters\n\t\tFILE: Number of bytes read=386764389084\n\t\tFILE: Number of bytes written=506470583896\n\t\tFILE: Number of read operations=0\n\t\tFILE: Number of large read operations=0\n\t\tFILE: Number of write operations=0\n\t\tHDFS: Number of bytes read=115000088274\n\t\tHDFS: Number of bytes written=115000000000\n\t\tHDFS: Number of read operations=2655\n\t\tHDFS: Number of large read operations=0\n\t\tHDFS: Number of write operations=22\n\tJob Counters \n\t\tKilled map tasks=11\n\t\tLaunched map tasks=884\n\t\tLaunched reduce tasks=11\n\t\tData-local map tasks=844\n\t\tRack-local map tasks=40\n\t\tTotal time spent by all maps in occupied slots (ms)=55720122\n\t\tTotal time spent by all reduces in occupied slots (ms)=12545824\n\t\tTotal time spent by all map tasks (ms)=55720122\n\t\tTotal time spent by all reduce tasks (ms)=12545824\n\t\tTotal vcore-milliseconds taken by all map tasks=55720122\n\t\tTotal vcore-milliseconds taken by all reduce tasks=12545824\n\t\tTotal megabyte-milliseconds taken by all map tasks=57057404928\n\t\tTotal megabyte-milliseconds taken by all reduce tasks=12846923776\n\tMap-Reduce Framework\n\t\tMap input records=1150000000\n\t\tMap output records=1150000000\n\t\tMap output bytes=117300000000\n\t\tMap output materialized bytes=119600057684\n\t\tInput split bytes=88274\n\t\tCombine input records=0\n\t\tCombine output records=0\n\t\tReduce input groups=1150000000\n\t\tReduce shuffle bytes=119600057684\n\t\tReduce input records=1150000000\n\t\tReduce output records=1150000000\n\t\tSpilled Records=4868554438\n\t\tShuffled Maps =9614\n\t\tFailed Shuffles=0\n\t\tMerged Map outputs=9614\n\t\tGC time elapsed (ms)=379370\n\t\tCPU time spent (ms)=13850440\n\t\tPhysical memory (bytes) snapshot=264886837248\n\t\tVirtual memory (bytes) snapshot=1783068631040\n\t\tTotal committed heap usage (bytes)=174668120064\n\tShuffle Errors\n\t\tBAD_ID=0\n\t\tCONNECTION=0\n\t\tIO_ERROR=0\n\t\tWRONG_LENGTH=0\n\t\tWRONG_MAP=0\n\t\tWRONG_REDUCE=0\n\tFile Input Format Counters \n\t\tBytes Read=115000000000\n\tFile Output Format Counters \n\t\tBytes Written=11500000000018/12/13 01:24:58 INFO terasort.TeraSort: donereal\t20m42.506s\nuser\t0m13.517s\nsys\t0m1.576s", :stdout=>"Spent 193ms computing base-splits.Spent 5ms computing TeraScheduler splits.\nComputing input splits took 199msSampling 10 splits of 874Making 11 from 100000 sampled recordsComputing parititions took 2126msSpent 2328ms computing partitions.", :status=>0}}
Exp  2, overall time taken is 20 m 42.506 s
Exp  2 termintated at 2018-12-13 02:24:58 +0100

Exp  3 started at  2018-12-13 02:34:56 +0100
Exp 3's result is {"10.158.0.1"=>{:stderr=>"18/12/13 01:35:51 INFO terasort.TeraSort: starting18/12/13 01:35:52 INFO input.FileInputFormat: Total input files to process : 2318/12/13 01:35:52 ERROR terasort.TeraSort: Cannot create file/output/_partition.lst. Name node is in safe mode.\nThe reported blocks 889 has reached the threshold 0.9990 of total blocks 889. The number of live datanodes 23 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 18 seconds. NamenodeHostName:node1\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1407)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1395)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2278)\n\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2223)\n\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:728)\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:413)\n\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:447)\n\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)\n\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:850)\n\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:793)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)\n\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2489)Got an exception while reading splits java.io.IOException: Failed on local exception: java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/10.158.0.1:36492 remote=node1/10.158.0.1:9000]. 60000 millis timeout left.; Host Details : local host is: \"node1/10.158.0.1\"; destination host is: \"node1\":9000; \n\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:782)\n\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1493)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1435)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1345)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)\n\tat com.sun.proxy.$Proxy10.getBlockLocations(Unknown Source)\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:259)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)\n\tat com.sun.proxy.$Proxy11.getBlockLocations(Unknown Source)\n\tat org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:847)\n\tat org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:836)\n\tat org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:825)\n\tat org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:325)\n\tat org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:285)\n\tat org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:270)\n\tat org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1064)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:328)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:325)\n\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:325)\n\tat org.apache.hadoop.fs.FileSystem.open(FileSystem.java:787)\n\tat org.apache.hadoop.examples.terasort.TeraInputFormat$TeraRecordReader.initialize(TeraInputFormat.java:227)\n\tat org.apache.hadoop.examples.terasort.TeraInputFormat$1.run(TeraInputFormat.java:153)\nCaused by: java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/10.158.0.1:36492 remote=node1/10.158.0.1:9000]. 60000 millis timeout left.\n\tat org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)\n\tat org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)\n\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)\n\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)\n\tat java.io.FilterInputStream.read(FilterInputStream.java:133)\n\tat java.io.BufferedInputStream.fill(BufferedInputStream.java:246)\n\tat java.io.BufferedInputStream.read(BufferedInputStream.java:265)\n\tat java.io.FilterInputStream.read(FilterInputStream.java:83)\n\tat java.io.FilterInputStream.read(FilterInputStream.java:83)\n\tat org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:554)\n\tat java.io.DataInputStream.readInt(DataInputStream.java:387)\n\tat org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1794)\n\tat org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1163)\n\tat org.apache.hadoop.ipc.Client$Connection.run(Client.java:1059)Got an exception while reading splits java.io.IOException: Failed on local exception: java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/10.158.0.1:36492 remote=node1/10.158.0.1:9000]. 60000 millis timeout left.; Host Details : local host is: \"node1/10.158.0.1\"; destination host is: \"node1\":9000; \n\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:782)\n\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1493)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1435)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1345)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)\n\tat com.sun.proxy.$Proxy10.getBlockLocations(Unknown Source)\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:259)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)\n\tat com.sun.proxy.$Proxy11.getBlockLocations(Unknown Source)\n\tat org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:847)\n\tat org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:836)\n\tat org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:825)\n\tat org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:325)\n\tat org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:285)\n\tat org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:270)\n\tat org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1064)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:328)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:325)\n\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:325)\n\tat org.apache.hadoop.fs.FileSystem.open(FileSystem.java:787)\n\tat org.apache.hadoop.examples.terasort.TeraInputFormat$TeraRecordReader.initialize(TeraInputFormat.java:227)\n\tat org.apache.hadoop.examples.terasort.TeraInputFormat$1.run(TeraInputFormat.java:153)\nCaused by: java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/10.158.0.1:36492 remote=node1/10.158.0.1:9000]. 60000 millis timeout left.\n\tat org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)\n\tat org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)\n\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)\n\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)\n\tat java.io.FilterInputStream.read(FilterInputStream.java:133)\n\tat java.io.BufferedInputStream.fill(BufferedInputStream.java:246)\n\tat java.io.BufferedInputStream.read(BufferedInputStream.java:265)\n\tat java.io.FilterInputStream.read(FilterInputStream.java:83)\n\tat java.io.FilterInputStream.read(FilterInputStream.java:83)\n\tat org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:554)\n\tat java.io.DataInputStream.readInt(DataInputStream.java:387)\n\tat org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1794)\n\tat org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1163)\n\tat org.apache.hadoop.ipc.Client$Connection.run(Client.java:1059)Got an exception while reading splits java.io.IOException: Failed on local exception: java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/10.158.0.1:36492 remote=node1/10.158.0.1:9000]. 60000 millis timeout left.; Host Details : local host is: \"node1/10.158.0.1\"; destination host is: \"node1\":9000; \n\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:782)\n\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1493)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1435)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1345)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)\n\tat com.sun.proxy.$Proxy10.getBlockLocations(Unknown Source)\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:259)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)\n\tat com.sun.proxy.$Proxy11.getBlockLocations(Unknown Source)\n\tat org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:847)\n\tat org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:836)\n\tat org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:825)\n\tat org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:325)\n\tat org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:285)\n\tat org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:270)\n\tat org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1064)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:328)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:325)\n\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:325)\n\tat org.apache.hadoop.fs.FileSystem.open(FileSystem.java:787)\n\tat org.apache.hadoop.examples.terasort.TeraInputFormat$TeraRecordReader.initialize(TeraInputFormat.java:227)\n\tat org.apache.hadoop.examples.terasort.TeraInputFormat$1.run(TeraInputFormat.java:153)\nCaused by: java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/10.158.0.1:36492 remote=node1/10.158.0.1:9000]. 60000 millis timeout left.\n\tat org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)\n\tat org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)\n\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)\n\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)\n\tat java.io.FilterInputStream.read(FilterInputStream.java:133)\n\tat java.io.BufferedInputStream.fill(BufferedInputStream.java:246)\n\tat java.io.BufferedInputStream.read(BufferedInputStream.java:265)\n\tat java.io.FilterInputStream.read(FilterInputStream.java:83)\n\tat java.io.FilterInputStream.read(FilterInputStream.java:83)\n\tat org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:554)\n\tat java.io.DataInputStream.readInt(DataInputStream.java:387)\n\tat org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1794)\n\tat org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1163)\n\tat org.apache.hadoop.ipc.Client$Connection.run(Client.java:1059)Got an exception while reading splits java.io.IOException: Failed on local exception: java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/10.158.0.1:36492 remote=node1/10.158.0.1:9000]. 60000 millis timeout left.; Host Details : local host is: \"node1/10.158.0.1\"; destination host is: \"node1\":9000; \n\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:782)\n\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1493)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1435)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1345)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)\n\tat com.sun.proxy.$Proxy10.getBlockLocations(Unknown Source)\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:259)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)\n\tat com.sun.proxy.$Proxy11.getBlockLocations(Unknown Source)\n\tat org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:847)\n\tat org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:836)\n\tat org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:825)\n\tat org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:325)\n\tat org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:285)\n\tat org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:270)\n\tat org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1064)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:328)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:325)\n\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:325)\n\tat org.apache.hadoop.fs.FileSystem.open(FileSystem.java:787)\n\tat org.apache.hadoop.examples.terasort.TeraInputFormat$TeraRecordReader.initialize(TeraInputFormat.java:227)\n\tat org.apache.hadoop.examples.terasort.TeraInputFormat$1.run(TeraInputFormat.java:153)\nCaused by: java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/10.158.0.1:36492 remote=node1/10.158.0.1:9000]. 60000 millis timeout left.\n\tat org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)\n\tat org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)\n\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)\n\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)\n\tat java.io.FilterInputStream.read(FilterInputStream.java:133)\n\tat java.io.BufferedInputStream.fill(BufferedInputStream.java:246)\n\tat java.io.BufferedInputStream.read(BufferedInputStream.java:265)\n\tat java.io.FilterInputStream.read(FilterInputStream.java:83)\n\tat java.io.FilterInputStream.read(FilterInputStream.java:83)\n\tat org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:554)\n\tat java.io.DataInputStream.readInt(DataInputStream.java:387)\n\tat org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1794)\n\tat org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1163)\n\tat org.apache.hadoop.ipc.Client$Connection.run(Client.java:1059)Got an exception while reading splits java.io.IOException: Failed on local exception: java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/10.158.0.1:36492 remote=node1/10.158.0.1:9000]. 60000 millis timeout left.; Host Details : local host is: \"node1/10.158.0.1\"; destination host is: \"node1\":9000; \n\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:782)\n\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1493)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1435)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1345)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)\n\tat com.sun.proxy.$Proxy10.getBlockLocations(Unknown Source)\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:259)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)\n\tat com.sun.proxy.$Proxy11.getBlockLocations(Unknown Source)\n\tat org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:847)\n\tat org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:836)\n\tat org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:825)\n\tat org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:325)\n\tat org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:285)\n\tat org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:270)\n\tat org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1064)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:328)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:325)\n\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:325)\n\tat org.apache.hadoop.fs.FileSystem.open(FileSystem.java:787)\n\tat org.apache.hadoop.examples.terasort.TeraInputFormat$TeraRecordReader.initialize(TeraInputFormat.java:227)\n\tat org.apache.hadoop.examples.terasort.TeraInputFormat$1.run(TeraInputFormat.java:153)\nCaused by: java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/10.158.0.1:36492 remote=node1/10.158.0.1:9000]. 60000 millis timeout left.\n\tat org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)\n\tat org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)\n\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)\n\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)\n\tat java.io.FilterInputStream.read(FilterInputStream.java:133)\n\tat java.io.BufferedInputStream.fill(BufferedInputStream.java:246)\n\tat java.io.BufferedInputStream.read(BufferedInputStream.java:265)\n\tat java.io.FilterInputStream.read(FilterInputStream.java:83)\n\tat java.io.FilterInputStream.read(FilterInputStream.java:83)\n\tat org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:554)\n\tat java.io.DataInputStream.readInt(DataInputStream.java:387)\n\tat org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1794)\n\tat org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1163)\n\tat org.apache.hadoop.ipc.Client$Connection.run(Client.java:1059)Got an exception while reading splits java.io.IOException: Failed on local exception: java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/10.158.0.1:36492 remote=node1/10.158.0.1:9000]. 60000 millis timeout left.; Host Details : local host is: \"node1/10.158.0.1\"; destination host is: \"node1\":9000; \n\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:782)\n\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1493)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1435)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1345)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)\n\tat com.sun.proxy.$Proxy10.getBlockLocations(Unknown Source)\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:259)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)\n\tat com.sun.proxy.$Proxy11.getBlockLocations(Unknown Source)\n\tat org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:847)\n\tat org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:836)\n\tat org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:825)\n\tat org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:325)\n\tat org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:285)\n\tat org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:270)\n\tat org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1064)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:328)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:325)\n\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:325)\n\tat org.apache.hadoop.fs.FileSystem.open(FileSystem.java:787)\n\tat org.apache.hadoop.examples.terasort.TeraInputFormat$TeraRecordReader.initialize(TeraInputFormat.java:227)\n\tat org.apache.hadoop.examples.terasort.TeraInputFormat$1.run(TeraInputFormat.java:153)\nCaused by: java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/10.158.0.1:36492 remote=node1/10.158.0.1:9000]. 60000 millis timeout left.\n\tat org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)\n\tat org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)\n\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)\n\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)\n\tat java.io.FilterInputStream.read(FilterInputStream.java:133)\n\tat java.io.BufferedInputStream.fill(BufferedInputStream.java:246)\n\tat java.io.BufferedInputStream.read(BufferedInputStream.java:265)\n\tat java.io.FilterInputStream.read(FilterInputStream.java:83)\n\tat java.io.FilterInputStream.read(FilterInputStream.java:83)\n\tat org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:554)\n\tat java.io.DataInputStream.readInt(DataInputStream.java:387)\n\tat org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1794)\n\tat org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1163)\n\tat org.apache.hadoop.ipc.Client$Connection.run(Client.java:1059)Got an exception while reading splits java.io.IOException: Failed on local exception: java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/10.158.0.1:36492 remote=node1/10.158.0.1:9000]. 60000 millis timeout left.; Host Details : local host is: \"node1/10.158.0.1\"; destination host is: \"node1\":9000; \n\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:782)\n\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1493)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1435)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1345)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)\n\tat com.sun.proxy.$Proxy10.getBlockLocations(Unknown Source)\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:259)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)\n\tat com.sun.proxy.$Proxy11.getBlockLocations(Unknown Source)\n\tat org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:847)\n\tat org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:836)\n\tat org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:825)\n\tat org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:325)\n\tat org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:285)\n\tat org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:270)\n\tat org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1064)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:328)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:325)\n\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:325)\n\tat org.apache.hadoop.fs.FileSystem.open(FileSystem.java:787)\n\tat org.apache.hadoop.examples.terasort.TeraInputFormat$TeraRecordReader.initialize(TeraInputFormat.java:227)\n\tat org.apache.hadoop.examples.terasort.TeraInputFormat$1.run(TeraInputFormat.java:153)\nCaused by: java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/10.158.0.1:36492 remote=node1/10.158.0.1:9000]. 60000 millis timeout left.\n\tat org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)\n\tat org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)\n\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)\n\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)\n\tat java.io.FilterInputStream.read(FilterInputStream.java:133)\n\tat java.io.BufferedInputStream.fill(BufferedInputStream.java:246)\n\tat java.io.BufferedInputStream.read(BufferedInputStream.java:265)\n\tat java.io.FilterInputStream.read(FilterInputStream.java:83)\n\tat java.io.FilterInputStream.read(FilterInputStream.java:83)\n\tat org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:554)\n\tat java.io.DataInputStream.readInt(DataInputStream.java:387)\n\tat org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1794)\n\tat org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1163)\n\tat org.apache.hadoop.ipc.Client$Connection.run(Client.java:1059)Got an exception while reading splits java.io.IOException: Failed on local exception: java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/10.158.0.1:36492 remote=node1/10.158.0.1:9000]. 60000 millis timeout left.; Host Details : local host is: \"node1/10.158.0.1\"; destination host is: \"node1\":9000; \n\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:782)\n\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1493)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1435)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1345)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)\n\tat com.sun.proxy.$Proxy10.getBlockLocations(Unknown Source)\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:259)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)\n\tat com.sun.proxy.$Proxy11.getBlockLocations(Unknown Source)\n\tat org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:847)\n\tat org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:836)\n\tat org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:825)\n\tat org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:325)\n\tat org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:285)\n\tat org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:270)\n\tat org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1064)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:328)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:325)\n\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:325)\n\tat org.apache.hadoop.fs.FileSystem.open(FileSystem.java:787)\n\tat org.apache.hadoop.examples.terasort.TeraInputFormat$TeraRecordReader.initialize(TeraInputFormat.java:227)\n\tat org.apache.hadoop.examples.terasort.TeraInputFormat$1.run(TeraInputFormat.java:153)\nCaused by: java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/10.158.0.1:36492 remote=node1/10.158.0.1:9000]. 60000 millis timeout left.\n\tat org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)\n\tat org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)\n\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)\n\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)\n\tat java.io.FilterInputStream.read(FilterInputStream.java:133)\n\tat java.io.BufferedInputStream.fill(BufferedInputStream.java:246)\n\tat java.io.BufferedInputStream.read(BufferedInputStream.java:265)\n\tat java.io.FilterInputStream.read(FilterInputStream.java:83)\n\tat java.io.FilterInputStream.read(FilterInputStream.java:83)\n\tat org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:554)\n\tat java.io.DataInputStream.readInt(DataInputStream.java:387)\n\tat org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1794)\n\tat org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1163)\n\tat org.apache.hadoop.ipc.Client$Connection.run(Client.java:1059)Got an exception while reading splits java.io.IOException: Failed on local exception: java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/10.158.0.1:36492 remote=node1/10.158.0.1:9000]. 60000 millis timeout left.; Host Details : local host is: \"node1/10.158.0.1\"; destination host is: \"node1\":9000; \n\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:782)\n\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1493)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1435)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1345)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)\n\tat com.sun.proxy.$Proxy10.getBlockLocations(Unknown Source)\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:259)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)\n\tat com.sun.proxy.$Proxy11.getBlockLocations(Unknown Source)\n\tat org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:847)\n\tat org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:836)\n\tat org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:825)\n\tat org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:325)\n\tat org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:285)\n\tat org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:270)\n\tat org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1064)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:328)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:325)\n\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:325)\n\tat org.apache.hadoop.fs.FileSystem.open(FileSystem.java:787)\n\tat org.apache.hadoop.examples.terasort.TeraInputFormat$TeraRecordReader.initialize(TeraInputFormat.java:227)\n\tat org.apache.hadoop.examples.terasort.TeraInputFormat$1.run(TeraInputFormat.java:153)\nCaused by: java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/10.158.0.1:36492 remote=node1/10.158.0.1:9000]. 60000 millis timeout left.\n\tat org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)\n\tat org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)\n\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)\n\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)\n\tat java.io.FilterInputStream.read(FilterInputStream.java:133)\n\tat java.io.BufferedInputStream.fill(BufferedInputStream.java:246)\n\tat java.io.BufferedInputStream.read(BufferedInputStream.java:265)\n\tat java.io.FilterInputStream.read(FilterInputStream.java:83)\n\tat java.io.FilterInputStream.read(FilterInputStream.java:83)\n\tat org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:554)\n\tat java.io.DataInputStream.readInt(DataInputStream.java:387)\n\tat org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1794)\n\tat org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1163)\n\tat org.apache.hadoop.ipc.Client$Connection.run(Client.java:1059)Got an exception while reading splits java.io.IOException: Failed on local exception: java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/10.158.0.1:36492 remote=node1/10.158.0.1:9000]. 60000 millis timeout left.; Host Details : local host is: \"node1/10.158.0.1\"; destination host is: \"node1\":9000; \n\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:782)\n\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1493)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1435)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1345)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)\n\tat com.sun.proxy.$Proxy10.getBlockLocations(Unknown Source)\n\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:259)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)\n\tat com.sun.proxy.$Proxy11.getBlockLocations(Unknown Source)\n\tat org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:847)\n\tat org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:836)\n\tat org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:825)\n\tat org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:325)\n\tat org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:285)\n\tat org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:270)\n\tat org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1064)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:328)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:325)\n\tat org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)\n\tat org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:325)\n\tat org.apache.hadoop.fs.FileSystem.open(FileSystem.java:787)\n\tat org.apache.hadoop.examples.terasort.TeraInputFormat$TeraRecordReader.initialize(TeraInputFormat.java:227)\n\tat org.apache.hadoop.examples.terasort.TeraInputFormat$1.run(TeraInputFormat.java:153)\nCaused by: java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/10.158.0.1:36492 remote=node1/10.158.0.1:9000]. 60000 millis timeout left.\n\tat org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)\n\tat org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)\n\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)\n\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)\n\tat java.io.FilterInputStream.read(FilterInputStream.java:133)\n\tat java.io.BufferedInputStream.fill(BufferedInputStream.java:246)\n\tat java.io.BufferedInputStream.read(BufferedInputStream.java:265)\n\tat java.io.FilterInputStream.read(FilterInputStream.java:83)\n\tat java.io.FilterInputStream.read(FilterInputStream.java:83)\n\tat org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:554)\n\tat java.io.DataInputStream.readInt(DataInputStream.java:387)\n\tat org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1794)\n\tat org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1163)\n\tat org.apache.hadoop.ipc.Client$Connection.run(Client.java:1059)real\t0m2.062s\nuser\t0m4.432s\nsys\t0m0.377s", :stdout=>"Spent 185ms computing base-splits.Spent 7ms computing TeraScheduler splits.\nComputing input splits took 193msSampling 10 splits of 874", :status=>255}}
Exp  3, overall time taken is 0 m 2.062 s
Exp  3 termintated at 2018-12-13 02:35:52 +0100

Exp  4 started at  2018-12-13 02:46:01 +0100
Exp 4's result is {"10.158.0.1"=>{:stderr=>"18/12/13 01:46:56 INFO terasort.TeraSort: starting18/12/13 01:46:57 INFO input.FileInputFormat: Total input files to process : 2318/12/13 01:46:59 INFO client.RMProxy: Connecting to ResourceManager at node1/10.158.0.1:803218/12/13 01:47:01 INFO mapreduce.JobSubmitter: number of splits:87418/12/13 01:47:01 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces18/12/13 01:47:01 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1544665355073_000118/12/13 01:47:02 INFO impl.YarnClientImpl: Submitted application application_1544665355073_000118/12/13 01:47:02 INFO mapreduce.Job: The url to track the job: http://node1:8088/proxy/application_1544665355073_0001/18/12/13 01:47:02 INFO mapreduce.Job: Running job: job_1544665355073_000118/12/13 01:47:09 INFO mapreduce.Job: Job job_1544665355073_0001 running in uber mode : false18/12/13 01:47:09 INFO mapreduce.Job:  map 0% reduce 0%18/12/13 01:47:28 INFO mapreduce.Job:  map 2% reduce 0%18/12/13 01:47:29 INFO mapreduce.Job:  map 4% reduce 0%18/12/13 01:47:30 INFO mapreduce.Job:  map 5% reduce 0%18/12/13 01:47:34 INFO mapreduce.Job:  map 6% reduce 0%18/12/13 01:47:35 INFO mapreduce.Job:  map 7% reduce 0%18/12/13 01:47:40 INFO mapreduce.Job:  map 8% reduce 0%18/12/13 01:47:41 INFO mapreduce.Job:  map 9% reduce 0%18/12/13 01:47:46 INFO mapreduce.Job:  map 10% reduce 0%18/12/13 01:47:47 INFO mapreduce.Job:  map 11% reduce 0%18/12/13 01:47:48 INFO mapreduce.Job:  map 12% reduce 0%18/12/13 01:47:52 INFO mapreduce.Job:  map 13% reduce 0%18/12/13 01:47:53 INFO mapreduce.Job:  map 14% reduce 0%18/12/13 01:47:58 INFO mapreduce.Job:  map 15% reduce 0%18/12/13 01:47:59 INFO mapreduce.Job:  map 16% reduce 0%18/12/13 01:48:03 INFO mapreduce.Job:  map 17% reduce 0%18/12/13 01:48:04 INFO mapreduce.Job:  map 18% reduce 0%18/12/13 01:48:05 INFO mapreduce.Job:  map 19% reduce 0%18/12/13 01:48:10 INFO mapreduce.Job:  map 20% reduce 0%18/12/13 01:48:11 INFO mapreduce.Job:  map 21% reduce 0%18/12/13 01:48:12 INFO mapreduce.Job:  map 23% reduce 0%18/12/13 01:48:13 INFO mapreduce.Job:  map 26% reduce 0%18/12/13 01:48:14 INFO mapreduce.Job:  map 28% reduce 0%18/12/13 01:48:16 INFO mapreduce.Job:  map 29% reduce 0%18/12/13 01:48:17 INFO mapreduce.Job:  map 31% reduce 0%18/12/13 01:48:19 INFO mapreduce.Job:  map 32% reduce 0%18/12/13 01:48:28 INFO mapreduce.Job:  map 34% reduce 0%18/12/13 01:48:29 INFO mapreduce.Job:  map 35% reduce 3%18/12/13 01:48:30 INFO mapreduce.Job:  map 36% reduce 4%18/12/13 01:48:33 INFO mapreduce.Job:  map 37% reduce 4%18/12/13 01:48:35 INFO mapreduce.Job:  map 38% reduce 6%18/12/13 01:48:36 INFO mapreduce.Job:  map 39% reduce 7%18/12/13 01:48:40 INFO mapreduce.Job:  map 40% reduce 7%18/12/13 01:48:41 INFO mapreduce.Job:  map 41% reduce 8%18/12/13 01:48:42 INFO mapreduce.Job:  map 41% reduce 9%18/12/13 01:48:46 INFO mapreduce.Job:  map 42% reduce 9%18/12/13 01:48:47 INFO mapreduce.Job:  map 43% reduce 10%18/12/13 01:48:51 INFO mapreduce.Job:  map 44% reduce 10%18/12/13 01:48:52 INFO mapreduce.Job:  map 45% reduce 10%18/12/13 01:48:53 INFO mapreduce.Job:  map 45% reduce 11%18/12/13 01:48:54 INFO mapreduce.Job:  map 46% reduce 11%18/12/13 01:48:59 INFO mapreduce.Job:  map 47% reduce 11%18/12/13 01:49:01 INFO mapreduce.Job:  map 48% reduce 11%18/12/13 01:49:04 INFO mapreduce.Job:  map 49% reduce 11%18/12/13 01:49:05 INFO mapreduce.Job:  map 50% reduce 11%18/12/13 01:49:06 INFO mapreduce.Job:  map 50% reduce 12%18/12/13 01:49:11 INFO mapreduce.Job:  map 51% reduce 12%18/12/13 01:49:12 INFO mapreduce.Job:  map 52% reduce 12%18/12/13 01:49:14 INFO mapreduce.Job:  map 54% reduce 12%18/12/13 01:49:16 INFO mapreduce.Job:  map 55% reduce 12%18/12/13 01:49:18 INFO mapreduce.Job:  map 55% reduce 14%18/12/13 01:49:19 INFO mapreduce.Job:  map 56% reduce 14%18/12/13 01:49:20 INFO mapreduce.Job:  map 57% reduce 14%18/12/13 01:49:23 INFO mapreduce.Job:  map 58% reduce 14%18/12/13 01:49:24 INFO mapreduce.Job:  map 58% reduce 16%18/12/13 01:49:29 INFO mapreduce.Job:  map 59% reduce 16%18/12/13 01:49:30 INFO mapreduce.Job:  map 59% reduce 17%18/12/13 01:49:31 INFO mapreduce.Job:  map 60% reduce 17%18/12/13 01:49:33 INFO mapreduce.Job:  map 61% reduce 17%18/12/13 01:49:35 INFO mapreduce.Job:  map 62% reduce 17%18/12/13 01:49:36 INFO mapreduce.Job:  map 62% reduce 18%18/12/13 01:49:39 INFO mapreduce.Job:  map 63% reduce 18%18/12/13 01:49:42 INFO mapreduce.Job:  map 64% reduce 19%18/12/13 01:49:47 INFO mapreduce.Job:  map 65% reduce 19%18/12/13 01:49:51 INFO mapreduce.Job:  map 66% reduce 19%18/12/13 01:49:53 INFO mapreduce.Job:  map 67% reduce 19%18/12/13 01:49:57 INFO mapreduce.Job:  map 68% reduce 19%18/12/13 01:49:59 INFO mapreduce.Job:  map 69% reduce 19%18/12/13 01:50:03 INFO mapreduce.Job:  map 70% reduce 19%18/12/13 01:50:05 INFO mapreduce.Job:  map 71% reduce 19%18/12/13 01:50:06 INFO mapreduce.Job:  map 71% reduce 20%18/12/13 01:50:07 INFO mapreduce.Job:  map 72% reduce 20%18/12/13 01:50:10 INFO mapreduce.Job:  map 73% reduce 20%18/12/13 01:50:11 INFO mapreduce.Job:  map 74% reduce 20%18/12/13 01:50:12 INFO mapreduce.Job:  map 74% reduce 21%18/12/13 01:50:13 INFO mapreduce.Job:  map 75% reduce 21%18/12/13 01:50:15 INFO mapreduce.Job:  map 76% reduce 21%18/12/13 01:50:17 INFO mapreduce.Job:  map 77% reduce 21%18/12/13 01:50:18 INFO mapreduce.Job:  map 78% reduce 23%18/12/13 01:50:20 INFO mapreduce.Job:  map 79% reduce 23%18/12/13 01:50:23 INFO mapreduce.Job:  map 80% reduce 23%18/12/13 01:50:24 INFO mapreduce.Job:  map 80% reduce 25%18/12/13 01:50:25 INFO mapreduce.Job:  map 81% reduce 25%18/12/13 01:50:28 INFO mapreduce.Job:  map 82% reduce 25%18/12/13 01:50:29 INFO mapreduce.Job:  map 83% reduce 25%18/12/13 01:50:30 INFO mapreduce.Job:  map 83% reduce 26%18/12/13 01:50:35 INFO mapreduce.Job:  map 84% reduce 26%18/12/13 01:50:40 INFO mapreduce.Job:  map 85% reduce 26%18/12/13 01:50:49 INFO mapreduce.Job:  map 86% reduce 26%18/12/13 01:50:54 INFO mapreduce.Job:  map 86% reduce 27%18/12/13 01:51:00 INFO mapreduce.Job:  map 87% reduce 27%18/12/13 01:51:07 INFO mapreduce.Job:  map 88% reduce 27%18/12/13 01:51:12 INFO mapreduce.Job:  map 88% reduce 28%18/12/13 01:51:13 INFO mapreduce.Job:  map 89% reduce 28%18/12/13 01:51:25 INFO mapreduce.Job:  map 90% reduce 28%18/12/13 01:51:36 INFO mapreduce.Job:  map 90% reduce 29%18/12/13 01:51:42 INFO mapreduce.Job:  map 91% reduce 29%18/12/13 01:51:59 INFO mapreduce.Job:  map 92% reduce 29%18/12/13 01:52:11 INFO mapreduce.Job:  map 92% reduce 30%18/12/13 01:52:18 INFO mapreduce.Job:  map 93% reduce 30%18/12/13 01:52:31 INFO mapreduce.Job:  map 94% reduce 30%18/12/13 01:52:37 INFO mapreduce.Job:  map 94% reduce 31%18/12/13 01:52:43 INFO mapreduce.Job:  map 95% reduce 31%18/12/13 01:52:50 INFO mapreduce.Job:  map 96% reduce 31%18/12/13 01:52:59 INFO mapreduce.Job:  map 97% reduce 31%18/12/13 01:53:08 INFO mapreduce.Job:  map 98% reduce 31%18/12/13 01:53:13 INFO mapreduce.Job:  map 98% reduce 32%18/12/13 01:53:24 INFO mapreduce.Job:  map 99% reduce 32%18/12/13 01:53:44 INFO mapreduce.Job:  map 100% reduce 32%18/12/13 01:53:50 INFO mapreduce.Job:  map 100% reduce 33%18/12/13 01:57:01 INFO mapreduce.Job:  map 100% reduce 34%18/12/13 01:57:19 INFO mapreduce.Job:  map 100% reduce 35%18/12/13 01:57:49 INFO mapreduce.Job:  map 100% reduce 36%18/12/13 01:57:55 INFO mapreduce.Job:  map 100% reduce 37%18/12/13 01:58:01 INFO mapreduce.Job:  map 100% reduce 39%18/12/13 01:58:07 INFO mapreduce.Job:  map 100% reduce 41%18/12/13 01:58:13 INFO mapreduce.Job:  map 100% reduce 42%18/12/13 01:58:19 INFO mapreduce.Job:  map 100% reduce 43%18/12/13 01:58:25 INFO mapreduce.Job:  map 100% reduce 45%18/12/13 01:58:37 INFO mapreduce.Job:  map 100% reduce 46%18/12/13 01:58:56 INFO mapreduce.Job:  map 100% reduce 47%18/12/13 01:59:08 INFO mapreduce.Job:  map 100% reduce 48%18/12/13 02:00:32 INFO mapreduce.Job:  map 100% reduce 49%18/12/13 02:00:44 INFO mapreduce.Job:  map 100% reduce 50%18/12/13 02:00:56 INFO mapreduce.Job:  map 100% reduce 51%18/12/13 02:01:02 INFO mapreduce.Job:  map 100% reduce 52%18/12/13 02:01:14 INFO mapreduce.Job:  map 100% reduce 53%18/12/13 02:01:20 INFO mapreduce.Job:  map 100% reduce 54%18/12/13 02:01:26 INFO mapreduce.Job:  map 100% reduce 55%18/12/13 02:01:32 INFO mapreduce.Job:  map 100% reduce 56%18/12/13 02:01:38 INFO mapreduce.Job:  map 100% reduce 57%18/12/13 02:01:44 INFO mapreduce.Job:  map 100% reduce 58%18/12/13 02:01:50 INFO mapreduce.Job:  map 100% reduce 59%18/12/13 02:01:56 INFO mapreduce.Job:  map 100% reduce 60%18/12/13 02:02:02 INFO mapreduce.Job:  map 100% reduce 61%18/12/13 02:02:08 INFO mapreduce.Job:  map 100% reduce 62%18/12/13 02:02:25 INFO mapreduce.Job:  map 100% reduce 63%18/12/13 02:02:37 INFO mapreduce.Job:  map 100% reduce 64%18/12/13 02:03:25 INFO mapreduce.Job:  map 100% reduce 66%18/12/13 02:03:49 INFO mapreduce.Job:  map 100% reduce 71%18/12/13 02:03:55 INFO mapreduce.Job:  map 100% reduce 76%18/12/13 02:04:01 INFO mapreduce.Job:  map 100% reduce 80%18/12/13 02:04:07 INFO mapreduce.Job:  map 100% reduce 82%18/12/13 02:11:20 INFO mapreduce.Job:  map 100% reduce 83%18/12/13 02:11:32 INFO mapreduce.Job:  map 100% reduce 84%18/12/13 02:11:38 INFO mapreduce.Job:  map 100% reduce 85%18/12/13 02:11:50 INFO mapreduce.Job:  map 100% reduce 86%18/12/13 02:12:02 INFO mapreduce.Job:  map 100% reduce 87%18/12/13 02:12:08 INFO mapreduce.Job:  map 100% reduce 88%18/12/13 02:12:20 INFO mapreduce.Job:  map 100% reduce 89%18/12/13 02:12:32 INFO mapreduce.Job:  map 100% reduce 90%18/12/13 02:12:44 INFO mapreduce.Job:  map 100% reduce 91%18/12/13 02:14:07 INFO mapreduce.Job: Task Id : attempt_1544665355073_0001_r_000004_0, Status : FAILEDAttemptID:attempt_1544665355073_0001_r_000004_0 Timed out after 600 secs18/12/13 02:14:08 INFO mapreduce.Job:  map 100% reduce 88%18/12/13 02:14:32 INFO mapreduce.Job:  map 100% reduce 89%18/12/13 02:14:50 INFO mapreduce.Job:  map 100% reduce 90%18/12/13 02:15:02 INFO mapreduce.Job:  map 100% reduce 91%18/12/13 02:15:20 INFO mapreduce.Job:  map 100% reduce 92%18/12/13 02:15:31 INFO mapreduce.Job:  map 100% reduce 93%18/12/13 02:15:49 INFO mapreduce.Job:  map 100% reduce 94%18/12/13 02:21:40 INFO mapreduce.Job:  map 100% reduce 95%18/12/13 02:21:52 INFO mapreduce.Job:  map 100% reduce 96%18/12/13 02:21:58 INFO mapreduce.Job:  map 100% reduce 97%18/12/13 02:26:17 INFO mapreduce.Job:  map 100% reduce 98%18/12/13 02:26:53 INFO mapreduce.Job:  map 100% reduce 99%18/12/13 02:27:23 INFO mapreduce.Job:  map 100% reduce 100%18/12/13 02:31:22 INFO mapreduce.Job: Job job_1544665355073_0001 completed successfully18/12/13 02:31:22 INFO mapreduce.Job: Counters: 53\n\tFile System Counters\n\t\tFILE: Number of bytes read=381467419900\n\t\tFILE: Number of bytes written=501173614712\n\t\tFILE: Number of read operations=0\n\t\tFILE: Number of large read operations=0\n\t\tFILE: Number of write operations=0\n\t\tHDFS: Number of bytes read=115000088274\n\t\tHDFS: Number of bytes written=115000000000\n\t\tHDFS: Number of read operations=2655\n\t\tHDFS: Number of large read operations=0\n\t\tHDFS: Number of write operations=22\n\tJob Counters \n\t\tFailed reduce tasks=1\n\t\tKilled map tasks=7\n\t\tKilled reduce tasks=6\n\t\tLaunched map tasks=881\n\t\tLaunched reduce tasks=18\n\t\tData-local map tasks=774\n\t\tRack-local map tasks=107\n\t\tTotal time spent by all maps in occupied slots (ms)=55106729\n\t\tTotal time spent by all reduces in occupied slots (ms)=21828976\n\t\tTotal time spent by all map tasks (ms)=55106729\n\t\tTotal time spent by all reduce tasks (ms)=21828976\n\t\tTotal vcore-milliseconds taken by all map tasks=55106729\n\t\tTotal vcore-milliseconds taken by all reduce tasks=21828976\n\t\tTotal megabyte-milliseconds taken by all map tasks=56429290496\n\t\tTotal megabyte-milliseconds taken by all reduce tasks=22352871424\n\tMap-Reduce Framework\n\t\tMap input records=1150000000\n\t\tMap output records=1150000000\n\t\tMap output bytes=117300000000\n\t\tMap output materialized bytes=119600057684\n\t\tInput split bytes=88274\n\t\tCombine input records=0\n\t\tCombine output records=0\n\t\tReduce input groups=1150000000\n\t\tReduce shuffle bytes=119600057684\n\t\tReduce input records=1150000000\n\t\tReduce output records=1150000000\n\t\tSpilled Records=4817622042\n\t\tShuffled Maps =9614\n\t\tFailed Shuffles=0\n\t\tMerged Map outputs=9614\n\t\tGC time elapsed (ms)=311155\n\t\tCPU time spent (ms)=13178050\n\t\tPhysical memory (bytes) snapshot=264085815296\n\t\tVirtual memory (bytes) snapshot=1782827782144\n\t\tTotal committed heap usage (bytes)=174429569024\n\tShuffle Errors\n\t\tBAD_ID=0\n\t\tCONNECTION=0\n\t\tIO_ERROR=0\n\t\tWRONG_LENGTH=0\n\t\tWRONG_MAP=0\n\t\tWRONG_REDUCE=0\n\tFile Input Format Counters \n\t\tBytes Read=115000000000\n\tFile Output Format Counters \n\t\tBytes Written=11500000000018/12/13 02:31:22 INFO terasort.TeraSort: donereal\t44m26.979s\nuser\t0m18.013s\nsys\t0m2.551s", :stdout=>"Spent 199ms computing base-splits.Spent 5ms computing TeraScheduler splits.\nComputing input splits took 204msSampling 10 splits of 874Making 11 from 100000 sampled recordsComputing parititions took 1835msSpent 2042ms computing partitions.", :status=>0}}
Exp  4, overall time taken is 44 m 26.979 s
Exp  4 termintated at 2018-12-13 03:31:22 +0100

Exp  5 started at  2018-12-13 03:42:28 +0100
Exp 5's result is {"10.158.0.1"=>{:stderr=>"18/12/13 02:43:22 INFO terasort.TeraSort: starting18/12/13 02:43:23 INFO input.FileInputFormat: Total input files to process : 2318/12/13 02:43:25 INFO client.RMProxy: Connecting to ResourceManager at node1/10.158.0.1:803218/12/13 02:43:26 INFO mapreduce.JobSubmitter: number of splits:87418/12/13 02:43:26 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces18/12/13 02:43:26 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1544668740052_000118/12/13 02:43:27 INFO impl.YarnClientImpl: Submitted application application_1544668740052_000118/12/13 02:43:27 INFO mapreduce.Job: The url to track the job: http://node1:8088/proxy/application_1544668740052_0001/18/12/13 02:43:27 INFO mapreduce.Job: Running job: job_1544668740052_000118/12/13 02:43:33 INFO mapreduce.Job: Job job_1544668740052_0001 running in uber mode : false18/12/13 02:43:33 INFO mapreduce.Job:  map 0% reduce 0%18/12/13 02:43:52 INFO mapreduce.Job:  map 2% reduce 0%18/12/13 02:43:53 INFO mapreduce.Job:  map 5% reduce 0%18/12/13 02:43:54 INFO mapreduce.Job:  map 7% reduce 0%18/12/13 02:43:58 INFO mapreduce.Job:  map 8% reduce 0%18/12/13 02:43:59 INFO mapreduce.Job:  map 10% reduce 0%18/12/13 02:44:04 INFO mapreduce.Job:  map 12% reduce 0%18/12/13 02:44:05 INFO mapreduce.Job:  map 13% reduce 0%18/12/13 02:44:06 INFO mapreduce.Job:  map 14% reduce 0%18/12/13 02:44:10 INFO mapreduce.Job:  map 17% reduce 0%18/12/13 02:44:11 INFO mapreduce.Job:  map 18% reduce 0%18/12/13 02:44:12 INFO mapreduce.Job:  map 20% reduce 0%18/12/13 02:44:15 INFO mapreduce.Job:  map 21% reduce 0%18/12/13 02:44:16 INFO mapreduce.Job:  map 22% reduce 0%18/12/13 02:44:23 INFO mapreduce.Job:  map 23% reduce 0%18/12/13 02:44:24 INFO mapreduce.Job:  map 24% reduce 0%18/12/13 02:44:27 INFO mapreduce.Job:  map 26% reduce 0%18/12/13 02:44:28 INFO mapreduce.Job:  map 26% reduce 1%18/12/13 02:44:29 INFO mapreduce.Job:  map 28% reduce 4%18/12/13 02:44:30 INFO mapreduce.Job:  map 29% reduce 4%18/12/13 02:44:32 INFO mapreduce.Job:  map 30% reduce 4%18/12/13 02:44:33 INFO mapreduce.Job:  map 31% reduce 4%18/12/13 02:44:35 INFO mapreduce.Job:  map 32% reduce 6%18/12/13 02:44:36 INFO mapreduce.Job:  map 33% reduce 6%18/12/13 02:44:37 INFO mapreduce.Job:  map 34% reduce 6%18/12/13 02:44:38 INFO mapreduce.Job:  map 35% reduce 6%18/12/13 02:44:39 INFO mapreduce.Job:  map 36% reduce 6%18/12/13 02:44:40 INFO mapreduce.Job:  map 37% reduce 6%18/12/13 02:44:41 INFO mapreduce.Job:  map 39% reduce 6%18/12/13 02:44:42 INFO mapreduce.Job:  map 40% reduce 6%18/12/13 02:44:43 INFO mapreduce.Job:  map 41% reduce 6%18/12/13 02:44:44 INFO mapreduce.Job:  map 42% reduce 6%18/12/13 02:44:45 INFO mapreduce.Job:  map 43% reduce 6%18/12/13 02:44:46 INFO mapreduce.Job:  map 44% reduce 7%18/12/13 02:44:47 INFO mapreduce.Job:  map 44% reduce 8%18/12/13 02:44:48 INFO mapreduce.Job:  map 45% reduce 8%18/12/13 02:44:50 INFO mapreduce.Job:  map 46% reduce 8%18/12/13 02:44:52 INFO mapreduce.Job:  map 47% reduce 9%18/12/13 02:44:53 INFO mapreduce.Job:  map 47% reduce 10%18/12/13 02:44:54 INFO mapreduce.Job:  map 48% reduce 10%18/12/13 02:44:56 INFO mapreduce.Job:  map 49% reduce 10%18/12/13 02:44:58 INFO mapreduce.Job:  map 50% reduce 10%18/12/13 02:44:59 INFO mapreduce.Job:  map 50% reduce 11%18/12/13 02:45:00 INFO mapreduce.Job:  map 51% reduce 11%18/12/13 02:45:02 INFO mapreduce.Job:  map 52% reduce 11%18/12/13 02:45:04 INFO mapreduce.Job:  map 53% reduce 11%18/12/13 02:45:05 INFO mapreduce.Job:  map 53% reduce 12%18/12/13 02:45:06 INFO mapreduce.Job:  map 54% reduce 12%18/12/13 02:45:09 INFO mapreduce.Job:  map 55% reduce 12%18/12/13 02:45:10 INFO mapreduce.Job:  map 56% reduce 12%18/12/13 02:45:12 INFO mapreduce.Job:  map 57% reduce 12%18/12/13 02:45:13 INFO mapreduce.Job:  map 58% reduce 12%18/12/13 02:45:15 INFO mapreduce.Job:  map 59% reduce 12%18/12/13 02:45:17 INFO mapreduce.Job:  map 60% reduce 12%18/12/13 02:45:18 INFO mapreduce.Job:  map 61% reduce 12%18/12/13 02:45:20 INFO mapreduce.Job:  map 62% reduce 12%18/12/13 02:45:21 INFO mapreduce.Job:  map 63% reduce 12%18/12/13 02:45:22 INFO mapreduce.Job:  map 64% reduce 12%18/12/13 02:45:23 INFO mapreduce.Job:  map 64% reduce 13%18/12/13 02:45:24 INFO mapreduce.Job:  map 65% reduce 13%18/12/13 02:45:26 INFO mapreduce.Job:  map 66% reduce 13%18/12/13 02:45:27 INFO mapreduce.Job:  map 67% reduce 13%18/12/13 02:45:29 INFO mapreduce.Job:  map 68% reduce 13%18/12/13 02:45:31 INFO mapreduce.Job:  map 69% reduce 13%18/12/13 02:45:32 INFO mapreduce.Job:  map 70% reduce 13%18/12/13 02:45:34 INFO mapreduce.Job:  map 71% reduce 14%18/12/13 02:45:35 INFO mapreduce.Job:  map 72% reduce 14%18/12/13 02:45:36 INFO mapreduce.Job:  map 73% reduce 14%18/12/13 02:45:37 INFO mapreduce.Job:  map 74% reduce 14%18/12/13 02:45:39 INFO mapreduce.Job:  map 75% reduce 14%18/12/13 02:45:40 INFO mapreduce.Job:  map 75% reduce 15%18/12/13 02:45:41 INFO mapreduce.Job:  map 76% reduce 15%18/12/13 02:45:42 INFO mapreduce.Job:  map 77% reduce 15%18/12/13 02:45:43 INFO mapreduce.Job:  map 78% reduce 15%18/12/13 02:45:52 INFO mapreduce.Job:  map 79% reduce 15%18/12/13 02:45:56 INFO mapreduce.Job:  map 80% reduce 15%18/12/13 02:45:58 INFO mapreduce.Job:  map 80% reduce 16%18/12/13 02:45:59 INFO mapreduce.Job:  map 81% reduce 16%18/12/13 02:46:04 INFO mapreduce.Job:  map 82% reduce 16%18/12/13 02:46:07 INFO mapreduce.Job:  map 83% reduce 16%18/12/13 02:46:10 INFO mapreduce.Job:  map 84% reduce 16%18/12/13 02:46:13 INFO mapreduce.Job:  map 85% reduce 16%18/12/13 02:46:17 INFO mapreduce.Job:  map 86% reduce 16%18/12/13 02:46:21 INFO mapreduce.Job:  map 87% reduce 16%18/12/13 02:46:23 INFO mapreduce.Job:  map 87% reduce 17%18/12/13 02:46:24 INFO mapreduce.Job:  map 88% reduce 17%18/12/13 02:46:28 INFO mapreduce.Job:  map 89% reduce 17%18/12/13 02:46:31 INFO mapreduce.Job:  map 90% reduce 17%18/12/13 02:46:34 INFO mapreduce.Job:  map 91% reduce 17%18/12/13 02:46:36 INFO mapreduce.Job:  map 92% reduce 17%18/12/13 02:46:38 INFO mapreduce.Job:  map 93% reduce 17%18/12/13 02:46:40 INFO mapreduce.Job:  map 94% reduce 17%18/12/13 02:46:41 INFO mapreduce.Job:  map 94% reduce 18%18/12/13 02:46:42 INFO mapreduce.Job:  map 95% reduce 18%18/12/13 02:46:51 INFO mapreduce.Job:  map 96% reduce 18%18/12/13 02:46:52 INFO mapreduce.Job:  map 98% reduce 18%18/12/13 02:46:54 INFO mapreduce.Job:  map 99% reduce 18%18/12/13 02:46:57 INFO mapreduce.Job:  map 100% reduce 19%18/12/13 02:47:15 INFO mapreduce.Job:  map 100% reduce 20%18/12/13 02:47:51 INFO mapreduce.Job:  map 100% reduce 21%18/12/13 02:48:28 INFO mapreduce.Job:  map 100% reduce 22%18/12/13 02:49:10 INFO mapreduce.Job:  map 100% reduce 23%18/12/13 02:49:46 INFO mapreduce.Job:  map 100% reduce 24%18/12/13 02:50:28 INFO mapreduce.Job:  map 100% reduce 25%18/12/13 02:51:16 INFO mapreduce.Job:  map 100% reduce 26%18/12/13 02:52:04 INFO mapreduce.Job:  map 100% reduce 27%18/12/13 02:52:10 INFO mapreduce.Job:  map 100% reduce 29%18/12/13 02:52:16 INFO mapreduce.Job:  map 100% reduce 31%18/12/13 02:52:22 INFO mapreduce.Job:  map 100% reduce 33%18/12/13 02:52:34 INFO mapreduce.Job:  map 100% reduce 34%18/12/13 02:52:46 INFO mapreduce.Job:  map 100% reduce 35%18/12/13 02:52:58 INFO mapreduce.Job:  map 100% reduce 36%18/12/13 02:53:22 INFO mapreduce.Job:  map 100% reduce 37%18/12/13 02:53:34 INFO mapreduce.Job:  map 100% reduce 38%18/12/13 02:53:46 INFO mapreduce.Job:  map 100% reduce 39%18/12/13 02:53:59 INFO mapreduce.Job:  map 100% reduce 40%18/12/13 02:54:53 INFO mapreduce.Job:  map 100% reduce 41%18/12/13 02:55:41 INFO mapreduce.Job:  map 100% reduce 42%18/12/13 02:56:22 INFO mapreduce.Job:  map 100% reduce 43%18/12/13 02:56:34 INFO mapreduce.Job:  map 100% reduce 44%18/12/13 02:57:52 INFO mapreduce.Job:  map 100% reduce 47%18/12/13 02:57:58 INFO mapreduce.Job:  map 100% reduce 50%18/12/13 02:58:04 INFO mapreduce.Job:  map 100% reduce 52%18/12/13 02:58:34 INFO mapreduce.Job:  map 100% reduce 53%18/12/13 02:59:15 INFO mapreduce.Job:  map 100% reduce 54%18/12/13 02:59:21 INFO mapreduce.Job:  map 100% reduce 55%18/12/13 02:59:27 INFO mapreduce.Job:  map 100% reduce 56%18/12/13 03:01:16 INFO mapreduce.Job:  map 100% reduce 57%18/12/13 03:01:40 INFO mapreduce.Job:  map 100% reduce 58%18/12/13 03:02:04 INFO mapreduce.Job:  map 100% reduce 59%18/12/13 03:02:10 INFO mapreduce.Job:  map 100% reduce 60%18/12/13 03:02:16 INFO mapreduce.Job:  map 100% reduce 61%18/12/13 03:02:23 INFO mapreduce.Job:  map 100% reduce 62%18/12/13 03:02:34 INFO mapreduce.Job:  map 100% reduce 63%18/12/13 03:02:40 INFO mapreduce.Job:  map 100% reduce 64%18/12/13 03:02:52 INFO mapreduce.Job:  map 100% reduce 65%18/12/13 03:03:11 INFO mapreduce.Job:  map 100% reduce 66%18/12/13 03:03:53 INFO mapreduce.Job:  map 100% reduce 67%18/12/13 03:04:40 INFO mapreduce.Job:  map 100% reduce 68%18/12/13 03:05:41 INFO mapreduce.Job:  map 100% reduce 69%18/12/13 03:06:41 INFO mapreduce.Job:  map 100% reduce 70%18/12/13 03:12:18 INFO mapreduce.Job:  map 100% reduce 71%18/12/13 03:12:36 INFO mapreduce.Job:  map 100% reduce 72%18/12/13 03:12:54 INFO mapreduce.Job:  map 100% reduce 73%18/12/13 03:13:12 INFO mapreduce.Job:  map 100% reduce 74%18/12/13 03:13:30 INFO mapreduce.Job:  map 100% reduce 75%18/12/13 03:13:48 INFO mapreduce.Job:  map 100% reduce 76%18/12/13 03:14:06 INFO mapreduce.Job:  map 100% reduce 77%18/12/13 03:14:23 INFO mapreduce.Job:  map 100% reduce 78%18/12/13 03:14:41 INFO mapreduce.Job:  map 100% reduce 79%18/12/13 03:14:59 INFO mapreduce.Job:  map 100% reduce 80%18/12/13 03:15:17 INFO mapreduce.Job:  map 100% reduce 81%18/12/13 03:15:35 INFO mapreduce.Job:  map 100% reduce 82%18/12/13 03:15:53 INFO mapreduce.Job:  map 100% reduce 83%18/12/13 03:16:11 INFO mapreduce.Job:  map 100% reduce 84%18/12/13 03:16:29 INFO mapreduce.Job:  map 100% reduce 85%18/12/13 03:18:54 INFO mapreduce.Job:  map 100% reduce 86%18/12/13 03:19:12 INFO mapreduce.Job:  map 100% reduce 87%18/12/13 03:19:18 INFO mapreduce.Job:  map 100% reduce 88%18/12/13 03:20:06 INFO mapreduce.Job:  map 100% reduce 89%18/12/13 03:21:06 INFO mapreduce.Job:  map 100% reduce 90%18/12/13 03:22:00 INFO mapreduce.Job:  map 100% reduce 91%18/12/13 03:23:00 INFO mapreduce.Job:  map 100% reduce 92%18/12/13 03:23:59 INFO mapreduce.Job:  map 100% reduce 93%18/12/13 03:24:55 INFO mapreduce.Job:  map 100% reduce 94%18/12/13 03:25:54 INFO mapreduce.Job:  map 100% reduce 95%18/12/13 03:26:54 INFO mapreduce.Job:  map 100% reduce 96%18/12/13 03:27:48 INFO mapreduce.Job:  map 100% reduce 97%18/12/13 03:28:48 INFO mapreduce.Job:  map 100% reduce 98%18/12/13 03:29:48 INFO mapreduce.Job:  map 100% reduce 99%18/12/13 03:30:42 INFO mapreduce.Job:  map 100% reduce 100%18/12/13 03:31:13 INFO mapreduce.Job: Job job_1544668740052_0001 completed successfully18/12/13 03:31:14 INFO mapreduce.Job: Counters: 52\n\tFile System Counters\n\t\tFILE: Number of bytes read=382391980420\n\t\tFILE: Number of bytes written=502098175232\n\t\tFILE: Number of read operations=0\n\t\tFILE: Number of large read operations=0\n\t\tFILE: Number of write operations=0\n\t\tHDFS: Number of bytes read=115000088274\n\t\tHDFS: Number of bytes written=115000000000\n\t\tHDFS: Number of read operations=2655\n\t\tHDFS: Number of large read operations=0\n\t\tHDFS: Number of write operations=22\n\tJob Counters \n\t\tKilled map tasks=2\n\t\tKilled reduce tasks=9\n\t\tLaunched map tasks=876\n\t\tLaunched reduce tasks=20\n\t\tData-local map tasks=842\n\t\tRack-local map tasks=34\n\t\tTotal time spent by all maps in occupied slots (ms)=40283774\n\t\tTotal time spent by all reduces in occupied slots (ms)=34624321\n\t\tTotal time spent by all map tasks (ms)=40283774\n\t\tTotal time spent by all reduce tasks (ms)=34624321\n\t\tTotal vcore-milliseconds taken by all map tasks=40283774\n\t\tTotal vcore-milliseconds taken by all reduce tasks=34624321\n\t\tTotal megabyte-milliseconds taken by all map tasks=41250584576\n\t\tTotal megabyte-milliseconds taken by all reduce tasks=35455304704\n\tMap-Reduce Framework\n\t\tMap input records=1150000000\n\t\tMap output records=1150000000\n\t\tMap output bytes=117300000000\n\t\tMap output materialized bytes=119600057684\n\t\tInput split bytes=88274\n\t\tCombine input records=0\n\t\tCombine output records=0\n\t\tReduce input groups=1150000000\n\t\tReduce shuffle bytes=119600057684\n\t\tReduce input records=1150000000\n\t\tReduce output records=1150000000\n\t\tSpilled Records=4826512047\n\t\tShuffled Maps =9614\n\t\tFailed Shuffles=0\n\t\tMerged Map outputs=9614\n\t\tGC time elapsed (ms)=336492\n\t\tCPU time spent (ms)=14241110\n\t\tPhysical memory (bytes) snapshot=264201900032\n\t\tVirtual memory (bytes) snapshot=1782889541632\n\t\tTotal committed heap usage (bytes)=174303739904\n\tShuffle Errors\n\t\tBAD_ID=0\n\t\tCONNECTION=0\n\t\tIO_ERROR=0\n\t\tWRONG_LENGTH=0\n\t\tWRONG_MAP=0\n\t\tWRONG_REDUCE=0\n\tFile Input Format Counters \n\t\tBytes Read=115000000000\n\tFile Output Format Counters \n\t\tBytes Written=11500000000018/12/13 03:31:14 INFO terasort.TeraSort: donereal\t47m52.609s\nuser\t0m17.768s\nsys\t0m3.040s", :stdout=>"Spent 198ms computing base-splits.Spent 5ms computing TeraScheduler splits.\nComputing input splits took 204msSampling 10 splits of 874Making 11 from 100000 sampled recordsComputing parititions took 1913msSpent 2119ms computing partitions.", :status=>0}}
Exp  5, overall time taken is 47 m 52.609 s
Exp  5 termintated at 2018-12-13 04:31:14 +0100

