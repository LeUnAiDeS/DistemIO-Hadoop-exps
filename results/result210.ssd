Exp  1 started at  2018-12-30 06:29:08 +0100
Exp 1's result is {"10.158.0.1"=>{:stderr=>"18/12/30 05:29:11 INFO terasort.TeraSort: starting18/12/30 05:29:11 INFO input.FileInputFormat: Total input files to process : 2418/12/30 05:29:13 INFO client.RMProxy: Connecting to ResourceManager at node1/10.158.0.1:803218/12/30 05:29:14 INFO mapreduce.JobSubmitter: number of splits:91218/12/30 05:29:14 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces18/12/30 05:29:14 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1546147445320_000118/12/30 05:29:15 INFO impl.YarnClientImpl: Submitted application application_1546147445320_000118/12/30 05:29:15 INFO mapreduce.Job: The url to track the job: http://node1:8088/proxy/application_1546147445320_0001/18/12/30 05:29:15 INFO mapreduce.Job: Running job: job_1546147445320_000118/12/30 05:29:21 INFO mapreduce.Job: Job job_1546147445320_0001 running in uber mode : false18/12/30 05:29:21 INFO mapreduce.Job:  map 0% reduce 0%18/12/30 05:29:33 INFO mapreduce.Job:  map 8% reduce 0%18/12/30 05:29:34 INFO mapreduce.Job:  map 23% reduce 0%18/12/30 05:29:35 INFO mapreduce.Job:  map 31% reduce 0%18/12/30 05:29:42 INFO mapreduce.Job:  map 32% reduce 0%18/12/30 05:29:43 INFO mapreduce.Job:  map 37% reduce 0%18/12/30 05:29:44 INFO mapreduce.Job:  map 51% reduce 0%18/12/30 05:29:45 INFO mapreduce.Job:  map 60% reduce 0%18/12/30 05:29:46 INFO mapreduce.Job:  map 61% reduce 0%18/12/30 05:29:51 INFO mapreduce.Job:  map 62% reduce 4%18/12/30 05:29:52 INFO mapreduce.Job:  map 63% reduce 4%18/12/30 05:29:53 INFO mapreduce.Job:  map 67% reduce 4%18/12/30 05:29:54 INFO mapreduce.Job:  map 78% reduce 4%18/12/30 05:29:55 INFO mapreduce.Job:  map 89% reduce 4%18/12/30 05:29:56 INFO mapreduce.Job:  map 91% reduce 4%18/12/30 05:29:58 INFO mapreduce.Job:  map 92% reduce 6%18/12/30 05:29:59 INFO mapreduce.Job:  map 93% reduce 6%18/12/30 05:30:00 INFO mapreduce.Job:  map 94% reduce 6%18/12/30 05:30:01 INFO mapreduce.Job:  map 95% reduce 6%18/12/30 05:30:02 INFO mapreduce.Job:  map 96% reduce 6%18/12/30 05:30:03 INFO mapreduce.Job:  map 97% reduce 6%18/12/30 05:30:04 INFO mapreduce.Job:  map 98% reduce 8%18/12/30 05:30:05 INFO mapreduce.Job:  map 99% reduce 8%18/12/30 05:30:06 INFO mapreduce.Job:  map 100% reduce 8%18/12/30 05:30:10 INFO mapreduce.Job:  map 100% reduce 11%18/12/30 05:30:16 INFO mapreduce.Job:  map 100% reduce 13%18/12/30 05:30:22 INFO mapreduce.Job:  map 100% reduce 16%18/12/30 05:30:28 INFO mapreduce.Job:  map 100% reduce 18%18/12/30 05:30:34 INFO mapreduce.Job:  map 100% reduce 21%18/12/30 05:30:40 INFO mapreduce.Job:  map 100% reduce 23%18/12/30 05:30:46 INFO mapreduce.Job:  map 100% reduce 25%18/12/30 05:30:52 INFO mapreduce.Job:  map 100% reduce 28%18/12/30 05:30:58 INFO mapreduce.Job:  map 100% reduce 30%18/12/30 05:31:04 INFO mapreduce.Job:  map 100% reduce 32%18/12/30 05:31:10 INFO mapreduce.Job:  map 100% reduce 33%18/12/30 05:31:28 INFO mapreduce.Job:  map 100% reduce 34%18/12/30 05:31:34 INFO mapreduce.Job:  map 100% reduce 38%18/12/30 05:31:40 INFO mapreduce.Job:  map 100% reduce 45%18/12/30 05:31:46 INFO mapreduce.Job:  map 100% reduce 53%18/12/30 05:31:52 INFO mapreduce.Job:  map 100% reduce 59%18/12/30 05:31:58 INFO mapreduce.Job:  map 100% reduce 65%18/12/30 05:32:04 INFO mapreduce.Job:  map 100% reduce 69%18/12/30 05:32:10 INFO mapreduce.Job:  map 100% reduce 72%18/12/30 05:32:16 INFO mapreduce.Job:  map 100% reduce 74%18/12/30 05:32:22 INFO mapreduce.Job:  map 100% reduce 76%18/12/30 05:32:28 INFO mapreduce.Job:  map 100% reduce 78%18/12/30 05:32:34 INFO mapreduce.Job:  map 100% reduce 80%18/12/30 05:32:40 INFO mapreduce.Job:  map 100% reduce 82%18/12/30 05:32:45 INFO mapreduce.Job:  map 100% reduce 83%18/12/30 05:32:46 INFO mapreduce.Job:  map 100% reduce 84%18/12/30 05:32:51 INFO mapreduce.Job:  map 100% reduce 85%18/12/30 05:32:52 INFO mapreduce.Job:  map 100% reduce 86%18/12/30 05:32:57 INFO mapreduce.Job:  map 100% reduce 87%18/12/30 05:32:58 INFO mapreduce.Job:  map 100% reduce 88%18/12/30 05:33:03 INFO mapreduce.Job:  map 100% reduce 89%18/12/30 05:33:04 INFO mapreduce.Job:  map 100% reduce 90%18/12/30 05:33:09 INFO mapreduce.Job:  map 100% reduce 91%18/12/30 05:33:10 INFO mapreduce.Job:  map 100% reduce 92%18/12/30 05:33:15 INFO mapreduce.Job:  map 100% reduce 93%18/12/30 05:33:16 INFO mapreduce.Job:  map 100% reduce 94%18/12/30 05:33:21 INFO mapreduce.Job:  map 100% reduce 95%18/12/30 05:33:26 INFO mapreduce.Job:  map 100% reduce 96%18/12/30 05:33:28 INFO mapreduce.Job:  map 100% reduce 97%18/12/30 05:33:34 INFO mapreduce.Job:  map 100% reduce 98%18/12/30 05:33:40 INFO mapreduce.Job:  map 100% reduce 99%18/12/30 05:33:52 INFO mapreduce.Job:  map 100% reduce 100%18/12/30 05:34:01 INFO mapreduce.Job: Job job_1546147445320_0001 completed successfully18/12/30 05:34:02 INFO mapreduce.Job: Counters: 51\n\tFile System Counters\n\t\tFILE: Number of bytes read=388025346952\n\t\tFILE: Number of bytes written=512932461176\n\t\tFILE: Number of read operations=0\n\t\tFILE: Number of large read operations=0\n\t\tFILE: Number of write operations=0\n\t\tHDFS: Number of bytes read=120000092112\n\t\tHDFS: Number of bytes written=120000000000\n\t\tHDFS: Number of read operations=2772\n\t\tHDFS: Number of large read operations=0\n\t\tHDFS: Number of write operations=24\n\tJob Counters \n\t\tKilled map tasks=1\n\t\tLaunched map tasks=912\n\t\tLaunched reduce tasks=12\n\t\tData-local map tasks=904\n\t\tRack-local map tasks=8\n\t\tTotal time spent by all maps in occupied slots (ms)=8140980\n\t\tTotal time spent by all reduces in occupied slots (ms)=2867846\n\t\tTotal time spent by all map tasks (ms)=8140980\n\t\tTotal time spent by all reduce tasks (ms)=2867846\n\t\tTotal vcore-milliseconds taken by all map tasks=8140980\n\t\tTotal vcore-milliseconds taken by all reduce tasks=2867846\n\t\tTotal megabyte-milliseconds taken by all map tasks=8336363520\n\t\tTotal megabyte-milliseconds taken by all reduce tasks=2936674304\n\tMap-Reduce Framework\n\t\tMap input records=1200000000\n\t\tMap output records=1200000000\n\t\tMap output bytes=122400000000\n\t\tMap output materialized bytes=124800065664\n\t\tInput split bytes=92112\n\t\tCombine input records=0\n\t\tCombine output records=0\n\t\tReduce input groups=1200000000\n\t\tReduce shuffle bytes=124800065664\n\t\tReduce input records=1200000000\n\t\tReduce output records=1200000000\n\t\tSpilled Records=4930627801\n\t\tShuffled Maps =10944\n\t\tFailed Shuffles=0\n\t\tMerged Map outputs=10944\n\t\tGC time elapsed (ms)=419966\n\t\tCPU time spent (ms)=14480580\n\t\tPhysical memory (bytes) snapshot=275650613248\n\t\tVirtual memory (bytes) snapshot=1861602983936\n\t\tTotal committed heap usage (bytes)=182375677952\n\tShuffle Errors\n\t\tBAD_ID=0\n\t\tCONNECTION=0\n\t\tIO_ERROR=0\n\t\tWRONG_LENGTH=0\n\t\tWRONG_MAP=0\n\t\tWRONG_REDUCE=0\n\tFile Input Format Counters \n\t\tBytes Read=120000000000\n\tFile Output Format Counters \n\t\tBytes Written=12000000000018/12/30 05:34:02 INFO terasort.TeraSort: donereal\t4m51.928s\nuser\t0m11.626s\nsys\t0m1.020s", :stdout=>"Spent 194ms computing base-splits.Spent 5ms computing TeraScheduler splits.\nComputing input splits took 200msSampling 10 splits of 912Making 12 from 100000 sampled recordsComputing parititions took 1303msSpent 1506ms computing partitions.", :status=>0}}
Exp  1, overall time taken is 4 m 51.928 s
Exp  1 termintated at 2018-12-30 06:34:02 +0100

Exp  2 started at  2018-12-30 06:51:25 +0100
Exp 2's result is {"10.158.0.1"=>{:stderr=>"18/12/30 05:51:28 INFO terasort.TeraSort: starting18/12/30 05:51:29 INFO input.FileInputFormat: Total input files to process : 2418/12/30 05:51:30 INFO client.RMProxy: Connecting to ResourceManager at node1/10.158.0.1:803218/12/30 05:51:31 INFO mapreduce.JobSubmitter: number of splits:91218/12/30 05:51:31 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces18/12/30 05:51:31 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1546148781422_000118/12/30 05:51:32 INFO impl.YarnClientImpl: Submitted application application_1546148781422_000118/12/30 05:51:32 INFO mapreduce.Job: The url to track the job: http://node1:8088/proxy/application_1546148781422_0001/18/12/30 05:51:32 INFO mapreduce.Job: Running job: job_1546148781422_000118/12/30 05:51:38 INFO mapreduce.Job: Job job_1546148781422_0001 running in uber mode : false18/12/30 05:51:38 INFO mapreduce.Job:  map 0% reduce 0%18/12/30 05:51:50 INFO mapreduce.Job:  map 8% reduce 0%18/12/30 05:51:51 INFO mapreduce.Job:  map 20% reduce 0%18/12/30 05:51:52 INFO mapreduce.Job:  map 30% reduce 0%18/12/30 05:51:59 INFO mapreduce.Job:  map 31% reduce 0%18/12/30 05:52:00 INFO mapreduce.Job:  map 37% reduce 0%18/12/30 05:52:01 INFO mapreduce.Job:  map 48% reduce 0%18/12/30 05:52:02 INFO mapreduce.Job:  map 55% reduce 0%18/12/30 05:52:03 INFO mapreduce.Job:  map 58% reduce 0%18/12/30 05:52:04 INFO mapreduce.Job:  map 59% reduce 0%18/12/30 05:52:08 INFO mapreduce.Job:  map 59% reduce 4%18/12/30 05:52:09 INFO mapreduce.Job:  map 60% reduce 4%18/12/30 05:52:10 INFO mapreduce.Job:  map 66% reduce 4%18/12/30 05:52:11 INFO mapreduce.Job:  map 76% reduce 4%18/12/30 05:52:12 INFO mapreduce.Job:  map 84% reduce 4%18/12/30 05:52:13 INFO mapreduce.Job:  map 86% reduce 4%18/12/30 05:52:14 INFO mapreduce.Job:  map 88% reduce 6%18/12/30 05:52:15 INFO mapreduce.Job:  map 89% reduce 6%18/12/30 05:52:16 INFO mapreduce.Job:  map 90% reduce 6%18/12/30 05:52:18 INFO mapreduce.Job:  map 91% reduce 6%18/12/30 05:52:19 INFO mapreduce.Job:  map 92% reduce 7%18/12/30 05:52:20 INFO mapreduce.Job:  map 94% reduce 8%18/12/30 05:52:23 INFO mapreduce.Job:  map 95% reduce 8%18/12/30 05:52:24 INFO mapreduce.Job:  map 96% reduce 8%18/12/30 05:52:26 INFO mapreduce.Job:  map 96% reduce 10%18/12/30 05:52:32 INFO mapreduce.Job:  map 96% reduce 11%18/12/30 05:52:33 INFO mapreduce.Job:  map 96% reduce 13%18/12/30 05:52:39 INFO mapreduce.Job:  map 96% reduce 15%18/12/30 05:52:44 INFO mapreduce.Job:  map 96% reduce 16%18/12/30 05:52:45 INFO mapreduce.Job:  map 96% reduce 18%18/12/30 05:52:51 INFO mapreduce.Job:  map 96% reduce 20%18/12/30 05:52:57 INFO mapreduce.Job:  map 96% reduce 22%18/12/30 05:53:02 INFO mapreduce.Job:  map 96% reduce 23%18/12/30 05:53:03 INFO mapreduce.Job:  map 96% reduce 25%18/12/30 05:53:09 INFO mapreduce.Job:  map 96% reduce 27%18/12/30 05:53:14 INFO mapreduce.Job:  map 96% reduce 28%18/12/30 05:53:15 INFO mapreduce.Job:  map 96% reduce 29%18/12/30 05:53:20 INFO mapreduce.Job:  map 96% reduce 30%18/12/30 05:53:21 INFO mapreduce.Job:  map 96% reduce 31%18/12/30 05:53:27 INFO mapreduce.Job:  map 96% reduce 32%18/12/30 05:55:42 INFO mapreduce.Job:  map 97% reduce 32%18/12/30 06:01:35 INFO mapreduce.Job:  map 98% reduce 32%18/12/30 06:07:21 INFO mapreduce.Job:  map 99% reduce 32%18/12/30 06:08:36 INFO mapreduce.Job:  map 100% reduce 32%18/12/30 06:08:39 INFO mapreduce.Job:  map 100% reduce 33%18/12/30 06:08:51 INFO mapreduce.Job:  map 100% reduce 35%18/12/30 06:08:52 INFO mapreduce.Job:  map 100% reduce 41%18/12/30 06:08:57 INFO mapreduce.Job:  map 100% reduce 45%18/12/30 06:08:58 INFO mapreduce.Job:  map 100% reduce 65%18/12/30 06:09:03 INFO mapreduce.Job:  map 100% reduce 66%18/12/30 06:09:04 INFO mapreduce.Job:  map 100% reduce 68%18/12/30 06:09:09 INFO mapreduce.Job:  map 100% reduce 69%18/12/30 06:09:10 INFO mapreduce.Job:  map 100% reduce 70%18/12/30 06:09:15 INFO mapreduce.Job:  map 100% reduce 71%18/12/30 06:09:16 INFO mapreduce.Job:  map 100% reduce 72%18/12/30 06:09:21 INFO mapreduce.Job:  map 100% reduce 73%18/12/30 06:09:22 INFO mapreduce.Job:  map 100% reduce 74%18/12/30 06:09:27 INFO mapreduce.Job:  map 100% reduce 75%18/12/30 06:09:28 INFO mapreduce.Job:  map 100% reduce 76%18/12/30 06:09:34 INFO mapreduce.Job:  map 100% reduce 78%18/12/30 06:09:40 INFO mapreduce.Job:  map 100% reduce 80%18/12/30 06:09:46 INFO mapreduce.Job:  map 100% reduce 82%18/12/30 06:09:52 INFO mapreduce.Job:  map 100% reduce 84%18/12/30 06:09:58 INFO mapreduce.Job:  map 100% reduce 86%18/12/30 06:10:04 INFO mapreduce.Job:  map 100% reduce 88%18/12/30 06:10:10 INFO mapreduce.Job:  map 100% reduce 90%18/12/30 06:10:16 INFO mapreduce.Job:  map 100% reduce 92%18/12/30 06:10:22 INFO mapreduce.Job:  map 100% reduce 94%18/12/30 06:10:28 INFO mapreduce.Job:  map 100% reduce 96%18/12/30 06:10:34 INFO mapreduce.Job:  map 100% reduce 97%18/12/30 06:10:39 INFO mapreduce.Job:  map 100% reduce 98%18/12/30 06:10:40 INFO mapreduce.Job:  map 100% reduce 99%18/12/30 06:10:46 INFO mapreduce.Job:  map 100% reduce 100%18/12/30 06:10:54 INFO mapreduce.Job: Job job_1546148781422_0001 completed successfully18/12/30 06:10:54 INFO mapreduce.Job: Counters: 51\n\tFile System Counters\n\t\tFILE: Number of bytes read=395466496616\n\t\tFILE: Number of bytes written=520373610840\n\t\tFILE: Number of read operations=0\n\t\tFILE: Number of large read operations=0\n\t\tFILE: Number of write operations=0\n\t\tHDFS: Number of bytes read=120000092112\n\t\tHDFS: Number of bytes written=120000000000\n\t\tHDFS: Number of read operations=2772\n\t\tHDFS: Number of large read operations=0\n\t\tHDFS: Number of write operations=24\n\tJob Counters \n\t\tKilled map tasks=11\n\t\tLaunched map tasks=923\n\t\tLaunched reduce tasks=12\n\t\tData-local map tasks=882\n\t\tRack-local map tasks=41\n\t\tTotal time spent by all maps in occupied slots (ms)=52794794\n\t\tTotal time spent by all reduces in occupied slots (ms)=13542185\n\t\tTotal time spent by all map tasks (ms)=52794794\n\t\tTotal time spent by all reduce tasks (ms)=13542185\n\t\tTotal vcore-milliseconds taken by all map tasks=52794794\n\t\tTotal vcore-milliseconds taken by all reduce tasks=13542185\n\t\tTotal megabyte-milliseconds taken by all map tasks=54061869056\n\t\tTotal megabyte-milliseconds taken by all reduce tasks=13867197440\n\tMap-Reduce Framework\n\t\tMap input records=1200000000\n\t\tMap output records=1200000000\n\t\tMap output bytes=122400000000\n\t\tMap output materialized bytes=124800065664\n\t\tInput split bytes=92112\n\t\tCombine input records=0\n\t\tCombine output records=0\n\t\tReduce input groups=1200000000\n\t\tReduce shuffle bytes=124800065664\n\t\tReduce input records=1200000000\n\t\tReduce output records=1200000000\n\t\tSpilled Records=5002177317\n\t\tShuffled Maps =10944\n\t\tFailed Shuffles=0\n\t\tMerged Map outputs=10944\n\t\tGC time elapsed (ms)=415199\n\t\tCPU time spent (ms)=14526950\n\t\tPhysical memory (bytes) snapshot=275740082176\n\t\tVirtual memory (bytes) snapshot=1861673885696\n\t\tTotal committed heap usage (bytes)=182409232384\n\tShuffle Errors\n\t\tBAD_ID=0\n\t\tCONNECTION=0\n\t\tIO_ERROR=0\n\t\tWRONG_LENGTH=0\n\t\tWRONG_MAP=0\n\t\tWRONG_REDUCE=0\n\tFile Input Format Counters \n\t\tBytes Read=120000000000\n\tFile Output Format Counters \n\t\tBytes Written=12000000000018/12/30 06:10:54 INFO terasort.TeraSort: donereal\t19m27.175s\nuser\t0m13.639s\nsys\t0m1.846s", :stdout=>"Spent 196ms computing base-splits.Spent 5ms computing TeraScheduler splits.Computing input splits took 201msSampling 10 splits of 912Making 12 from 100000 sampled recordsComputing parititions took 1331msSpent 1535ms computing partitions.", :status=>0}}
Exp  2, overall time taken is 19 m 27.175 s
Exp  2 termintated at 2018-12-30 07:10:55 +0100

Exp  3 started at  2018-12-30 07:28:18 +0100
Exp 3's result is {"10.158.0.1"=>{:stderr=>"18/12/30 06:28:20 INFO terasort.TeraSort: starting18/12/30 06:28:21 INFO input.FileInputFormat: Total input files to process : 2418/12/30 06:28:22 INFO client.RMProxy: Connecting to ResourceManager at node1/10.158.0.1:803218/12/30 06:28:23 INFO mapreduce.JobSubmitter: number of splits:91218/12/30 06:28:23 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces18/12/30 06:28:24 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1546150992059_000118/12/30 06:28:24 INFO impl.YarnClientImpl: Submitted application application_1546150992059_000118/12/30 06:28:24 INFO mapreduce.Job: The url to track the job: http://node1:8088/proxy/application_1546150992059_0001/18/12/30 06:28:24 INFO mapreduce.Job: Running job: job_1546150992059_000118/12/30 06:28:30 INFO mapreduce.Job: Job job_1546150992059_0001 running in uber mode : false18/12/30 06:28:30 INFO mapreduce.Job:  map 0% reduce 0%18/12/30 06:28:47 INFO mapreduce.Job:  map 1% reduce 0%18/12/30 06:28:48 INFO mapreduce.Job:  map 5% reduce 0%18/12/30 06:28:49 INFO mapreduce.Job:  map 9% reduce 0%18/12/30 06:28:50 INFO mapreduce.Job:  map 10% reduce 0%18/12/30 06:28:54 INFO mapreduce.Job:  map 12% reduce 0%18/12/30 06:28:55 INFO mapreduce.Job:  map 14% reduce 0%18/12/30 06:28:56 INFO mapreduce.Job:  map 15% reduce 0%18/12/30 06:29:00 INFO mapreduce.Job:  map 17% reduce 0%18/12/30 06:29:01 INFO mapreduce.Job:  map 19% reduce 0%18/12/30 06:29:02 INFO mapreduce.Job:  map 20% reduce 0%18/12/30 06:29:05 INFO mapreduce.Job:  map 21% reduce 0%18/12/30 06:29:06 INFO mapreduce.Job:  map 26% reduce 0%18/12/30 06:29:08 INFO mapreduce.Job:  map 31% reduce 0%18/12/30 06:29:09 INFO mapreduce.Job:  map 32% reduce 0%18/12/30 06:29:19 INFO mapreduce.Job:  map 33% reduce 0%18/12/30 06:29:20 INFO mapreduce.Job:  map 34% reduce 0%18/12/30 06:29:21 INFO mapreduce.Job:  map 35% reduce 0%18/12/30 06:29:22 INFO mapreduce.Job:  map 37% reduce 0%18/12/30 06:29:23 INFO mapreduce.Job:  map 40% reduce 5%18/12/30 06:29:24 INFO mapreduce.Job:  map 43% reduce 5%18/12/30 06:29:26 INFO mapreduce.Job:  map 44% reduce 5%18/12/30 06:29:28 INFO mapreduce.Job:  map 45% reduce 5%18/12/30 06:29:29 INFO mapreduce.Job:  map 47% reduce 7%18/12/30 06:29:30 INFO mapreduce.Job:  map 48% reduce 7%18/12/30 06:29:32 INFO mapreduce.Job:  map 49% reduce 7%18/12/30 06:29:33 INFO mapreduce.Job:  map 50% reduce 7%18/12/30 06:29:34 INFO mapreduce.Job:  map 51% reduce 7%18/12/30 06:29:35 INFO mapreduce.Job:  map 53% reduce 9%18/12/30 06:29:36 INFO mapreduce.Job:  map 55% reduce 9%18/12/30 06:29:37 INFO mapreduce.Job:  map 56% reduce 9%18/12/30 06:29:38 INFO mapreduce.Job:  map 57% reduce 9%18/12/30 06:29:39 INFO mapreduce.Job:  map 60% reduce 9%18/12/30 06:29:40 INFO mapreduce.Job:  map 62% reduce 9%18/12/30 06:29:41 INFO mapreduce.Job:  map 63% reduce 11%18/12/30 06:29:42 INFO mapreduce.Job:  map 64% reduce 11%18/12/30 06:29:44 INFO mapreduce.Job:  map 65% reduce 11%18/12/30 06:29:46 INFO mapreduce.Job:  map 66% reduce 11%18/12/30 06:29:47 INFO mapreduce.Job:  map 66% reduce 13%18/12/30 06:29:49 INFO mapreduce.Job:  map 67% reduce 13%18/12/30 06:29:51 INFO mapreduce.Job:  map 68% reduce 13%18/12/30 06:29:53 INFO mapreduce.Job:  map 69% reduce 15%18/12/30 06:29:54 INFO mapreduce.Job:  map 69% reduce 16%18/12/30 06:29:56 INFO mapreduce.Job:  map 70% reduce 16%18/12/30 06:29:57 INFO mapreduce.Job:  map 71% reduce 16%18/12/30 06:29:58 INFO mapreduce.Job:  map 72% reduce 16%18/12/30 06:29:59 INFO mapreduce.Job:  map 73% reduce 18%18/12/30 06:30:00 INFO mapreduce.Job:  map 74% reduce 18%18/12/30 06:30:01 INFO mapreduce.Job:  map 75% reduce 18%18/12/30 06:30:02 INFO mapreduce.Job:  map 77% reduce 18%18/12/30 06:30:03 INFO mapreduce.Job:  map 78% reduce 18%18/12/30 06:30:04 INFO mapreduce.Job:  map 79% reduce 18%18/12/30 06:30:05 INFO mapreduce.Job:  map 80% reduce 20%18/12/30 06:30:06 INFO mapreduce.Job:  map 80% reduce 21%18/12/30 06:30:07 INFO mapreduce.Job:  map 82% reduce 21%18/12/30 06:30:08 INFO mapreduce.Job:  map 83% reduce 21%18/12/30 06:30:10 INFO mapreduce.Job:  map 84% reduce 21%18/12/30 06:30:11 INFO mapreduce.Job:  map 84% reduce 22%18/12/30 06:30:12 INFO mapreduce.Job:  map 86% reduce 23%18/12/30 06:30:13 INFO mapreduce.Job:  map 87% reduce 23%18/12/30 06:30:14 INFO mapreduce.Job:  map 89% reduce 23%18/12/30 06:30:15 INFO mapreduce.Job:  map 90% reduce 23%18/12/30 06:30:16 INFO mapreduce.Job:  map 91% reduce 23%18/12/30 06:30:17 INFO mapreduce.Job:  map 93% reduce 24%18/12/30 06:30:18 INFO mapreduce.Job:  map 94% reduce 24%18/12/30 06:30:19 INFO mapreduce.Job:  map 95% reduce 24%18/12/30 06:30:20 INFO mapreduce.Job:  map 96% reduce 24%18/12/30 06:30:23 INFO mapreduce.Job:  map 96% reduce 25%18/12/30 06:30:25 INFO mapreduce.Job:  map 97% reduce 25%18/12/30 06:30:29 INFO mapreduce.Job:  map 97% reduce 26%18/12/30 06:30:30 INFO mapreduce.Job:  map 97% reduce 27%18/12/30 06:30:32 INFO mapreduce.Job:  map 98% reduce 27%18/12/30 06:30:38 INFO mapreduce.Job:  map 99% reduce 27%18/12/30 06:30:44 INFO mapreduce.Job:  map 100% reduce 27%18/12/30 06:30:47 INFO mapreduce.Job:  map 100% reduce 28%18/12/30 06:31:29 INFO mapreduce.Job:  map 100% reduce 29%18/12/30 06:32:11 INFO mapreduce.Job:  map 100% reduce 30%18/12/30 06:33:13 INFO mapreduce.Job:  map 100% reduce 31%18/12/30 06:33:48 INFO mapreduce.Job:  map 100% reduce 32%18/12/30 06:34:19 INFO mapreduce.Job:  map 100% reduce 33%18/12/30 06:36:53 INFO mapreduce.Job:  map 100% reduce 38%18/12/30 06:36:59 INFO mapreduce.Job:  map 100% reduce 43%18/12/30 06:37:05 INFO mapreduce.Job:  map 100% reduce 47%18/12/30 06:38:30 INFO mapreduce.Job:  map 100% reduce 49%18/12/30 06:38:36 INFO mapreduce.Job:  map 100% reduce 50%18/12/30 06:39:42 INFO mapreduce.Job:  map 100% reduce 51%18/12/30 06:40:00 INFO mapreduce.Job:  map 100% reduce 52%18/12/30 06:40:18 INFO mapreduce.Job:  map 100% reduce 53%18/12/30 06:40:24 INFO mapreduce.Job:  map 100% reduce 54%18/12/30 06:40:37 INFO mapreduce.Job:  map 100% reduce 55%18/12/30 06:40:42 INFO mapreduce.Job:  map 100% reduce 56%18/12/30 06:40:48 INFO mapreduce.Job:  map 100% reduce 57%18/12/30 06:40:55 INFO mapreduce.Job:  map 100% reduce 58%18/12/30 06:41:00 INFO mapreduce.Job:  map 100% reduce 59%18/12/30 06:41:01 INFO mapreduce.Job:  map 100% reduce 60%18/12/30 06:41:24 INFO mapreduce.Job:  map 100% reduce 61%18/12/30 06:41:54 INFO mapreduce.Job:  map 100% reduce 62%18/12/30 06:42:35 INFO mapreduce.Job:  map 100% reduce 63%18/12/30 06:42:36 INFO mapreduce.Job:  map 100% reduce 64%18/12/30 06:42:47 INFO mapreduce.Job:  map 100% reduce 65%18/12/30 06:42:59 INFO mapreduce.Job:  map 100% reduce 66%18/12/30 06:43:11 INFO mapreduce.Job:  map 100% reduce 67%18/12/30 06:43:13 INFO mapreduce.Job:  map 100% reduce 68%18/12/30 06:43:17 INFO mapreduce.Job:  map 100% reduce 69%18/12/30 06:43:19 INFO mapreduce.Job:  map 100% reduce 71%18/12/30 06:43:23 INFO mapreduce.Job:  map 100% reduce 73%18/12/30 06:43:24 INFO mapreduce.Job:  map 100% reduce 75%18/12/30 06:43:25 INFO mapreduce.Job:  map 100% reduce 76%18/12/30 06:43:29 INFO mapreduce.Job:  map 100% reduce 79%18/12/30 06:43:30 INFO mapreduce.Job:  map 100% reduce 80%18/12/30 06:43:36 INFO mapreduce.Job:  map 100% reduce 81%18/12/30 06:43:47 INFO mapreduce.Job:  map 100% reduce 82%18/12/30 06:43:59 INFO mapreduce.Job:  map 100% reduce 83%18/12/30 06:46:36 INFO mapreduce.Job:  map 100% reduce 84%18/12/30 06:46:42 INFO mapreduce.Job:  map 100% reduce 85%18/12/30 06:46:50 INFO mapreduce.Job:  map 100% reduce 86%18/12/30 06:47:00 INFO mapreduce.Job:  map 100% reduce 87%18/12/30 06:47:06 INFO mapreduce.Job:  map 100% reduce 88%18/12/30 06:47:12 INFO mapreduce.Job:  map 100% reduce 89%18/12/30 06:47:19 INFO mapreduce.Job:  map 100% reduce 90%18/12/30 06:47:26 INFO mapreduce.Job:  map 100% reduce 91%18/12/30 06:47:36 INFO mapreduce.Job:  map 100% reduce 92%18/12/30 06:47:42 INFO mapreduce.Job:  map 100% reduce 93%18/12/30 06:47:50 INFO mapreduce.Job:  map 100% reduce 94%18/12/30 06:48:07 INFO mapreduce.Job:  map 100% reduce 95%18/12/30 06:48:30 INFO mapreduce.Job:  map 100% reduce 96%18/12/30 06:48:54 INFO mapreduce.Job:  map 100% reduce 97%18/12/30 06:49:13 INFO mapreduce.Job:  map 100% reduce 98%18/12/30 06:49:42 INFO mapreduce.Job:  map 100% reduce 99%18/12/30 06:50:11 INFO mapreduce.Job:  map 100% reduce 100%18/12/30 06:54:25 INFO mapreduce.Job: Job job_1546150992059_0001 completed successfully18/12/30 06:54:25 INFO mapreduce.Job: Counters: 52\n\tFile System Counters\n\t\tFILE: Number of bytes read=391540467918\n\t\tFILE: Number of bytes written=516447582142\n\t\tFILE: Number of read operations=0\n\t\tFILE: Number of large read operations=0\n\t\tFILE: Number of write operations=0\n\t\tHDFS: Number of bytes read=120000092112\n\t\tHDFS: Number of bytes written=120000000000\n\t\tHDFS: Number of read operations=2772\n\t\tHDFS: Number of large read operations=0\n\t\tHDFS: Number of write operations=24\n\tJob Counters \n\t\tKilled map tasks=1\n\t\tKilled reduce tasks=5\n\t\tLaunched map tasks=912\n\t\tLaunched reduce tasks=17\n\t\tData-local map tasks=883\n\t\tRack-local map tasks=29\n\t\tTotal time spent by all maps in occupied slots (ms)=28558345\n\t\tTotal time spent by all reduces in occupied slots (ms)=16982086\n\t\tTotal time spent by all map tasks (ms)=28558345\n\t\tTotal time spent by all reduce tasks (ms)=16982086\n\t\tTotal vcore-milliseconds taken by all map tasks=28558345\n\t\tTotal vcore-milliseconds taken by all reduce tasks=16982086\n\t\tTotal megabyte-milliseconds taken by all map tasks=29243745280\n\t\tTotal megabyte-milliseconds taken by all reduce tasks=17389656064\n\tMap-Reduce Framework\n\t\tMap input records=1200000000\n\t\tMap output records=1200000000\n\t\tMap output bytes=122400000000\n\t\tMap output materialized bytes=124800065664\n\t\tInput split bytes=92112\n\t\tCombine input records=0\n\t\tCombine output records=0\n\t\tReduce input groups=1200000000\n\t\tReduce shuffle bytes=124800065664\n\t\tReduce input records=1200000000\n\t\tReduce output records=1200000000\n\t\tSpilled Records=4964427041\n\t\tShuffled Maps =10944\n\t\tFailed Shuffles=0\n\t\tMerged Map outputs=10944\n\t\tGC time elapsed (ms)=338350\n\t\tCPU time spent (ms)=14260450\n\t\tPhysical memory (bytes) snapshot=275771244544\n\t\tVirtual memory (bytes) snapshot=1861506662400\n\t\tTotal committed heap usage (bytes)=182035939328\n\tShuffle Errors\n\t\tBAD_ID=0\n\t\tCONNECTION=0\n\t\tIO_ERROR=0\n\t\tWRONG_LENGTH=0\n\t\tWRONG_MAP=0\n\t\tWRONG_REDUCE=0\n\tFile Input Format Counters \n\t\tBytes Read=120000000000\n\tFile Output Format Counters \n\t\tBytes Written=12000000000018/12/30 06:54:25 INFO terasort.TeraSort: donereal\t26m6.098s\nuser\t0m14.509s\nsys\t0m1.997s", :stdout=>"Spent 198ms computing base-splits.Spent 5ms computing TeraScheduler splits.\nComputing input splits took 204msSampling 10 splits of 912Making 12 from 100000 sampled recordsComputing parititions took 1255msSpent 1461ms computing partitions.", :status=>0}}
Exp  3, overall time taken is 26 m 6.098 s
Exp  3 termintated at 2018-12-30 07:54:26 +0100

Exp  4 started at  2018-12-30 08:12:05 +0100
Exp 4's result is {"10.158.0.1"=>{:stderr=>"18/12/30 07:12:08 INFO terasort.TeraSort: starting18/12/30 07:12:08 INFO input.FileInputFormat: Total input files to process : 2418/12/30 07:12:10 INFO client.RMProxy: Connecting to ResourceManager at node1/10.158.0.1:803218/12/30 07:12:10 INFO mapreduce.JobSubmitter: number of splits:91218/12/30 07:12:10 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces18/12/30 07:12:11 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1546153616504_000118/12/30 07:12:11 INFO impl.YarnClientImpl: Submitted application application_1546153616504_000118/12/30 07:12:11 INFO mapreduce.Job: The url to track the job: http://node1:8088/proxy/application_1546153616504_0001/18/12/30 07:12:11 INFO mapreduce.Job: Running job: job_1546153616504_000118/12/30 07:12:17 INFO mapreduce.Job: Job job_1546153616504_0001 running in uber mode : false18/12/30 07:12:17 INFO mapreduce.Job:  map 0% reduce 0%18/12/30 07:12:35 INFO mapreduce.Job:  map 1% reduce 0%18/12/30 07:12:36 INFO mapreduce.Job:  map 3% reduce 0%18/12/30 07:12:37 INFO mapreduce.Job:  map 5% reduce 0%18/12/30 07:12:42 INFO mapreduce.Job:  map 6% reduce 0%18/12/30 07:12:43 INFO mapreduce.Job:  map 7% reduce 0%18/12/30 07:12:48 INFO mapreduce.Job:  map 9% reduce 0%18/12/30 07:12:53 INFO mapreduce.Job:  map 10% reduce 0%18/12/30 07:12:54 INFO mapreduce.Job:  map 11% reduce 0%18/12/30 07:12:55 INFO mapreduce.Job:  map 12% reduce 0%18/12/30 07:13:00 INFO mapreduce.Job:  map 13% reduce 0%18/12/30 07:13:01 INFO mapreduce.Job:  map 14% reduce 0%18/12/30 07:13:06 INFO mapreduce.Job:  map 15% reduce 0%18/12/30 07:13:07 INFO mapreduce.Job:  map 16% reduce 0%18/12/30 07:13:12 INFO mapreduce.Job:  map 17% reduce 0%18/12/30 07:13:13 INFO mapreduce.Job:  map 18% reduce 0%18/12/30 07:13:14 INFO mapreduce.Job:  map 19% reduce 0%18/12/30 07:13:18 INFO mapreduce.Job:  map 20% reduce 0%18/12/30 07:13:19 INFO mapreduce.Job:  map 21% reduce 0%18/12/30 07:13:20 INFO mapreduce.Job:  map 22% reduce 0%18/12/30 07:13:21 INFO mapreduce.Job:  map 23% reduce 0%18/12/30 07:13:22 INFO mapreduce.Job:  map 24% reduce 0%18/12/30 07:13:23 INFO mapreduce.Job:  map 25% reduce 0%18/12/30 07:13:24 INFO mapreduce.Job:  map 26% reduce 0%18/12/30 07:13:25 INFO mapreduce.Job:  map 27% reduce 0%18/12/30 07:13:26 INFO mapreduce.Job:  map 28% reduce 0%18/12/30 07:13:34 INFO mapreduce.Job:  map 29% reduce 0%18/12/30 07:13:36 INFO mapreduce.Job:  map 30% reduce 0%18/12/30 07:13:37 INFO mapreduce.Job:  map 31% reduce 0%18/12/30 07:13:38 INFO mapreduce.Job:  map 31% reduce 4%18/12/30 07:13:39 INFO mapreduce.Job:  map 32% reduce 4%18/12/30 07:13:40 INFO mapreduce.Job:  map 33% reduce 4%18/12/30 07:13:42 INFO mapreduce.Job:  map 34% reduce 4%18/12/30 07:13:43 INFO mapreduce.Job:  map 35% reduce 4%18/12/30 07:13:44 INFO mapreduce.Job:  map 35% reduce 6%18/12/30 07:13:45 INFO mapreduce.Job:  map 36% reduce 6%18/12/30 07:13:47 INFO mapreduce.Job:  map 37% reduce 6%18/12/30 07:13:50 INFO mapreduce.Job:  map 38% reduce 8%18/12/30 07:13:54 INFO mapreduce.Job:  map 39% reduce 8%18/12/30 07:13:56 INFO mapreduce.Job:  map 40% reduce 10%18/12/30 07:13:58 INFO mapreduce.Job:  map 41% reduce 10%18/12/30 07:14:00 INFO mapreduce.Job:  map 42% reduce 10%18/12/30 07:14:02 INFO mapreduce.Job:  map 43% reduce 10%18/12/30 07:14:05 INFO mapreduce.Job:  map 44% reduce 10%18/12/30 07:14:07 INFO mapreduce.Job:  map 45% reduce 10%18/12/30 07:14:09 INFO mapreduce.Job:  map 46% reduce 10%18/12/30 07:14:12 INFO mapreduce.Job:  map 47% reduce 10%18/12/30 07:14:14 INFO mapreduce.Job:  map 48% reduce 10%18/12/30 07:14:17 INFO mapreduce.Job:  map 49% reduce 10%18/12/30 07:14:20 INFO mapreduce.Job:  map 50% reduce 11%18/12/30 07:14:24 INFO mapreduce.Job:  map 51% reduce 11%18/12/30 07:14:26 INFO mapreduce.Job:  map 53% reduce 11%18/12/30 07:14:27 INFO mapreduce.Job:  map 54% reduce 11%18/12/30 07:14:29 INFO mapreduce.Job:  map 55% reduce 11%18/12/30 07:14:32 INFO mapreduce.Job:  map 56% reduce 12%18/12/30 07:14:35 INFO mapreduce.Job:  map 57% reduce 12%18/12/30 07:14:38 INFO mapreduce.Job:  map 58% reduce 13%18/12/30 07:14:40 INFO mapreduce.Job:  map 59% reduce 13%18/12/30 07:14:42 INFO mapreduce.Job:  map 60% reduce 13%18/12/30 07:14:43 INFO mapreduce.Job:  map 61% reduce 13%18/12/30 07:14:44 INFO mapreduce.Job:  map 62% reduce 14%18/12/30 07:14:48 INFO mapreduce.Job:  map 63% reduce 14%18/12/30 07:14:51 INFO mapreduce.Job:  map 64% reduce 14%18/12/30 07:14:54 INFO mapreduce.Job:  map 65% reduce 14%18/12/30 07:14:56 INFO mapreduce.Job:  map 65% reduce 15%18/12/30 07:14:57 INFO mapreduce.Job:  map 66% reduce 15%18/12/30 07:15:00 INFO mapreduce.Job:  map 67% reduce 15%18/12/30 07:15:02 INFO mapreduce.Job:  map 68% reduce 15%18/12/30 07:15:05 INFO mapreduce.Job:  map 69% reduce 15%18/12/30 07:15:07 INFO mapreduce.Job:  map 70% reduce 15%18/12/30 07:15:09 INFO mapreduce.Job:  map 71% reduce 15%18/12/30 07:15:12 INFO mapreduce.Job:  map 72% reduce 15%18/12/30 07:15:15 INFO mapreduce.Job:  map 73% reduce 15%18/12/30 07:15:18 INFO mapreduce.Job:  map 74% reduce 15%18/12/30 07:15:19 INFO mapreduce.Job:  map 75% reduce 15%18/12/30 07:15:21 INFO mapreduce.Job:  map 76% reduce 15%18/12/30 07:15:23 INFO mapreduce.Job:  map 77% reduce 15%18/12/30 07:15:24 INFO mapreduce.Job:  map 78% reduce 15%18/12/30 07:15:25 INFO mapreduce.Job:  map 79% reduce 15%18/12/30 07:15:26 INFO mapreduce.Job:  map 80% reduce 16%18/12/30 07:15:27 INFO mapreduce.Job:  map 81% reduce 16%18/12/30 07:15:29 INFO mapreduce.Job:  map 82% reduce 16%18/12/30 07:15:32 INFO mapreduce.Job:  map 83% reduce 16%18/12/30 07:15:34 INFO mapreduce.Job:  map 84% reduce 16%18/12/30 07:15:35 INFO mapreduce.Job:  map 85% reduce 16%18/12/30 07:15:36 INFO mapreduce.Job:  map 86% reduce 16%18/12/30 07:15:38 INFO mapreduce.Job:  map 87% reduce 17%18/12/30 07:15:41 INFO mapreduce.Job:  map 88% reduce 17%18/12/30 07:15:42 INFO mapreduce.Job:  map 89% reduce 17%18/12/30 07:15:48 INFO mapreduce.Job:  map 90% reduce 17%18/12/30 07:15:53 INFO mapreduce.Job:  map 91% reduce 17%18/12/30 07:15:58 INFO mapreduce.Job:  map 92% reduce 17%18/12/30 07:16:02 INFO mapreduce.Job:  map 92% reduce 18%18/12/30 07:16:06 INFO mapreduce.Job:  map 93% reduce 18%18/12/30 07:16:12 INFO mapreduce.Job:  map 94% reduce 18%18/12/30 07:16:31 INFO mapreduce.Job:  map 95% reduce 18%18/12/30 07:16:37 INFO mapreduce.Job:  map 96% reduce 18%18/12/30 07:16:44 INFO mapreduce.Job:  map 97% reduce 18%18/12/30 07:16:49 INFO mapreduce.Job:  map 98% reduce 18%18/12/30 07:16:55 INFO mapreduce.Job:  map 98% reduce 19%18/12/30 07:16:57 INFO mapreduce.Job:  map 99% reduce 19%18/12/30 07:17:29 INFO mapreduce.Job:  map 100% reduce 19%18/12/30 07:17:37 INFO mapreduce.Job:  map 100% reduce 20%18/12/30 07:18:37 INFO mapreduce.Job:  map 100% reduce 21%18/12/30 07:19:43 INFO mapreduce.Job:  map 100% reduce 22%18/12/30 07:20:55 INFO mapreduce.Job:  map 100% reduce 23%18/12/30 07:22:20 INFO mapreduce.Job:  map 100% reduce 24%18/12/30 07:24:16 INFO mapreduce.Job: Task Id : attempt_1546153616504_0001_m_000107_0, Status : FAILEDAttemptID:attempt_1546153616504_0001_m_000107_0 Timed out after 600 secsContainer killed by the ApplicationMaster.\nSent signal OUTPUT_THREAD_DUMP (SIGQUIT) to pid 16215 as user hadoop for container container_1546153616504_0001_01_000395, result=success\nContainer killed on request. Exit code is 143\nContainer exited with a non-zero exit code 14318/12/30 07:24:16 INFO mapreduce.Job: Task Id : attempt_1546153616504_0001_m_000108_0, Status : FAILEDAttemptID:attempt_1546153616504_0001_m_000108_0 Timed out after 600 secs\nSent signal OUTPUT_THREAD_DUMP (SIGQUIT) to pid 16321 as user hadoop for container container_1546153616504_0001_01_000416, result=success\nContainer killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\nContainer exited with a non-zero exit code 14318/12/30 07:25:43 INFO mapreduce.Job:  map 100% reduce 25%18/12/30 07:27:16 INFO mapreduce.Job: Task Id : attempt_1546153616504_0001_m_000110_0, Status : FAILEDAttemptID:attempt_1546153616504_0001_m_000110_0 Timed out after 600 secs18/12/30 07:27:16 INFO mapreduce.Job: Task Id : attempt_1546153616504_0001_m_000112_0, Status : FAILEDAttemptID:attempt_1546153616504_0001_m_000112_0 Timed out after 600 secs18/12/30 07:27:16 INFO mapreduce.Job: Task Id : attempt_1546153616504_0001_m_000111_0, Status : FAILEDAttemptID:attempt_1546153616504_0001_m_000111_0 Timed out after 600 secs18/12/30 07:27:17 INFO mapreduce.Job:  map 99% reduce 25%18/12/30 07:27:17 INFO mapreduce.Job: Task Id : attempt_1546153616504_0001_m_000181_0, Status : FAILEDAttemptID:attempt_1546153616504_0001_m_000181_0 Timed out after 600 secs18/12/30 07:27:17 INFO mapreduce.Job: Task Id : attempt_1546153616504_0001_m_000184_0, Status : FAILEDAttemptID:attempt_1546153616504_0001_m_000184_0 Timed out after 600 secs18/12/30 07:27:17 INFO mapreduce.Job: Task Id : attempt_1546153616504_0001_m_000187_0, Status : FAILEDAttemptID:attempt_1546153616504_0001_m_000187_0 Timed out after 600 secs18/12/30 07:27:17 INFO mapreduce.Job: Task Id : attempt_1546153616504_0001_m_000183_0, Status : FAILEDAttemptID:attempt_1546153616504_0001_m_000183_0 Timed out after 600 secs18/12/30 07:27:17 INFO mapreduce.Job: Task Id : attempt_1546153616504_0001_m_000180_0, Status : FAILEDAttemptID:attempt_1546153616504_0001_m_000180_0 Timed out after 600 secs18/12/30 07:27:17 INFO mapreduce.Job: Task Id : attempt_1546153616504_0001_m_000179_0, Status : FAILEDAttemptID:attempt_1546153616504_0001_m_000179_0 Timed out after 600 secs18/12/30 07:27:17 INFO mapreduce.Job: Task Id : attempt_1546153616504_0001_m_000185_0, Status : FAILEDAttemptID:attempt_1546153616504_0001_m_000185_0 Timed out after 600 secs\nSent signal OUTPUT_THREAD_DUMP (SIGQUIT) to pid 16385 as user hadoop for container container_1546153616504_0001_01_000771, result=success\nContainer killed by the ApplicationMaster.\nContainer killed on request. Exit code is 143\nContainer exited with a non-zero exit code 14318/12/30 07:27:17 INFO mapreduce.Job: Task Id : attempt_1546153616504_0001_m_000186_0, Status : FAILEDAttemptID:attempt_1546153616504_0001_m_000186_0 Timed out after 600 secs\nContainer killed by the ApplicationMaster.\nSent signal OUTPUT_THREAD_DUMP (SIGQUIT) to pid 16501 as user hadoop for container container_1546153616504_0001_01_000779, result=success\nContainer killed on request. Exit code is 143\nContainer exited with a non-zero exit code 14318/12/30 07:27:17 INFO mapreduce.Job: Task Id : attempt_1546153616504_0001_m_000182_0, Status : FAILEDAttemptID:attempt_1546153616504_0001_m_000182_0 Timed out after 600 secs18/12/30 07:27:26 INFO mapreduce.Job:  map 100% reduce 25%18/12/30 07:27:32 INFO mapreduce.Job:  map 100% reduce 26%18/12/30 07:27:38 INFO mapreduce.Job:  map 100% reduce 31%18/12/30 07:27:44 INFO mapreduce.Job:  map 100% reduce 33%18/12/30 07:27:50 INFO mapreduce.Job:  map 100% reduce 34%18/12/30 07:27:56 INFO mapreduce.Job:  map 100% reduce 35%18/12/30 07:28:08 INFO mapreduce.Job:  map 100% reduce 36%18/12/30 07:28:20 INFO mapreduce.Job:  map 100% reduce 37%18/12/30 07:28:27 INFO mapreduce.Job:  map 100% reduce 38%18/12/30 07:28:38 INFO mapreduce.Job:  map 100% reduce 39%18/12/30 07:28:50 INFO mapreduce.Job:  map 100% reduce 40%18/12/30 07:28:57 INFO mapreduce.Job:  map 100% reduce 41%18/12/30 07:29:09 INFO mapreduce.Job:  map 100% reduce 42%18/12/30 07:30:08 INFO mapreduce.Job:  map 100% reduce 43%18/12/30 07:30:23 INFO mapreduce.Job:  map 100% reduce 44%18/12/30 07:30:35 INFO mapreduce.Job:  map 100% reduce 45%18/12/30 07:32:57 INFO mapreduce.Job:  map 100% reduce 46%18/12/30 07:35:38 INFO mapreduce.Job:  map 100% reduce 47%18/12/30 07:36:11 INFO mapreduce.Job:  map 100% reduce 48%18/12/30 07:36:17 INFO mapreduce.Job:  map 100% reduce 49%18/12/30 07:36:24 INFO mapreduce.Job:  map 100% reduce 50%18/12/30 07:36:53 INFO mapreduce.Job:  map 100% reduce 51%18/12/30 07:37:17 INFO mapreduce.Job:  map 100% reduce 52%18/12/30 07:37:46 INFO mapreduce.Job: Task Id : attempt_1546153616504_0001_r_000011_0, Status : FAILEDAttemptID:attempt_1546153616504_0001_r_000011_0 Timed out after 600 secs\nContainer killed by the ApplicationMaster.\nSent signal OUTPUT_THREAD_DUMP (SIGQUIT) to pid 14932 as user hadoop for container container_1546153616504_0001_01_000389, result=success\nContainer killed on request. Exit code is 143\nContainer exited with a non-zero exit code 14318/12/30 07:37:46 INFO mapreduce.Job: Task Id : attempt_1546153616504_0001_r_000005_0, Status : FAILEDAttemptID:attempt_1546153616504_0001_r_000005_0 Timed out after 600 secs\nContainer killed by the ApplicationMaster.\nSent signal OUTPUT_THREAD_DUMP (SIGQUIT) to pid 14953 as user hadoop for container container_1546153616504_0001_01_000383, result=success\nContainer killed on request. Exit code is 143\nContainer exited with a non-zero exit code 14318/12/30 07:37:46 INFO mapreduce.Job: Task Id : attempt_1546153616504_0001_r_000009_0, Status : FAILEDAttemptID:attempt_1546153616504_0001_r_000009_0 Timed out after 600 secs\nContainer killed by the ApplicationMaster.\nSent signal OUTPUT_THREAD_DUMP (SIGQUIT) to pid 14926 as user hadoop for container container_1546153616504_0001_01_000387, result=success\nContainer killed on request. Exit code is 143\nContainer exited with a non-zero exit code 14318/12/30 07:37:47 INFO mapreduce.Job:  map 100% reduce 48%18/12/30 07:37:49 INFO mapreduce.Job:  map 100% reduce 49%18/12/30 07:37:53 INFO mapreduce.Job:  map 100% reduce 50%18/12/30 07:37:55 INFO mapreduce.Job:  map 100% reduce 51%18/12/30 07:38:22 INFO mapreduce.Job:  map 100% reduce 52%18/12/30 07:38:37 INFO mapreduce.Job:  map 100% reduce 53%18/12/30 07:38:50 INFO mapreduce.Job:  map 100% reduce 54%18/12/30 07:38:59 INFO mapreduce.Job:  map 100% reduce 55%18/12/30 07:39:08 INFO mapreduce.Job:  map 100% reduce 56%18/12/30 07:39:17 INFO mapreduce.Job:  map 100% reduce 57%18/12/30 07:39:32 INFO mapreduce.Job:  map 100% reduce 58%18/12/30 07:40:03 INFO mapreduce.Job:  map 100% reduce 59%18/12/30 07:42:13 INFO mapreduce.Job:  map 100% reduce 60%18/12/30 07:47:09 INFO mapreduce.Job:  map 100% reduce 61%18/12/30 07:50:10 INFO mapreduce.Job:  map 100% reduce 63%18/12/30 07:50:16 INFO mapreduce.Job:  map 100% reduce 64%18/12/30 07:50:55 INFO mapreduce.Job:  map 100% reduce 65%18/12/30 07:51:01 INFO mapreduce.Job:  map 100% reduce 66%18/12/30 07:51:07 INFO mapreduce.Job:  map 100% reduce 67%18/12/30 07:57:28 INFO mapreduce.Job:  map 100% reduce 68%18/12/30 07:58:05 INFO mapreduce.Job:  map 100% reduce 69%18/12/30 08:01:14 INFO mapreduce.Job:  map 100% reduce 70%18/12/30 08:01:44 INFO mapreduce.Job:  map 100% reduce 71%18/12/30 08:02:14 INFO mapreduce.Job:  map 100% reduce 72%18/12/30 08:06:40 INFO mapreduce.Job:  map 100% reduce 73%18/12/30 08:06:46 INFO mapreduce.Job:  map 100% reduce 76%18/12/30 08:06:52 INFO mapreduce.Job:  map 100% reduce 78%18/12/30 08:07:16 INFO mapreduce.Job:  map 100% reduce 79%18/12/30 08:07:46 INFO mapreduce.Job:  map 100% reduce 80%18/12/30 08:08:16 INFO mapreduce.Job:  map 100% reduce 81%18/12/30 08:10:15 INFO mapreduce.Job:  map 100% reduce 83%18/12/30 08:10:21 INFO mapreduce.Job:  map 100% reduce 84%18/12/30 08:13:16 INFO mapreduce.Job:  map 100% reduce 85%18/12/30 08:13:22 INFO mapreduce.Job:  map 100% reduce 86%18/12/30 08:17:58 INFO mapreduce.Job:  map 100% reduce 87%18/12/30 08:18:10 INFO mapreduce.Job:  map 100% reduce 88%18/12/30 08:18:22 INFO mapreduce.Job:  map 100% reduce 89%18/12/30 08:18:34 INFO mapreduce.Job:  map 100% reduce 90%18/12/30 08:19:35 INFO mapreduce.Job:  map 100% reduce 91%18/12/30 08:20:46 INFO mapreduce.Job: Task Id : attempt_1546153616504_0001_r_000000_0, Status : FAILEDAttemptID:attempt_1546153616504_0001_r_000000_0 Timed out after 600 secs18/12/30 08:20:47 INFO mapreduce.Job:  map 100% reduce 88%18/12/30 08:21:10 INFO mapreduce.Job:  map 100% reduce 89%18/12/30 08:22:27 INFO mapreduce.Job:  map 100% reduce 90%18/12/30 08:24:22 INFO mapreduce.Job:  map 100% reduce 91%18/12/30 08:26:23 INFO mapreduce.Job:  map 100% reduce 92%18/12/30 08:28:18 INFO mapreduce.Job:  map 100% reduce 93%18/12/30 08:28:24 INFO mapreduce.Job:  map 100% reduce 94%18/12/30 08:28:30 INFO mapreduce.Job:  map 100% reduce 95%18/12/30 08:28:42 INFO mapreduce.Job:  map 100% reduce 96%18/12/30 08:29:12 INFO mapreduce.Job:  map 100% reduce 97%18/12/30 08:29:36 INFO mapreduce.Job:  map 100% reduce 98%18/12/30 08:30:04 INFO mapreduce.Job:  map 100% reduce 99%18/12/30 08:32:04 INFO mapreduce.Job:  map 100% reduce 100%18/12/30 08:35:27 INFO mapreduce.Job: Job job_1546153616504_0001 completed successfully18/12/30 08:35:27 INFO mapreduce.Job: Counters: 55\n\tFile System Counters\n\t\tFILE: Number of bytes read=389826685198\n\t\tFILE: Number of bytes written=514733799422\n\t\tFILE: Number of read operations=0\n\t\tFILE: Number of large read operations=0\n\t\tFILE: Number of write operations=0\n\t\tHDFS: Number of bytes read=120000092112\n\t\tHDFS: Number of bytes written=120000000000\n\t\tHDFS: Number of read operations=2772\n\t\tHDFS: Number of large read operations=0\n\t\tHDFS: Number of write operations=24\n\tJob Counters \n\t\tFailed map tasks=14\n\t\tFailed reduce tasks=4\n\t\tKilled map tasks=6\n\t\tKilled reduce tasks=8\n\t\tLaunched map tasks=931\n\t\tLaunched reduce tasks=24\n\t\tOther local map tasks=16\n\t\tData-local map tasks=863\n\t\tRack-local map tasks=52\n\t\tTotal time spent by all maps in occupied slots (ms)=63073763\n\t\tTotal time spent by all reduces in occupied slots (ms)=62849693\n\t\tTotal time spent by all map tasks (ms)=63073763\n\t\tTotal time spent by all reduce tasks (ms)=62849693\n\t\tTotal vcore-milliseconds taken by all map tasks=63073763\n\t\tTotal vcore-milliseconds taken by all reduce tasks=62849693\n\t\tTotal megabyte-milliseconds taken by all map tasks=64587533312\n\t\tTotal megabyte-milliseconds taken by all reduce tasks=64358085632\n\tMap-Reduce Framework\n\t\tMap input records=1200000000\n\t\tMap output records=1200000000\n\t\tMap output bytes=122400000000\n\t\tMap output materialized bytes=124800065664\n\t\tInput split bytes=92112\n\t\tCombine input records=0\n\t\tCombine output records=0\n\t\tReduce input groups=1200000000\n\t\tReduce shuffle bytes=124800065664\n\t\tReduce input records=1200000000\n\t\tReduce output records=1200000000\n\t\tSpilled Records=4947948361\n\t\tShuffled Maps =10944\n\t\tFailed Shuffles=0\n\t\tMerged Map outputs=10944\n\t\tGC time elapsed (ms)=327179\n\t\tCPU time spent (ms)=14250410\n\t\tPhysical memory (bytes) snapshot=275209814016\n\t\tVirtual memory (bytes) snapshot=1861392191488\n\t\tTotal committed heap usage (bytes)=181924790272\n\tShuffle Errors\n\t\tBAD_ID=0\n\t\tCONNECTION=0\n\t\tIO_ERROR=0\n\t\tWRONG_LENGTH=0\n\t\tWRONG_MAP=0\n\t\tWRONG_REDUCE=0\n\tFile Input Format Counters \n\t\tBytes Read=120000000000\n\tFile Output Format Counters \n\t\tBytes Written=12000000000018/12/30 08:35:27 INFO terasort.TeraSort: donereal\t83m20.299s\nuser\t0m20.087s\nsys\t0m4.453s", :stdout=>"Spent 197ms computing base-splits.Spent 6ms computing TeraScheduler splits.\nComputing input splits took 203msSampling 10 splits of 912Making 12 from 100000 sampled recordsComputing parititions took 1149msSpent 1355ms computing partitions.", :status=>0}}
Exp  4, overall time taken is 83 m 20.299 s
Exp  4 termintated at 2018-12-30 09:35:27 +0100

Exp  5 started at  2018-12-30 09:55:13 +0100
Exp 5's result is {"10.158.0.1"=>{:stderr=>"18/12/30 08:55:16 INFO terasort.TeraSort: starting18/12/30 08:55:16 INFO input.FileInputFormat: Total input files to process : 2418/12/30 08:55:18 INFO client.RMProxy: Connecting to ResourceManager at node1/10.158.0.1:803218/12/30 08:55:19 INFO mapreduce.JobSubmitter: number of splits:91218/12/30 08:55:19 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces18/12/30 08:55:19 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1546159804241_000118/12/30 08:55:20 INFO impl.YarnClientImpl: Submitted application application_1546159804241_000118/12/30 08:55:20 INFO mapreduce.Job: The url to track the job: http://node1:8088/proxy/application_1546159804241_0001/18/12/30 08:55:20 INFO mapreduce.Job: Running job: job_1546159804241_000118/12/30 08:55:26 INFO mapreduce.Job: Job job_1546159804241_0001 running in uber mode : false18/12/30 08:55:26 INFO mapreduce.Job:  map 0% reduce 0%18/12/30 08:55:44 INFO mapreduce.Job:  map 2% reduce 0%18/12/30 08:55:45 INFO mapreduce.Job:  map 6% reduce 0%18/12/30 08:55:46 INFO mapreduce.Job:  map 7% reduce 0%18/12/30 08:55:50 INFO mapreduce.Job:  map 8% reduce 0%18/12/30 08:55:51 INFO mapreduce.Job:  map 10% reduce 0%18/12/30 08:55:56 INFO mapreduce.Job:  map 12% reduce 0%18/12/30 08:55:57 INFO mapreduce.Job:  map 13% reduce 0%18/12/30 08:55:58 INFO mapreduce.Job:  map 14% reduce 0%18/12/30 08:56:03 INFO mapreduce.Job:  map 17% reduce 0%18/12/30 08:56:04 INFO mapreduce.Job:  map 21% reduce 0%18/12/30 08:56:10 INFO mapreduce.Job:  map 22% reduce 0%18/12/30 08:56:15 INFO mapreduce.Job:  map 23% reduce 0%18/12/30 08:56:17 INFO mapreduce.Job:  map 24% reduce 0%18/12/30 08:56:19 INFO mapreduce.Job:  map 25% reduce 0%18/12/30 08:56:21 INFO mapreduce.Job:  map 26% reduce 2%18/12/30 08:56:22 INFO mapreduce.Job:  map 27% reduce 5%18/12/30 08:56:23 INFO mapreduce.Job:  map 28% reduce 5%18/12/30 08:56:24 INFO mapreduce.Job:  map 29% reduce 5%18/12/30 08:56:25 INFO mapreduce.Job:  map 30% reduce 5%18/12/30 08:56:26 INFO mapreduce.Job:  map 31% reduce 5%18/12/30 08:56:28 INFO mapreduce.Job:  map 32% reduce 5%18/12/30 08:56:29 INFO mapreduce.Job:  map 33% reduce 6%18/12/30 08:56:30 INFO mapreduce.Job:  map 34% reduce 6%18/12/30 08:56:31 INFO mapreduce.Job:  map 36% reduce 6%18/12/30 08:56:32 INFO mapreduce.Job:  map 37% reduce 6%18/12/30 08:56:33 INFO mapreduce.Job:  map 38% reduce 6%18/12/30 08:56:34 INFO mapreduce.Job:  map 40% reduce 7%18/12/30 08:56:35 INFO mapreduce.Job:  map 41% reduce 7%18/12/30 08:56:36 INFO mapreduce.Job:  map 42% reduce 7%18/12/30 08:56:39 INFO mapreduce.Job:  map 43% reduce 8%18/12/30 08:56:40 INFO mapreduce.Job:  map 43% reduce 10%18/12/30 08:56:41 INFO mapreduce.Job:  map 44% reduce 10%18/12/30 08:56:44 INFO mapreduce.Job:  map 45% reduce 10%18/12/30 08:56:45 INFO mapreduce.Job:  map 45% reduce 11%18/12/30 08:56:46 INFO mapreduce.Job:  map 45% reduce 12%18/12/30 08:56:47 INFO mapreduce.Job:  map 46% reduce 12%18/12/30 08:56:50 INFO mapreduce.Job:  map 47% reduce 12%18/12/30 08:56:51 INFO mapreduce.Job:  map 47% reduce 13%18/12/30 08:56:52 INFO mapreduce.Job:  map 47% reduce 14%18/12/30 08:56:53 INFO mapreduce.Job:  map 48% reduce 14%18/12/30 08:56:56 INFO mapreduce.Job:  map 49% reduce 14%18/12/30 08:56:57 INFO mapreduce.Job:  map 49% reduce 15%18/12/30 08:56:58 INFO mapreduce.Job:  map 50% reduce 15%18/12/30 08:57:01 INFO mapreduce.Job:  map 51% reduce 15%18/12/30 08:57:02 INFO mapreduce.Job:  map 52% reduce 15%18/12/30 08:57:04 INFO mapreduce.Job:  map 53% reduce 15%18/12/30 08:57:05 INFO mapreduce.Job:  map 54% reduce 15%18/12/30 08:57:07 INFO mapreduce.Job:  map 55% reduce 15%18/12/30 08:57:09 INFO mapreduce.Job:  map 56% reduce 16%18/12/30 08:57:10 INFO mapreduce.Job:  map 57% reduce 16%18/12/30 08:57:11 INFO mapreduce.Job:  map 58% reduce 16%18/12/30 08:57:13 INFO mapreduce.Job:  map 59% reduce 16%18/12/30 08:57:14 INFO mapreduce.Job:  map 60% reduce 16%18/12/30 08:57:15 INFO mapreduce.Job:  map 61% reduce 16%18/12/30 08:57:16 INFO mapreduce.Job:  map 62% reduce 17%18/12/30 08:57:18 INFO mapreduce.Job:  map 63% reduce 17%18/12/30 08:57:20 INFO mapreduce.Job:  map 64% reduce 17%18/12/30 08:57:22 INFO mapreduce.Job:  map 65% reduce 18%18/12/30 08:57:23 INFO mapreduce.Job:  map 66% reduce 18%18/12/30 08:57:26 INFO mapreduce.Job:  map 67% reduce 18%18/12/30 08:57:37 INFO mapreduce.Job:  map 70% reduce 19%18/12/30 08:57:40 INFO mapreduce.Job:  map 72% reduce 19%18/12/30 08:57:43 INFO mapreduce.Job:  map 74% reduce 21%18/12/30 08:57:49 INFO mapreduce.Job:  map 74% reduce 22%18/12/30 08:57:51 INFO mapreduce.Job:  map 75% reduce 22%18/12/30 08:57:52 INFO mapreduce.Job:  map 76% reduce 22%18/12/30 08:57:53 INFO mapreduce.Job:  map 77% reduce 22%18/12/30 08:57:55 INFO mapreduce.Job:  map 78% reduce 23%18/12/30 08:57:59 INFO mapreduce.Job:  map 79% reduce 23%18/12/30 08:58:05 INFO mapreduce.Job:  map 80% reduce 23%18/12/30 08:58:08 INFO mapreduce.Job:  map 81% reduce 23%18/12/30 08:58:11 INFO mapreduce.Job:  map 82% reduce 23%18/12/30 08:58:16 INFO mapreduce.Job:  map 83% reduce 23%18/12/30 08:58:19 INFO mapreduce.Job:  map 83% reduce 24%18/12/30 08:58:21 INFO mapreduce.Job:  map 84% reduce 24%18/12/30 08:58:24 INFO mapreduce.Job:  map 85% reduce 24%18/12/30 08:58:28 INFO mapreduce.Job:  map 86% reduce 24%18/12/30 08:58:33 INFO mapreduce.Job:  map 87% reduce 24%18/12/30 08:58:35 INFO mapreduce.Job:  map 88% reduce 24%18/12/30 08:58:37 INFO mapreduce.Job:  map 89% reduce 25%18/12/30 08:58:38 INFO mapreduce.Job:  map 90% reduce 25%18/12/30 08:58:41 INFO mapreduce.Job:  map 91% reduce 25%18/12/30 08:58:45 INFO mapreduce.Job:  map 92% reduce 25%18/12/30 08:58:50 INFO mapreduce.Job:  map 93% reduce 25%18/12/30 08:58:55 INFO mapreduce.Job:  map 94% reduce 26%18/12/30 08:59:00 INFO mapreduce.Job:  map 95% reduce 26%18/12/30 08:59:03 INFO mapreduce.Job:  map 96% reduce 26%18/12/30 08:59:07 INFO mapreduce.Job:  map 96% reduce 27%18/12/30 08:59:11 INFO mapreduce.Job:  map 97% reduce 27%18/12/30 08:59:16 INFO mapreduce.Job:  map 98% reduce 27%18/12/30 08:59:22 INFO mapreduce.Job:  map 99% reduce 27%18/12/30 08:59:30 INFO mapreduce.Job:  map 100% reduce 27%18/12/30 08:59:31 INFO mapreduce.Job:  map 100% reduce 28%18/12/30 09:00:03 INFO mapreduce.Job: Task Id : attempt_1546159804241_0001_m_000488_0, Status : FAILEDContainer launch failed for container_1546159804241_0001_01_000919 : java.io.IOException: Failed on local exception: java.io.IOException: java.net.SocketTimeoutException: 60000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.158.0.2:48046 remote=node25/10.158.0.25:40809]; Host Details : local host is: \"node2/10.158.0.2\"; destination host is: \"node25\":40809; \n\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:782)\n\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1493)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1435)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1345)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)\n\tat com.sun.proxy.$Proxy82.startContainers(Unknown Source)\n\tat org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)\n\tat sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)\n\tat com.sun.proxy.$Proxy83.startContainers(Unknown Source)\n\tat org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$Container.launch(ContainerLauncherImpl.java:158)\n\tat org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$EventProcessor.run(ContainerLauncherImpl.java:393)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.io.IOException: java.net.SocketTimeoutException: 60000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.158.0.2:48046 remote=node25/10.158.0.25:40809]\n\tat org.apache.hadoop.ipc.Client$Connection$1.run(Client.java:755)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)\n\tat org.apache.hadoop.ipc.Client$Connection.handleSaslConnectionFailure(Client.java:718)\n\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:811)\n\tat org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)\n\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1381)\n\t... 19 more\nCaused by: java.net.SocketTimeoutException: 60000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.158.0.2:48046 remote=node25/10.158.0.25:40809]\n\tat org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)\n\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)\n\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)\n\tat java.io.FilterInputStream.read(FilterInputStream.java:133)\n\tat java.io.BufferedInputStream.fill(BufferedInputStream.java:246)\n\tat java.io.BufferedInputStream.read(BufferedInputStream.java:265)\n\tat java.io.DataInputStream.readInt(DataInputStream.java:387)\n\tat org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1794)\n\tat org.apache.hadoop.security.SaslRpcClient.saslConnect(SaslRpcClient.java:364)\n\tat org.apache.hadoop.ipc.Client$Connection.setupSaslConnection(Client.java:614)\n\tat org.apache.hadoop.ipc.Client$Connection.access$2200(Client.java:410)\n\tat org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:798)\n\tat org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:794)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)\n\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:793)\n\t... 22 more18/12/30 09:00:04 INFO mapreduce.Job: Task Id : attempt_1546159804241_0001_m_000688_0, Status : FAILEDContainer launch failed for container_1546159804241_0001_01_000927 : java.io.IOException: Failed on local exception: java.io.IOException: java.net.SocketTimeoutException: 60000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.158.0.2:48072 remote=node25/10.158.0.25:40809]; Host Details : local host is: \"node2/10.158.0.2\"; destination host is: \"node25\":40809; \n\tat org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:782)\n\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1493)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1435)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1345)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:227)\n\tat org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)\n\tat com.sun.proxy.$Proxy82.startContainers(Unknown Source)\n\tat org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:106)\n\tat sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:409)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:346)\n\tat com.sun.proxy.$Proxy83.startContainers(Unknown Source)\n\tat org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$Container.launch(ContainerLauncherImpl.java:158)\n\tat org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$EventProcessor.run(ContainerLauncherImpl.java:393)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.io.IOException: java.net.SocketTimeoutException: 60000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.158.0.2:48072 remote=node25/10.158.0.25:40809]\n\tat org.apache.hadoop.ipc.Client$Connection$1.run(Client.java:755)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)\n\tat org.apache.hadoop.ipc.Client$Connection.handleSaslConnectionFailure(Client.java:718)\n\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:811)\n\tat org.apache.hadoop.ipc.Client$Connection.access$3500(Client.java:410)\n\tat org.apache.hadoop.ipc.Client.getConnection(Client.java:1550)\n\tat org.apache.hadoop.ipc.Client.call(Client.java:1381)\n\t... 19 more\nCaused by: java.net.SocketTimeoutException: 60000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.158.0.2:48072 remote=node25/10.158.0.25:40809]\n\tat org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)\n\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)\n\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)\n\tat java.io.FilterInputStream.read(FilterInputStream.java:133)\n\tat java.io.BufferedInputStream.fill(BufferedInputStream.java:246)\n\tat java.io.BufferedInputStream.read(BufferedInputStream.java:265)\n\tat java.io.DataInputStream.readInt(DataInputStream.java:387)\n\tat org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1794)\n\tat org.apache.hadoop.security.SaslRpcClient.saslConnect(SaslRpcClient.java:364)\n\tat org.apache.hadoop.ipc.Client$Connection.setupSaslConnection(Client.java:614)\n\tat org.apache.hadoop.ipc.Client$Connection.access$2200(Client.java:410)\n\tat org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:798)\n\tat org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:794)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1840)\n\tat org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:793)\n\t... 22 more18/12/30 09:00:08 INFO mapreduce.Job:  map 100% reduce 29%18/12/30 09:00:59 INFO mapreduce.Job:  map 100% reduce 30%18/12/30 09:01:14 INFO mapreduce.Job:  map 100% reduce 31%18/12/30 09:02:38 INFO mapreduce.Job:  map 100% reduce 32%18/12/30 09:04:32 INFO mapreduce.Job:  map 100% reduce 33%18/12/30 09:04:37 INFO mapreduce.Job:  map 100% reduce 35%18/12/30 09:04:38 INFO mapreduce.Job:  map 100% reduce 36%18/12/30 09:04:43 INFO mapreduce.Job:  map 100% reduce 39%18/12/30 09:04:44 INFO mapreduce.Job:  map 100% reduce 40%18/12/30 09:04:50 INFO mapreduce.Job:  map 100% reduce 41%18/12/30 09:05:02 INFO mapreduce.Job:  map 100% reduce 42%18/12/30 09:05:26 INFO mapreduce.Job:  map 100% reduce 43%18/12/30 09:05:50 INFO mapreduce.Job:  map 100% reduce 44%18/12/30 09:07:32 INFO mapreduce.Job:  map 100% reduce 46%18/12/30 09:07:56 INFO mapreduce.Job:  map 100% reduce 47%18/12/30 09:08:14 INFO mapreduce.Job:  map 100% reduce 49%18/12/30 09:08:26 INFO mapreduce.Job:  map 100% reduce 50%18/12/30 09:09:52 INFO mapreduce.Job:  map 100% reduce 52%18/12/30 09:09:58 INFO mapreduce.Job:  map 100% reduce 53%18/12/30 09:09:59 INFO mapreduce.Job:  map 100% reduce 54%18/12/30 09:10:05 INFO mapreduce.Job:  map 100% reduce 55%18/12/30 09:10:11 INFO mapreduce.Job:  map 100% reduce 56%18/12/30 09:11:03 INFO mapreduce.Job:  map 100% reduce 59%18/12/30 09:11:09 INFO mapreduce.Job:  map 100% reduce 61%18/12/30 09:12:39 INFO mapreduce.Job:  map 100% reduce 62%18/12/30 09:12:51 INFO mapreduce.Job:  map 100% reduce 63%18/12/30 09:13:03 INFO mapreduce.Job:  map 100% reduce 64%18/12/30 09:13:20 INFO mapreduce.Job:  map 100% reduce 65%18/12/30 09:13:32 INFO mapreduce.Job:  map 100% reduce 66%18/12/30 09:13:44 INFO mapreduce.Job:  map 100% reduce 67%18/12/30 09:13:56 INFO mapreduce.Job:  map 100% reduce 68%18/12/30 09:14:08 INFO mapreduce.Job:  map 100% reduce 69%18/12/30 09:14:20 INFO mapreduce.Job:  map 100% reduce 70%18/12/30 09:14:26 INFO mapreduce.Job:  map 100% reduce 71%18/12/30 09:14:38 INFO mapreduce.Job:  map 100% reduce 72%18/12/30 09:14:44 INFO mapreduce.Job:  map 100% reduce 73%18/12/30 09:14:56 INFO mapreduce.Job:  map 100% reduce 74%18/12/30 09:15:02 INFO mapreduce.Job:  map 100% reduce 75%18/12/30 09:15:14 INFO mapreduce.Job:  map 100% reduce 76%18/12/30 09:15:26 INFO mapreduce.Job:  map 100% reduce 77%18/12/30 09:15:38 INFO mapreduce.Job:  map 100% reduce 78%18/12/30 09:15:56 INFO mapreduce.Job:  map 100% reduce 79%18/12/30 09:16:14 INFO mapreduce.Job:  map 100% reduce 80%18/12/30 09:16:33 INFO mapreduce.Job:  map 100% reduce 81%18/12/30 09:16:51 INFO mapreduce.Job:  map 100% reduce 82%18/12/30 09:17:29 INFO mapreduce.Job:  map 100% reduce 83%18/12/30 09:17:47 INFO mapreduce.Job:  map 100% reduce 84%18/12/30 09:18:05 INFO mapreduce.Job:  map 100% reduce 85%18/12/30 09:18:23 INFO mapreduce.Job:  map 100% reduce 86%18/12/30 09:18:41 INFO mapreduce.Job:  map 100% reduce 87%18/12/30 09:19:05 INFO mapreduce.Job:  map 100% reduce 88%18/12/30 09:21:02 INFO mapreduce.Job:  map 100% reduce 89%18/12/30 09:21:09 INFO mapreduce.Job:  map 100% reduce 90%18/12/30 09:21:21 INFO mapreduce.Job:  map 100% reduce 91%18/12/30 09:21:32 INFO mapreduce.Job:  map 100% reduce 92%18/12/30 09:21:44 INFO mapreduce.Job:  map 100% reduce 93%18/12/30 09:21:50 INFO mapreduce.Job:  map 100% reduce 94%18/12/30 09:22:02 INFO mapreduce.Job:  map 100% reduce 95%18/12/30 09:23:58 INFO mapreduce.Job: Task Id : attempt_1546159804241_0001_r_000006_0, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.7:50010,DS-bf2614ac-823c-4b04-b4aa-0da07ba140e5,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)18/12/30 09:23:58 INFO mapreduce.Job: Task Id : attempt_1546159804241_0001_r_000008_0, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.7:50010,DS-bf2614ac-823c-4b04-b4aa-0da07ba140e5,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)18/12/30 09:23:58 INFO mapreduce.Job: Task Id : attempt_1546159804241_0001_r_000004_0, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.7:50010,DS-bf2614ac-823c-4b04-b4aa-0da07ba140e5,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)18/12/30 09:23:58 INFO mapreduce.Job: Task Id : attempt_1546159804241_0001_r_000011_0, Status : FAILEDError: java.io.IOException: All datanodes [DatanodeInfoWithStorage[10.158.0.7:50010,DS-bf2614ac-823c-4b04-b4aa-0da07ba140e5,DISK]] are bad. Aborting...\n\tat org.apache.hadoop.hdfs.DataStreamer.handleBadDatanode(DataStreamer.java:1530)\n\tat org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1465)\n\tat org.apache.hadoop.hdfs.DataStreamer.processDatanodeError(DataStreamer.java:1237)\n\tat org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:657)18/12/30 09:23:59 INFO mapreduce.Job:  map 100% reduce 84%18/12/30 09:24:26 INFO mapreduce.Job:  map 100% reduce 85%18/12/30 09:24:56 INFO mapreduce.Job:  map 100% reduce 86%18/12/30 09:25:14 INFO mapreduce.Job:  map 100% reduce 87%18/12/30 09:25:26 INFO mapreduce.Job:  map 100% reduce 88%18/12/30 09:25:53 INFO mapreduce.Job:  map 100% reduce 89%18/12/30 09:26:11 INFO mapreduce.Job:  map 100% reduce 90%18/12/30 09:26:47 INFO mapreduce.Job:  map 100% reduce 91%18/12/30 09:27:17 INFO mapreduce.Job:  map 100% reduce 92%18/12/30 09:30:09 INFO mapreduce.Job:  map 100% reduce 93%18/12/30 09:30:15 INFO mapreduce.Job:  map 100% reduce 94%18/12/30 09:30:21 INFO mapreduce.Job:  map 100% reduce 95%18/12/30 09:30:33 INFO mapreduce.Job:  map 100% reduce 96%18/12/30 09:31:03 INFO mapreduce.Job:  map 100% reduce 97%18/12/30 09:32:27 INFO mapreduce.Job:  map 100% reduce 98%18/12/30 09:32:57 INFO mapreduce.Job:  map 100% reduce 99%18/12/30 09:33:27 INFO mapreduce.Job:  map 100% reduce 100%18/12/30 09:36:28 INFO mapreduce.Job: Job job_1546159804241_0001 completed successfully18/12/30 09:36:28 INFO mapreduce.Job: Counters: 55\n\tFile System Counters\n\t\tFILE: Number of bytes read=389751749240\n\t\tFILE: Number of bytes written=514658863464\n\t\tFILE: Number of read operations=0\n\t\tFILE: Number of large read operations=0\n\t\tFILE: Number of write operations=0\n\t\tHDFS: Number of bytes read=120000092112\n\t\tHDFS: Number of bytes written=120000000000\n\t\tHDFS: Number of read operations=2772\n\t\tHDFS: Number of large read operations=0\n\t\tHDFS: Number of write operations=24\n\tJob Counters \n\t\tFailed map tasks=2\n\t\tFailed reduce tasks=4\n\t\tKilled map tasks=4\n\t\tKilled reduce tasks=7\n\t\tLaunched map tasks=917\n\t\tLaunched reduce tasks=22\n\t\tOther local map tasks=3\n\t\tData-local map tasks=871\n\t\tRack-local map tasks=43\n\t\tTotal time spent by all maps in occupied slots (ms)=40423898\n\t\tTotal time spent by all reduces in occupied slots (ms)=27453406\n\t\tTotal time spent by all map tasks (ms)=40423898\n\t\tTotal time spent by all reduce tasks (ms)=27453406\n\t\tTotal vcore-milliseconds taken by all map tasks=40423898\n\t\tTotal vcore-milliseconds taken by all reduce tasks=27453406\n\t\tTotal megabyte-milliseconds taken by all map tasks=41394071552\n\t\tTotal megabyte-milliseconds taken by all reduce tasks=28112287744\n\tMap-Reduce Framework\n\t\tMap input records=1200000000\n\t\tMap output records=1200000000\n\t\tMap output bytes=122400000000\n\t\tMap output materialized bytes=124800065664\n\t\tInput split bytes=92112\n\t\tCombine input records=0\n\t\tCombine output records=0\n\t\tReduce input groups=1200000000\n\t\tReduce shuffle bytes=124800065664\n\t\tReduce input records=1200000000\n\t\tReduce output records=1200000000\n\t\tSpilled Records=4947227823\n\t\tShuffled Maps =10944\n\t\tFailed Shuffles=0\n\t\tMerged Map outputs=10944\n\t\tGC time elapsed (ms)=333548\n\t\tCPU time spent (ms)=14237750\n\t\tPhysical memory (bytes) snapshot=275579871232\n\t\tVirtual memory (bytes) snapshot=1861356912640\n\t\tTotal committed heap usage (bytes)=182249324544\n\tShuffle Errors\n\t\tBAD_ID=0\n\t\tCONNECTION=0\n\t\tIO_ERROR=0\n\t\tWRONG_LENGTH=0\n\t\tWRONG_MAP=0\n\t\tWRONG_REDUCE=0\n\tFile Input Format Counters \n\t\tBytes Read=120000000000\n\tFile Output Format Counters \n\t\tBytes Written=12000000000018/12/30 09:36:28 INFO terasort.TeraSort: donereal\t41m13.115s\nuser\t0m17.475s\nsys\t0m2.614s", :stdout=>"Spent 192ms computing base-splits.Spent 6ms computing TeraScheduler splits.\nComputing input splits took 199msSampling 10 splits of 912Making 12 from 100000 sampled recordsComputing parititions took 1107msSpent 1309ms computing partitions.", :status=>0}}
Exp  5, overall time taken is 41 m 13.115 s
Exp  5 termintated at 2018-12-30 10:36:28 +0100

